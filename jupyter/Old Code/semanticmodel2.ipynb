{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1799e9a-c582-4305-bed9-f5fe0a4571d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/bin/python\n",
      "Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:20) [Clang 17.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab552e-0b92-496e-874d-f910246cb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Install packages ########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create chunks\n",
    "import re\n",
    "\n",
    "# Model for NER\n",
    "import spacy \n",
    "from sklearn.cluster import KMeans\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "#UMLSClient for NER\n",
    "import umls_api\n",
    "from umls_api_client import UMLS\n",
    "from quickumls import QuickUMLS\n",
    "\n",
    "# Use natural language processing (NLP) to extract keywords from the criteria\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Performance\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc454d26-2984-419c-b89a-c0fd752889e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Connect to Snowflake ########################################\n",
    "\n",
    "# Establish a connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user='dana_george@hakkoda.io',\n",
    "    authenticator='externalbrowser',\n",
    "    account='ska04930.east-us-2.azure',\n",
    "    warehouse='DATASCIENCE_WH',\n",
    "    database='ONCOEMR_RAW_DEV',\n",
    "    schema='DBO',\n",
    "    role='ACCOUNTADMIN'\n",
    ")\n",
    "\n",
    "# Run a test query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
    "row = cursor.fetchone()\n",
    "print(\"Snowflake version:\", row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09e86f-4132-4319-8ba8-4bb4b56bbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Load Data ########################################\n",
    "\n",
    "# Get sample patient ids\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
    "    ORDER BY RANDOM()\n",
    "\"\"\")\n",
    "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
    "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'DBO'\n",
    "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
    "    AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all the table names\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "#print(tables)\n",
    "\n",
    "# Create a dictionary to hold each table as a DataFrame\n",
    "table_dataframes = {}\n",
    "table_dataframes_spat = {}\n",
    "\n",
    "for table in tables:\n",
    "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
    "    \"\"\")\n",
    "    \n",
    "    columns = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    # If 'patientid' is a column, proceed to query the table\n",
    "    if 'patientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "    # If 'spatientid' is a column, proceed to query the table\n",
    "    if 'spatientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results_spat = cursor.fetchall()\n",
    "        columns_spat = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
    "\n",
    "# Merge table_dataframes_spat into table_dataframes_pat\n",
    "table_dataframes.update(table_dataframes_spat)\n",
    "\n",
    "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
    "print(\"Tables Loaded:\")\n",
    "for table, df in table_dataframes.items():\n",
    "    print(f\"{table}\")\n",
    "    #print(df.head())\n",
    "\n",
    "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
    "for table, df in table_dataframes.items():\n",
    "    globals()[table] = df\n",
    "\n",
    "# Now you can access the DataFrames as individual variables:\n",
    "# print(ADMINISTRATIONS.head())\n",
    "\n",
    "# Bring in clinical trial data\n",
    "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
    "clinical_trials_incl = pd.read_csv('clinical_trials_data_simple_inclusion.csv')\n",
    "print(\"clinical_trials_data_simple_exclusion\")\n",
    "print(\"clinical_trials_data_simple_inclusion\")\n",
    "print(\" \")\n",
    "print(\"Data Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282a9cb-7edd-4d69-8ab9-466e98565ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_columns_of_dict_of_dfs(df_dict):\n",
    "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
    "\n",
    "    for df_name, df in df_dict.items():\n",
    "        print(f\"Columns of {df_name}:\")\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "# Call the function to print the columns\n",
    "print_columns_of_dict_of_dfs(table_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed99ed-c27d-4aa2-8ab3-cd27c00e1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Feature Engineering ########################################\n",
    "\n",
    "# Convert non-numeric values to NaN\n",
    "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
    "\n",
    "# Now, convert the column to integers (NaNs will remain as NaN)\n",
    "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
    "print(\"Feature Engineering Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e0bbb-da04-447e-99d6-17a4188db9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Quality Check ########################################\n",
    "print(clinical_trials_incl.columns)\n",
    "print(DEMOGRAPHICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb975d-d5c9-4c2c-812b-0954914c1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Build Mock Expert Decision ########################################\n",
    "# Perform the LEFT JOIN\n",
    "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
    "\n",
    "# Filter using \"LIKE\" equivalent\n",
    "eligible = merged_df[\n",
    "    (merged_df['age'] >= 18) &\n",
    "    (merged_df['gender'] == 'Female') &\n",
    "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('lung', case=False, na=False)) &\n",
    "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
    "]\n",
    "\n",
    "# eligible['Expert Decision'] = 1\n",
    "\n",
    "# Extract patient IDs that match the expert's eligibility criteria\n",
    "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
    "\n",
    "# Get patient IDs that are not in the eligible list\n",
    "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
    "\n",
    "# SELECT * FROM DEMOGRAPHICS\n",
    "# LEFT JOIN DIAGNOSIS ON PATIENTID\n",
    "# WHERE AGE >= 18 AND GENDER = 'FEMALE'\n",
    "# AND DIAGNOSIS like LUNG CANCER\n",
    "\n",
    "print(len(eligible_patient_ids))\n",
    "print(len(ineligible_patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b7927-d8cb-40be-8ca5-b59c9ba1cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clinical_trials_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b08989-9ac6-4e46-bce3-211578348e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test to apply to 1 line of text\n",
    "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# Load the MedSpaCy model\n",
    "nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# Process your text\n",
    "text = \"The patient is a female 18 years old and was diagnosed with breast cancer and prescribed Tamoxifen.\"\n",
    "\n",
    "# Function to extract entities and labels\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # Custom check for age-related information (e.g., \"18 years old\")\n",
    "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If age-related information is found, add it to the entities with the correct label\n",
    "    for age in age_matches:\n",
    "        entities.append((f\"{age} years old\", 'AGE'))\n",
    "    \n",
    "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "    # Check for the first gender-related term match (female first, then male)\n",
    "    gender_found = False\n",
    "    for gender in gender_keywords:\n",
    "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            entities.append((match.group(), 'GENDER'))\n",
    "            break  # Once a match is found, stop further checking\n",
    "\n",
    "    return entities\n",
    "\n",
    "# Display named entities and custom additions\n",
    "entities = extract_entities(text)\n",
    "for ent in entities:\n",
    "    print(f\"Entity: {ent[0]}, Label: {ent[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6d86a-37d7-4e6e-bfce-9f50692250e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply to a dataframe of trial data\n",
    "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# Load the MedSpaCy model\n",
    "nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# Function to extract entities and labels\n",
    "def extract_entities(text):\n",
    "    # Process the text through the NLP model\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # Custom check for age-related information (e.g., \"18 years old\")\n",
    "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If age-related information is found, add it to the entities with the correct label\n",
    "    for age in age_matches:\n",
    "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
    "    \n",
    "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "    # Check for the first gender-related term match (female first, then male)\n",
    "    gender_found = False\n",
    "    for gender in gender_keywords:\n",
    "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            entities.append((match.group(), 'GENDER'))\n",
    "            break  # Once a match is found, stop further checking\n",
    "\n",
    "    # Extract the unique labels to avoid duplicates and return them\n",
    "    unique_labels = set([label for _, label in entities])\n",
    "    return list(unique_labels)\n",
    "\n",
    "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
    "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76504c-9037-43a8-a16f-4fc8b75065cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find exact matches and fuzzy matches\n",
    "def find_matching_columns(category, dict_of_dfs, fuzzy_threshold=80):\n",
    "    # Step 1: Find exact matches (case-insensitive)\n",
    "    exact_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        if category.lower() in [col.lower() for col in df.columns]:\n",
    "            exact_column = next(col for col in df.columns if col.lower() == category.lower())\n",
    "            exact_matches.append(f'{df_name}.{exact_column}')\n",
    "            return exact_matches  # Return immediately after finding an exact match\n",
    "    \n",
    "    # Step 2: If no exact match, find fuzzy matches\n",
    "    fuzzy_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        columns = df.columns\n",
    "        for column in columns:\n",
    "            score = process.extractOne(category, [column])  # Compare category with each column\n",
    "            if score and score[1] >= fuzzy_threshold:  # If score is above threshold\n",
    "                fuzzy_matches.append(f'{df_name}.{column}')\n",
    "    \n",
    "    return fuzzy_matches\n",
    "\n",
    "# Loop through the clinical_trials_incl DataFrame and apply matching function\n",
    "def add_source_columns(clinical_trials_incl, table_dataframes):\n",
    "    source_columns_list = []\n",
    "    \n",
    "    for index, row in clinical_trials_incl.iterrows():\n",
    "        category = row['Category']\n",
    "        matching_columns = find_matching_columns(category, table_dataframes)\n",
    "        \n",
    "        # If there are multiple matches, list them, else return 'No match'\n",
    "        if matching_columns:\n",
    "            source_columns_list.append(', '.join(matching_columns))\n",
    "        else:\n",
    "            source_columns_list.append('No match')\n",
    "    \n",
    "    clinical_trials_incl['source_columns'] = source_columns_list\n",
    "    return clinical_trials_incl\n",
    "\n",
    "# Apply the function to the clinical_trials_incl DataFrame\n",
    "updated_df = add_source_columns(clinical_trials_incl, table_dataframes)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(updated_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_mitsui_condapy310)",
   "language": "python",
   "name": "venv_mitsui_condapy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
