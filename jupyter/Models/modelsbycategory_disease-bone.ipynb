{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef112a06-1ff5-41a3-ab40-7ec260c1e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/bin/python\n",
      "Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:20) [Clang 17.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "######################################## Check Environment ########################################\n",
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420d431f-e164-4c22-9e4f-ad7b9e9ed80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################################## Install packages ########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create chunks\n",
    "import re\n",
    "\n",
    "# Model for NER\n",
    "import spacy \n",
    "from sklearn.cluster import KMeans\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "#UMLSClient for NER\n",
    "import umls_api\n",
    "from umls_api_client import UMLS\n",
    "from quickumls import QuickUMLS\n",
    "\n",
    "# Use natural language processing (NLP) to extract keywords from the criteria\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Performance\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fdc997-2323-400b-b5b5-e8b779cc070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://login.microsoftonline.com/bbaf0319-e615-416f-8870-f7eacf074b66/saml2?SAMLRequest=nZJPc9owEMW%2Fikc925b%2FAEEDZGgorWdoYTD0kJuw16DBlhytHId%2B%2BsoGZtJDcuhNI73d39O%2BnTy%2BVaXzChqFklMSeJQ4IDOVC3mckv1u6T4QBw2XOS%2BVhCm5AJLH2QR5VdZs3piT3MJLA2gc20gi6x6mpNGSKY4CmeQVIDMZS%2Bc%2FVyz0KOOIoI3FkVtJjsKyTsbUzPfbtvXayFP66IeUUp%2BOfavqJF%2FIO0T9OaPWyqhMlfeSN%2FunDxCBT%2BMOYRWWsLkVfhXyOoLPKIerCNmP3W7jbtbpjjjz%2B%2B%2BelMSmAp2CfhUZ7LerqwG0DvDMaTyOqAccjdugG3r8T6PBQ6naouRnyFRVN8Y29%2BzJLyD3S3UUdmTJYkrqs8jXx28pXQUqVXFTrPWyTfZyxZ%2BhSi7b7fdB9DIPaZbGp5RnGXF%2B3wMOu4ATxAYS2cVq7BUNYzcI3DDYUcqiiA2GXhSFz8RZ2FiF5KavvHvvfXiVyLRCVRglSyGhd3k48IJGwdiFYTBw42BYuA8PI%2BoWI%2BBZQUfxYTj0u%2FBCcl0g1hvRs%2F8cy8R%2F3%2BS2kr9sSslio0qRXZyl0hU3H4cYeEF%2FI3K36KUMKi7KeZ5rQLRhlqVqnzRwYzff6AaIP7tS%2F9392V8%3D&RelayState=57771 to authenticate...\n",
      "Snowflake version: 8.43.0\n"
     ]
    }
   ],
   "source": [
    "######################################## Connect to Snowflake ########################################\n",
    "\n",
    "# Establish a connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user='dana_george@hakkoda.io',\n",
    "    authenticator='externalbrowser',\n",
    "    account='ska04930.east-us-2.azure',\n",
    "    warehouse='DATASCIENCE_WH',\n",
    "    database='ONCOEMR_RAW_DEV',\n",
    "    schema='DBO',\n",
    "    role='ACCOUNTADMIN'\n",
    ")\n",
    "\n",
    "# Run a test query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
    "row = cursor.fetchone()\n",
    "print(\"Snowflake version:\", row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c0af24-5888-4593-a386-e6e6259a5e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      " \n",
      "Tables Loaded:\n",
      "ADMINISTRATIONS\n",
      "ADVANCEDIRECTIVES\n",
      "ALLERGY\n",
      "CHARGE\n",
      "DEMOGRAHPICS\n",
      "DEMOGRAPHICS\n",
      "DIAGNOSIS\n",
      "DISEASESTATUS\n",
      "ERX\n",
      "FAMILYHISTORY\n",
      "HOSPITALIZATION\n",
      "INSURANCE\n",
      "LABS\n",
      "ORDERS\n",
      "RADIOLOGY\n",
      "REFERRINGPROVIDER\n",
      "SOCIALHISTORY\n",
      "TRANSFUSION\n",
      "GRADESCALES\n",
      "SURGICALHISTORY\n",
      "PERFORMANCE\n",
      "VISIT\n",
      "BIOMARKERS\n",
      "TOXICITIES\n",
      "MEDICATIONLIST\n",
      "STAGING\n",
      "DATA_HISTORY\n",
      "PATIENT_LOCATION_HISTORY\n",
      "ORDER_CHARGE_HISTORY\n",
      "TREATMENT_CURRENT_HISTORY\n",
      "VITAL_SIGN_HISTORY\n",
      "TREATMENT_PREVIOUS_HISTORY\n",
      "clinical_trials_data_simple_exclusion\n",
      "clinical_trials_data_simple_inclusion\n",
      " \n",
      "Columns of ADMINISTRATIONS:\n",
      "Index(['clientid', 'administrationid', 'diagnosisid', 'doseadministered',\n",
      "       'doseapproved', 'drugname', 'duration', 'intent', 'endreason', 'form',\n",
      "       'targetdrugname', 'targetdrugshortname', 'targetdrugcategory', 'ndc',\n",
      "       'nodosestaken', 'orderedamount', 'ordereddate', 'administeredunits',\n",
      "       'targetadministeredunits', 'orderid', 'patientid', 'plannedcycles',\n",
      "       'providerid', 'orderhassignoff', 'orderstatus', 'regimen', 'route',\n",
      "       'targetroute', 'locationid', 'startdate', 'stopdate',\n",
      "       'transactiontimestamp', 'lineoftx', 'visitid', 'administrationdate',\n",
      "       'clinicalstudydrugind', 'clinicalstudyregimenind',\n",
      "       'compassionatecaredrugind', 'targetdiagnosiscode',\n",
      "       'targetdiagnosiscodesys', 'antineoplasticind',\n",
      "       'targetclinicalstudyregimenind'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ADVANCEDIRECTIVES:\n",
      "Index(['clientid', 'patientid', 'advancedirectiveid', 'dnr', 'lw', 'dpa',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ALLERGY:\n",
      "Index(['allergy', 'allergyid', 'allergyseverity', 'allergytype', 'clientid',\n",
      "       'onsetdate', 'patientid', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of CHARGE:\n",
      "Index(['clientid', 'patientid', 'chargeid', 'visitid', 'servicecode',\n",
      "       'servicecodedescription', 'billcdtype', 'providerid',\n",
      "       'orderingproviderid', 'locationid', 'units', 'servicedate',\n",
      "       'chargestatus', 'quantity', 'transactiontimestamp', 'icdhold',\n",
      "       'icdcode1', 'icdcode2', 'icdcode3', 'icdcode4', 'icdcode5', 'icdcode6',\n",
      "       'icdcode7', 'icdcode8', 'icdcode9', 'icdcode10', 'icdcode11'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DEMOGRAHPICS:\n",
      "Index(['RowID', 'clientid', 'patientid', 'patientmrn', 'patientssn',\n",
      "       'primaryphysicianid', 'dob', 'birthyear', 'age', 'dod', 'vitalstatus',\n",
      "       'gender', 'targetgender', 'race', 'targetrace', 'zip', 'zip3',\n",
      "       'preferredlang', 'address1', 'address2', 'city', 'state', 'targetstate',\n",
      "       'ethnicity', 'targetethnicity', 'locationid', 'registrationdate',\n",
      "       'transactiontimestamp', 'lastname', 'firstname', 'emailaddress',\n",
      "       'phonenumber', 'middlename', 'status', 'statusdate',\n",
      "       'TrialPatientIndicator', 'LogDate', 'DeathYear'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DEMOGRAPHICS:\n",
      "Index(['RowID', 'clientid', 'patientid', 'patientmrn', 'patientssn',\n",
      "       'primaryphysicianid', 'dob', 'birthyear', 'age', 'dod', 'vitalstatus',\n",
      "       'gender', 'targetgender', 'race', 'targetrace', 'zip', 'zip3',\n",
      "       'preferredlang', 'address1', 'address2', 'city', 'state', 'targetstate',\n",
      "       'ethnicity', 'targetethnicity', 'locationid', 'registrationdate',\n",
      "       'transactiontimestamp', 'lastname', 'firstname', 'emailaddress',\n",
      "       'phonenumber', 'middlename', 'status', 'statusdate',\n",
      "       'TrialPatientIndicator', 'LogDate', 'DeathYear'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DIAGNOSIS:\n",
      "Index(['clientid', 'patientid', 'diagnosisid', 'primaryflag', 'diagnosistype',\n",
      "       'diagnosisdescription', 'diagnosisdate', 'resolutiondate',\n",
      "       'patientstatus', 'metastaticindicator', 'transactiontimestamp',\n",
      "       'apprind', 'resolutiontyp', 'targeticd9description', 'targeticd9code',\n",
      "       'diagnosiscode', 'diagnosiscodesys', 'targetdiagnosiscode',\n",
      "       'targetdiagnosiscodesys', 'targetdiagnosisdescription',\n",
      "       'targetdetaileddiagnosisgroup', 'targetdiagnosisgroup',\n",
      "       'cancerdiagnosisind', 'diseaseid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DISEASESTATUS:\n",
      "Index(['clientid', 'diagnosisid', 'diseasestatusid', 'diseasestatus',\n",
      "       'patientid', 'locationid', 'statusdate', 'transactiontimestamp',\n",
      "       'visitid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ERX:\n",
      "Index(['clientid', 'erxid', 'erxtype', 'orderid', 'patientid', 'providerid',\n",
      "       'transactiontimestamp', 'pharmacyid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of FAMILYHISTORY:\n",
      "Index(['clientid', 'familyhistoryid', 'familyitem', 'familyvalue', 'patientid',\n",
      "       'recorddate', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of HOSPITALIZATION:\n",
      "Index(['clientid', 'patientid', 'hospitalizationid', 'startdate', 'enddate',\n",
      "       'reason', 'outcome', 'comment', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of INSURANCE:\n",
      "Index(['clientid', 'patientid', 'payer', 'payertype', 'targetpayertype',\n",
      "       'targetpayername', 'targetmedicareadvind', 'effectivedate',\n",
      "       'inactivedate', 'transactiontimestamp', 'primaryindicator',\n",
      "       'currentindicator', 'ismedicareadv', 'ismedicaresupp', 'ispartaonly',\n",
      "       'ispartbonly', 'ispartaandpartb', 'ispartdonly', 'ismanagedmedicaid',\n",
      "       'isacaplan', 'ismedicaremedicaid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of LABS:\n",
      "Index(['category', 'clientid', 'compflag', 'labid', 'maxnorm', 'minnorm',\n",
      "       'normal', 'orderid', 'diagnosisid', 'disease', 'panel', 'patientid',\n",
      "       'resultdate', 'test', 'testdate', 'testresult', 'testunits',\n",
      "       'transactiontimestamp', 'visitid', 'loinc', 'targettest',\n",
      "       'targettestunits', 'targetloinc'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ORDERS:\n",
      "Index(['clientid', 'diagnosisid', 'expectedstartdate', 'expectedstopdate',\n",
      "       'form', 'frequency', 'diagnosiscode', 'itemno', 'ndc', 'orderedamount',\n",
      "       'ordereddate', 'orderedunits', 'orderid', 'ordername', 'ordertype',\n",
      "       'orderstatus', 'patientid', 'plannedcycles', 'providerid', 'qtyperday',\n",
      "       'locationid', 'quantity', 'quantityunits', 'dayssupply', 'refill',\n",
      "       'regimen', 'relativedose', 'relativedoseuom', 'lineoftx', 'intent',\n",
      "       'route', 'strength', 'transactiontimestamp', 'visitid', 'orderstopdate',\n",
      "       'targetorderedunits', 'targetrelativeorderedunits', 'targetdrugname',\n",
      "       'targetdrugshortname', 'targetdrugcategory', 'targetroute',\n",
      "       'targetquantityunits', 'clinicalstudydrugind',\n",
      "       'clinicalstudyregimenind', 'compassionatecaredrugind',\n",
      "       'targetdiagnosiscode', 'targetdiagnosiscodesys', 'antineoplasticind',\n",
      "       'targetclinicalstudyregimenind'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of RADIOLOGY:\n",
      "Index(['clientid', 'patientid', 'radiologyid', 'visitid', 'visitdate',\n",
      "       'category', 'type', 'radiologyresult', 'mdinterpretation',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of REFERRINGPROVIDER:\n",
      "Index(['clientid', 'patientid', 'referringproviderid', 'providername',\n",
      "       'transactiontimestamp', 'providertype', 'specialty',\n",
      "       'referringprovidernpi', 'referringproviderupin'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of SOCIALHISTORY:\n",
      "Index(['clientid', 'patientid', 'recorddate', 'socialhistoryid', 'socialitem',\n",
      "       'socialvalue', 'transactiontimestamp', 'targetsocialitem',\n",
      "       'targetsocialvalue'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TRANSFUSION:\n",
      "Index(['clientid', 'patientid', 'transfusionid', 'transfusiondate',\n",
      "       'transfusiontype', 'units', 'comment', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of GRADESCALES:\n",
      "Index(['clientid', 'patientid', 'gradescaleid', 'gradescaledate',\n",
      "       'gradescalename', 'result', 'transactiontimestamp', 'documentid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of SURGICALHISTORY:\n",
      "Index(['clientid', 'patientid', 'surgerydate', 'surgeryid', 'surgicalsite',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of PERFORMANCE:\n",
      "Index(['clientid', 'patientid', 'performancedate', 'performanceid',\n",
      "       'performancescale', 'visitid', 'performancevalue',\n",
      "       'targetperformancescale', 'targetperformancevalue',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of VISIT:\n",
      "Index(['clientid', 'patientid', 'visitid', 'visittype', 'visitdate',\n",
      "       'transactiontimestamp', 'providerid', 'diagnosisid', 'locationid',\n",
      "       'visitdesc'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of BIOMARKERS:\n",
      "Index(['category', 'clientid', 'labid', 'diagnosisid', 'patientid',\n",
      "       'resultdate', 'test', 'testdate', 'testresult', 'testunits',\n",
      "       'transactiontimestamp', 'targettest', 'targettestunits', 'targetloinc',\n",
      "       'targettestresult'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TOXICITIES:\n",
      "Index(['clientid', 'patientid', 'locationid', 'toxicity', 'toxicitydate',\n",
      "       'toxicitygrade', 'toxicityid', 'transactiontimestamp', 'visitid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of MEDICATIONLIST:\n",
      "Index(['clientid', 'patientid', 'medicationid', 'ordereddate',\n",
      "       'medicationtype', 'medicationname', 'targetdrugname',\n",
      "       'targetdrugshortname', 'targetdrugcategory', 'sourcedrugkey',\n",
      "       'sourcedrugvalue', 'ndc', 'gcn', 'units', 'targetunits', 'frequency',\n",
      "       'targetroute', 'transactiontimestamp', 'qtyperday', 'quantity',\n",
      "       'refill', 'medicationstopdate', 'verifydate', 'externalind'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of STAGING:\n",
      "Index(['clientid', 'patientid', 'diagnosisid', 'stagingsystem', 'stageid',\n",
      "       'stagingdate', 'stage', 'stagebasis', 't', 'n', 'm', 'g', 'histology',\n",
      "       'transactiontimestamp', 'critdesc', 'morphology', 'locationid', 'grade',\n",
      "       'targetstage', 'targett', 'targetn', 'targetm', 'targethistology',\n",
      "       'targetgleasonscore', 'histopathology'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DATA_HISTORY:\n",
      "Index(['srowid', 'snoteid', 'sgroupid', 'spatientid', 'dservicedate', 'sfrom',\n",
      "       'sctltype', 'sdataname', 'sdatavalue'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of PATIENT_LOCATION_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'slocation', 'dservicedate',\n",
      "       'dstatuschangeddate', 'sstatuschangedbyuid', 'sstatusreprowid',\n",
      "       'dstatusdeleteddate', 'sstatusdeletedbyuid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ORDER_CHARGE_HISTORY:\n",
      "Index(['srowid', 'saccountno', 'sgroupid', 'spatientid', 'sorderid', 'soidext',\n",
      "       'slocationid', 'sdescription', 'fsequence', 'sorderdose', 'sroute',\n",
      "       'sduration', 'ddatetime', 'sicdcode', 'schargetype', 'schargecode',\n",
      "       'fbillingunits', 'fquantity', 'sthisdose', 'scomment', 'ssignoffuid',\n",
      "       'dsignoffdate', 'ssupersedeuid', 'dsupersededate', 'sorderstatus',\n",
      "       'schargestatus', 'dstoptime', 'dstarttime', 'shideuid', 'dhidedt',\n",
      "       'istatus', 'dstatuschangeddate', 'sstatuschangedbyuid',\n",
      "       'sstatusreprowid', 'sdoseunits', 'sbuunits', 'ssupervisingmduid',\n",
      "       'sorderingmduid', 'sbagnum', 'smodifiers', 'dstatusdeleteddate',\n",
      "       'sstatusdeletedbyuid', 'sreferringmdid', 'sreferralauth', 'spriorauth',\n",
      "       'sicd10code', 'saddtcodes', 'sndc', 'sndcuom', 'fndcqty'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TREATMENT_CURRENT_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'stype', 'ddate', 'ddateend',\n",
      "       'sintent', 'svalue', 'svalue2', 'soutcome', 'dstatuschangeddate',\n",
      "       'sstatuschangedbyuid', 'sstatusreprowid', 'dstatusdeleteddate',\n",
      "       'sstatusdeletedbyuid', 'stxdocuid', 'shospmdid', 'sunknownptinfo',\n",
      "       'streatmenthistoryid', 'lsnomedcode'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of VITAL_SIGN_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'ddatetime', 'scode', 'svalue',\n",
      "       'sunits', 'flowerlimit', 'fupperlimit', 'dstatuschangeddate',\n",
      "       'sstatuschangedbyuid', 'slimits', 'sstatusreprowid',\n",
      "       'dstatusdeleteddate', 'sstatusdeletedbyuid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TREATMENT_PREVIOUS_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'stype', 'ddate', 'ddateend',\n",
      "       'sintent', 'svalue', 'svalue2', 'soutcome', 'dstatuschangeddate',\n",
      "       'sstatuschangedbyuid', 'sstatusreprowid', 'dstatusdeleteddate',\n",
      "       'sstatusdeletedbyuid', 'lsnomedcode'],\n",
      "      dtype='object')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "######################################## Load Data ########################################\n",
    "\n",
    "# Get sample patient ids\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
    "    ORDER BY RANDOM()\n",
    "\"\"\")\n",
    "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
    "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'DBO'\n",
    "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
    "    AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all the table names\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "#print(tables)\n",
    "\n",
    "# Create a dictionary to hold each table as a DataFrame\n",
    "table_dataframes = {}\n",
    "table_dataframes_spat = {}\n",
    "\n",
    "for table in tables:\n",
    "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
    "    \"\"\")\n",
    "    \n",
    "    columns = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    # If 'patientid' is a column, proceed to query the table\n",
    "    if 'patientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "    # If 'spatientid' is a column, proceed to query the table\n",
    "    if 'spatientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results_spat = cursor.fetchall()\n",
    "        columns_spat = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
    "\n",
    "# Merge table_dataframes_spat into table_dataframes_pat\n",
    "table_dataframes.update(table_dataframes_spat)\n",
    "\n",
    "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
    "print(\"Data Loaded Successfully!\")\n",
    "print(\" \")\n",
    "print(\"Tables Loaded:\")\n",
    "for table, df in table_dataframes.items():\n",
    "    print(f\"{table}\")\n",
    "    #print(df.head())\n",
    "\n",
    "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
    "for table, df in table_dataframes.items():\n",
    "    globals()[table] = df\n",
    "\n",
    "# Now you can access the DataFrames as individual variables:\n",
    "# print(ADMINISTRATIONS.head())\n",
    "\n",
    "# Bring in clinical trial data\n",
    "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
    "clinical_trials_incl = pd.read_csv('bonecancer_incl.csv')\n",
    "print(\"clinical_trials_data_simple_exclusion\")\n",
    "print(\"clinical_trials_data_simple_inclusion\")\n",
    "print(\" \")\n",
    "\n",
    "def print_columns_of_dict_of_dfs(df_dict):\n",
    "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
    "\n",
    "    for df_name, df in df_dict.items():\n",
    "        print(f\"Columns of {df_name}:\")\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "# Call the function to print the columns\n",
    "print_columns_of_dict_of_dfs(table_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112b909a-3fe7-4a3a-bb29-0ff963fdacf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete!\n"
     ]
    }
   ],
   "source": [
    "######################################## Feature Engineering ########################################\n",
    "\n",
    "# Convert non-numeric values to NaN\n",
    "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
    "\n",
    "# Now, convert the column to integers (NaNs will remain as NaN)\n",
    "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
    "print(\"Feature Engineering Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6c4807-c0a9-4eac-827a-0c2a1960f310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Trial_Name', 'Trial_ID', 'Inclusion_Criteria'], dtype='object')\n",
      "      RowID clientid                             patientid patientmrn  \\\n",
      "0    112304   CA0026  D6288764-EBAB-429D-9D6E-BA5152340FDD       None   \n",
      "1    158902   CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "2       924   CA0026  A552A6C5-63DB-4152-B0E3-4C1A94C9CF27       None   \n",
      "3    109938   CA0026  ECCE7682-F192-4E4B-8915-D3808F81E60E       None   \n",
      "4    131886   CA0026  B995B177-DA99-4BEF-9818-8E40DCD9841D       None   \n",
      "..      ...      ...                                   ...        ...   \n",
      "995     148   CA0026  9D1DAE72-E47F-453C-AF06-12AA2B97855C       None   \n",
      "996     228   CA0026  E393B5A7-862D-43DD-97A2-4B2075FBD297       None   \n",
      "997     398   CA0026  F90AA3C5-D2D7-4A6E-AFC5-024A1F912112       None   \n",
      "998     878   CA0026  BE19FCC3-3107-400D-9C0B-1A6C3ADB8D5E       None   \n",
      "999     275   CA0026  F124E3E2-C129-4FA2-8144-BF11CEC44CFB       None   \n",
      "\n",
      "    patientssn         primaryphysicianid   dob  birthyear  age   dod  ...  \\\n",
      "0         None  PH_2E0C6FDB8CA0035D2FABD0  None     1944.0   79  None  ...   \n",
      "1         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "2         None         UID_MA206161585_30  None     1973.0   50  None  ...   \n",
      "3         None  PH_82AFB13F99200B0A05DAD7  None     1981.0   42  None  ...   \n",
      "4         None  PH_B124FEEF1BE70F214EB8C8  None     1960.0   63  None  ...   \n",
      "..         ...                        ...   ...        ...  ...   ...  ...   \n",
      "995       None                       None  None        NaN   99  None  ...   \n",
      "996       None                       None  None        NaN   97  None  ...   \n",
      "997       None                       None  None        NaN   92  None  ...   \n",
      "998       None                       None  None        NaN  117  None  ...   \n",
      "999       None                       None  None        NaN   97  None  ...   \n",
      "\n",
      "     lastname firstname emailaddress phonenumber middlename    status  \\\n",
      "0        None      None         None        None       None  Deceased   \n",
      "1        None      None         None        None       None  Deceased   \n",
      "2        None      None         None        None       None  Deceased   \n",
      "3        None      None         None        None       None  Deceased   \n",
      "4        None      None         None        None       None  Deceased   \n",
      "..        ...       ...          ...         ...        ...       ...   \n",
      "995      None      None         None        None       None    Active   \n",
      "996      None      None         None        None       None    Active   \n",
      "997      None      None         None        None       None    Active   \n",
      "998      None      None         None        None       None    Active   \n",
      "999      None      None         None        None       None    Active   \n",
      "\n",
      "             statusdate TrialPatientIndicator    LogDate DeathYear  \n",
      "0   2022-08-31 12:04:27                   Yes 2024-02-12    2022.0  \n",
      "1   2022-12-23 18:18:43                   Yes 2024-02-12    2022.0  \n",
      "2   2022-01-17 13:37:13                    No 2024-02-12    2022.0  \n",
      "3   2023-11-08 13:57:03                   Yes 2024-02-12    2022.0  \n",
      "4   2022-09-19 12:45:19                   Yes 2024-02-12    2022.0  \n",
      "..                  ...                   ...        ...       ...  \n",
      "995                 NaT                    No 2024-02-12       NaN  \n",
      "996                 NaT                    No 2024-02-12       NaN  \n",
      "997                 NaT                    No 2024-02-12       NaN  \n",
      "998                 NaT                    No 2024-02-12       NaN  \n",
      "999                 NaT                    No 2024-02-12       NaN  \n",
      "\n",
      "[1000 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################## Quality Check ########################################\n",
    "print(clinical_trials_incl.columns)\n",
    "print(DEMOGRAPHICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7865d0fd-f717-453e-a2fc-88c5dd035db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "993\n",
      "      RowID clientid_x                             patientid patientmrn  \\\n",
      "918     289     CA0026  1C18C7F0-A512-40EF-AD48-B934521F9C7B       None   \n",
      "1246    436     CA0026  0CA1BC14-02F2-47BC-B8B1-7EF62566D7D4       None   \n",
      "1247    436     CA0026  0CA1BC14-02F2-47BC-B8B1-7EF62566D7D4       None   \n",
      "2459    827     CA0026  01DE42C6-D20D-4BF8-A6DE-AA65AE7512BC       None   \n",
      "2478    274     CA0026  771F10EB-EB2F-4D0D-BC16-340C18C975EF       None   \n",
      "3180    494     CA0026  11C1721B-F992-4E34-8AC1-50405BA0E6A5       None   \n",
      "3255    195     CA0026  5A1271D8-B7FD-4999-BCFF-35D3DD924D6C       None   \n",
      "3256    195     CA0026  5A1271D8-B7FD-4999-BCFF-35D3DD924D6C       None   \n",
      "3272    195     CA0026  5A1271D8-B7FD-4999-BCFF-35D3DD924D6C       None   \n",
      "3273    195     CA0026  5A1271D8-B7FD-4999-BCFF-35D3DD924D6C       None   \n",
      "\n",
      "     patientssn         primaryphysicianid   dob  birthyear  age   dod  ...  \\\n",
      "918        None         UID_Tz419171991_39  None        NaN   92  None  ...   \n",
      "1246       None         UID_MA206161585_58  None     1965.0   58  None  ...   \n",
      "1247       None         UID_MA206161585_58  None     1965.0   58  None  ...   \n",
      "2459       None  PH_2E0C6FDB8CA0035D2FABD0  None     1976.0   47  None  ...   \n",
      "2478       None  PH_4F92721C0EAD0F3B9B746C  None     1977.0   46  None  ...   \n",
      "3180       None         UID_ME375893116_15  None     1981.0   42  None  ...   \n",
      "3255       None  PH_82AFB13F99200B0A05DAD7  None     1977.0   46  None  ...   \n",
      "3256       None  PH_82AFB13F99200B0A05DAD7  None     1977.0   46  None  ...   \n",
      "3272       None  PH_82AFB13F99200B0A05DAD7  None     1977.0   46  None  ...   \n",
      "3273       None  PH_82AFB13F99200B0A05DAD7  None     1977.0   46  None  ...   \n",
      "\n",
      "      diagnosiscode diagnosiscodesys targetdiagnosiscode  \\\n",
      "918           171.8         ICD-9-CM               171.8   \n",
      "1246          C41.0        ICD-10-CM               C41.0   \n",
      "1247          C41.0        ICD-10-CM               C41.0   \n",
      "2459          C49.9        ICD-10-CM               C49.9   \n",
      "2478         C49.A2        ICD-10-CM              C49.A2   \n",
      "3180         C40.02        ICD-10-CM              C40.02   \n",
      "3255          C49.9        ICD-10-CM               C49.9   \n",
      "3256          C49.9        ICD-10-CM               C49.9   \n",
      "3272          C49.9        ICD-10-CM               C49.9   \n",
      "3273          C49.9        ICD-10-CM               C49.9   \n",
      "\n",
      "     targetdiagnosiscodesys  \\\n",
      "918                ICD-9-CM   \n",
      "1246              ICD-10-CM   \n",
      "1247              ICD-10-CM   \n",
      "2459              ICD-10-CM   \n",
      "2478              ICD-10-CM   \n",
      "3180              ICD-10-CM   \n",
      "3255              ICD-10-CM   \n",
      "3256              ICD-10-CM   \n",
      "3272              ICD-10-CM   \n",
      "3273              ICD-10-CM   \n",
      "\n",
      "                             targetdiagnosisdescription  \\\n",
      "918   Malignant neoplasm of other specified sites of...   \n",
      "1246      Malignant neoplasm of bones of skull and face   \n",
      "1247      Malignant neoplasm of bones of skull and face   \n",
      "2459  Malignant neoplasm of connective and soft tiss...   \n",
      "2478          Gastrointestinal stromal tumor of stomach   \n",
      "3180  Malignant neoplasm of scapula and long bones o...   \n",
      "3255  Malignant neoplasm of connective and soft tiss...   \n",
      "3256  Malignant neoplasm of connective and soft tiss...   \n",
      "3272  Malignant neoplasm of connective and soft tiss...   \n",
      "3273  Malignant neoplasm of connective and soft tiss...   \n",
      "\n",
      "                    targetdetaileddiagnosisgroup        targetdiagnosisgroup  \\\n",
      "918   Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "1246  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "1247  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "2459  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "2478  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "3180  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "3255  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "3256  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "3272  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "3273  Cancer of other bone and connective tissue  Bone and connective tissue   \n",
      "\n",
      "     cancerdiagnosisind            diseaseid Expert_Decision_Disease  \n",
      "918                   Y  4344070510199424431                       1  \n",
      "1246                  Y                 None                       1  \n",
      "1247                  Y                 None                       1  \n",
      "2459                  Y                 None                       1  \n",
      "2478                  Y   DID_KI879704700_93                       1  \n",
      "3180                  Y                 None                       1  \n",
      "3255                  Y               100255                       1  \n",
      "3256                  Y               100255                       1  \n",
      "3272                  Y               100255                       1  \n",
      "3273                  Y               100255                       1  \n",
      "\n",
      "[10 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################## Build Mock Expert Decision ########################################\n",
    "# Perform the LEFT JOIN\n",
    "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
    "\n",
    "# Filter using \"LIKE\" equivalent\n",
    "eligible = merged_df[\n",
    "    # (merged_df['age'] >= 18) &\n",
    "    # (merged_df['gender'] == 'Female') &\n",
    "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('bone', case=False, na=False)) &\n",
    "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
    "]\n",
    "\n",
    "# # For evaluation metrics later\n",
    "# eligible['Expert_Decision_Age'] = 1\n",
    "# eligible['Expert_Decision_Gender'] = 1\n",
    "eligible['Expert_Decision_Disease'] = 1\n",
    "\n",
    "#distinct_count = eligible['patientid'].nunique()\n",
    "\n",
    "# Extract patient IDs that match the expert's eligibility criteria\n",
    "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
    "\n",
    "# Get patient IDs that are not in the eligible list\n",
    "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
    "\n",
    "print(len(eligible_patient_ids))\n",
    "print(len(ineligible_patient_ids))\n",
    "\n",
    "print(eligible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413bca5f-ef11-4c9d-8688-6e3fef8d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible.to_csv('test_eligible_breast.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea0ed51-9c15-41a8-830a-154b5a8f11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: breast cancer, Label: DISEASE\n",
      "Entity: Tamoxifen, Label: CHEMICAL\n",
      "Entity: 18 years old, Label: AGE\n",
      "Entity: female, Label: GENDER\n"
     ]
    }
   ],
   "source": [
    "# ######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - 1 line of text, model testing ########################################\n",
    "\n",
    "# ### Test to apply to 1 line of text\n",
    "# ### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# # Load the MedSpaCy model\n",
    "# nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# # Process your text\n",
    "# text = \"The patient is a female 18 years old and was diagnosed with breast cancer and prescribed Tamoxifen.\"\n",
    "\n",
    "# # Function to extract entities and labels\n",
    "# def extract_entities(text):\n",
    "#     doc = nlp(text)\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "#     # Custom check for age-related information (e.g., \"18 years old\")\n",
    "#     age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "#     age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "#     # If age-related information is found, add it to the entities with the correct label\n",
    "#     for age in age_matches:\n",
    "#         entities.append((f\"{age} years old\", 'AGE'))\n",
    "    \n",
    "#     # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "#     gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "#     # Check for the first gender-related term match (female first, then male)\n",
    "#     gender_found = False\n",
    "#     for gender in gender_keywords:\n",
    "#         match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "#         if match:\n",
    "#             entities.append((match.group(), 'GENDER'))\n",
    "#             break  # Once a match is found, stop further checking\n",
    "\n",
    "#     return entities\n",
    "\n",
    "# # Display named entities and custom additions\n",
    "# entities = extract_entities(text)\n",
    "# for ent in entities:\n",
    "#     print(f\"Entity: {ent[0]}, Label: {ent[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e491783-7d24-49d8-a9ee-2a0963cd335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial_Name  Trial_ID          Inclusion_Criteria Category\n",
      "0  Test_Trial       123            Aged 18 or over.      AGE\n",
      "1  Test_Trial       123                      Female   GENDER\n",
      "2  Test_Trial       123  Diagnosed with Bone Cancer  DISEASE\n"
     ]
    }
   ],
   "source": [
    "######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - Clinical Trial Dataframe ########################################\n",
    "\n",
    "### Apply to a dataframe of trial data\n",
    "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# Load the MedSpaCy model\n",
    "nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# Function to extract entities and labels\n",
    "def extract_entities(text):\n",
    "    # Process the text through the NLP model\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # Custom check for age-related information (e.g., \"18 years old\")\n",
    "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If age-related information is found, add it to the entities with the correct label\n",
    "    for age in age_matches:\n",
    "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
    "    \n",
    "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "    # Check for the first gender-related term match (female first, then male)\n",
    "    gender_found = False\n",
    "    for gender in gender_keywords:\n",
    "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            entities.append((match.group(), 'GENDER'))\n",
    "            break  # Once a match is found, stop further checking\n",
    "\n",
    "    # Extract the unique labels to avoid duplicates and return them\n",
    "    unique_labels = set([label for _, label in entities])\n",
    "    return list(unique_labels)\n",
    "\n",
    "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
    "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1a0444-d109-4fed-866d-cd0445090f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial_Name  Trial_ID          Inclusion_Criteria Category  \\\n",
      "0  Test_Trial       123            Aged 18 or over.      AGE   \n",
      "1  Test_Trial       123                      Female   GENDER   \n",
      "2  Test_Trial       123  Diagnosed with Bone Cancer  DISEASE   \n",
      "\n",
      "                           Source_Columns  \n",
      "0                        DEMOGRAHPICS.age  \n",
      "1                     DEMOGRAHPICS.gender  \n",
      "2  DIAGNOSIS.targetdetaileddiagnosisgroup  \n"
     ]
    }
   ],
   "source": [
    "######################################## Use Fuzzy: Find columns in Patient Data that match Trial Inclusion Criteria ########################################\n",
    "\n",
    "# Function to find exact matches and fuzzy matches\n",
    "def find_matching_columns(category, dict_of_dfs, fuzzy_threshold=80):\n",
    "    if category.lower() == 'disease':\n",
    "        return ['DIAGNOSIS.targetdetaileddiagnosisgroup']\n",
    "    \n",
    "    # Step 1: Find exact matches (case-insensitive)\n",
    "    exact_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        if category.lower() in [col.lower() for col in df.columns]:\n",
    "            exact_column = next(col for col in df.columns if col.lower() == category.lower())\n",
    "            exact_matches.append(f'{df_name}.{exact_column}')\n",
    "            return exact_matches  # Return immediately after finding an exact match\n",
    "    \n",
    "    # Step 2: If no exact match, find fuzzy matches\n",
    "    fuzzy_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        columns = df.columns\n",
    "        for column in columns:\n",
    "            score = process.extractOne(category, [column])  # Compare category with each column\n",
    "            if score and score[1] >= fuzzy_threshold:  # If score is above threshold\n",
    "                fuzzy_matches.append(f'{df_name}.{column}')\n",
    "    \n",
    "    return fuzzy_matches\n",
    "\n",
    "# Loop through the clinical_trials_incl DataFrame and apply matching function\n",
    "def add_source_columns(clinical_trials_incl, table_dataframes):\n",
    "    source_columns_list = []\n",
    "    \n",
    "    for index, row in clinical_trials_incl.iterrows():\n",
    "        category = row['Category']\n",
    "        matching_columns = find_matching_columns(category, table_dataframes)\n",
    "        \n",
    "        # If there are multiple matches, list them, else return 'No match'\n",
    "        if matching_columns:\n",
    "            source_columns_list.append(', '.join(matching_columns))\n",
    "        else:\n",
    "            source_columns_list.append('No match')\n",
    "    \n",
    "    clinical_trials_incl['Source_Columns'] = source_columns_list\n",
    "    return clinical_trials_incl\n",
    "\n",
    "# Apply the function to the clinical_trials_incl DataFrame\n",
    "clinical_trials_incl_ner = add_source_columns(clinical_trials_incl, table_dataframes)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl_ner)\n",
    "\n",
    "######################### Now the clinical trial data is ready. #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f6deb0-9a73-49fe-9075-a8f3bd33ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Patient_ID  Trial_Name  Trial_ID  \\\n",
      "0     2D6D0A37-E044-4D5A-85A8-0331B753A3F2  Test_Trial       123   \n",
      "1     2D6D0A37-E044-4D5A-85A8-0331B753A3F2  Test_Trial       123   \n",
      "2     2D6D0A37-E044-4D5A-85A8-0331B753A3F2  Test_Trial       123   \n",
      "3     86E11975-50A1-4B40-9424-040FDD087809  Test_Trial       123   \n",
      "4     51D81E7C-D95C-4338-827D-E8DA084F77C7  Test_Trial       123   \n",
      "...                                    ...         ...       ...   \n",
      "4377  4AEAE5F0-9EC7-4B55-AC30-5D8C5A16250D  Test_Trial       123   \n",
      "4378  381BC62B-F71E-435E-87F4-B5BB88ABC4C2  Test_Trial       123   \n",
      "4379  0C92FCC0-2D67-4058-B943-644157E00191  Test_Trial       123   \n",
      "4380  0C92FCC0-2D67-4058-B943-644157E00191  Test_Trial       123   \n",
      "4381  0C92FCC0-2D67-4058-B943-644157E00191  Test_Trial       123   \n",
      "\n",
      "              Inclusion_Criteria Category  \\\n",
      "0     Diagnosed with Bone Cancer  DISEASE   \n",
      "1     Diagnosed with Bone Cancer  DISEASE   \n",
      "2     Diagnosed with Bone Cancer  DISEASE   \n",
      "3     Diagnosed with Bone Cancer  DISEASE   \n",
      "4     Diagnosed with Bone Cancer  DISEASE   \n",
      "...                          ...      ...   \n",
      "4377  Diagnosed with Bone Cancer  DISEASE   \n",
      "4378  Diagnosed with Bone Cancer  DISEASE   \n",
      "4379  Diagnosed with Bone Cancer  DISEASE   \n",
      "4380  Diagnosed with Bone Cancer  DISEASE   \n",
      "4381  Diagnosed with Bone Cancer  DISEASE   \n",
      "\n",
      "                               Source_Column  \\\n",
      "0     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "1     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "2     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "3     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "...                                      ...   \n",
      "4377  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4378  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4379  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4380  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4381  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "\n",
      "                               Source_Value  Match_Percentage patientid  \\\n",
      "0     Other benign hematological conditions          9.938017       NaN   \n",
      "1     Other benign hematological conditions          9.938017       NaN   \n",
      "2                                      None          0.000000       NaN   \n",
      "3              Secondary malignant neoplasm         36.300415       NaN   \n",
      "4     Other benign hematological conditions          9.938017       NaN   \n",
      "...                                     ...               ...       ...   \n",
      "4377                                   None          0.000000       NaN   \n",
      "4378                                   None          0.000000       NaN   \n",
      "4379                         Other leukemia         44.310614       NaN   \n",
      "4380       Vascular disease or complication         17.248298       NaN   \n",
      "4381                                   None          0.000000       NaN   \n",
      "\n",
      "     targetdetaileddiagnosisgroup  Expert_Decision_Disease  \n",
      "0                             NaN                        0  \n",
      "1                             NaN                        0  \n",
      "2                             NaN                        0  \n",
      "3                             NaN                        0  \n",
      "4                             NaN                        0  \n",
      "...                           ...                      ...  \n",
      "4377                          NaN                        0  \n",
      "4378                          NaN                        0  \n",
      "4379                          NaN                        0  \n",
      "4380                          NaN                        0  \n",
      "4381                          NaN                        0  \n",
      "\n",
      "[4382 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Load the SentenceTransformer model and biomedical NER pipeline\n",
    "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Load the biomedical-ner-all model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Function to extract biomedical entities using the NER pipeline\n",
    "def extract_entities(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    ner_results = biomedical_ner_pipeline(text)\n",
    "    return [entity['word'] for entity in ner_results]\n",
    "\n",
    "# Function to calculate match percentage using NER and cosine similarity\n",
    "def calculate_match_percentage(criteria, value):\n",
    "    if not criteria or not value:\n",
    "        return 0\n",
    "\n",
    "    # Extract entities from criteria and value\n",
    "    criteria_entities = extract_entities(criteria)\n",
    "    value_entities = extract_entities(value)\n",
    "\n",
    "    # Use extracted entities if available, otherwise fallback to raw text\n",
    "    if criteria_entities and value_entities:\n",
    "        criteria_text = \" \".join(criteria_entities)\n",
    "        value_text = \" \".join(value_entities)\n",
    "    else:\n",
    "        criteria_text = str(criteria)\n",
    "        value_text = str(value)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    criteria_embedding = transformer_model.encode([criteria_text])\n",
    "    value_embedding = transformer_model.encode([value_text])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
    "    return similarity_score[0][0] * 100\n",
    "\n",
    "# Function to match patients to trial criteria\n",
    "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
    "    results = []\n",
    "    all_patient_ids = set()\n",
    "\n",
    "    # Collect all unique patient IDs\n",
    "    for df in table_dataframes.values():\n",
    "         if 'patientid' in df.columns:\n",
    "            all_patient_ids.update(df['patientid'].unique())\n",
    "\n",
    "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
    "        trial_name = row['Trial_Name']\n",
    "        trial_id = row['Trial_ID']\n",
    "        inclusion_criteria = row['Inclusion_Criteria']\n",
    "        category = row['Category']\n",
    "        source_column = row['Source_Columns']\n",
    "        \n",
    "        table_name, column_name = source_column.split('.')\n",
    "        \n",
    "        if table_name in table_dataframes:\n",
    "            df = table_dataframes[table_name]\n",
    "            \n",
    "            if column_name in df.columns:\n",
    "                for patient_id in all_patient_ids:\n",
    "                    patient_rows = df[df['patientid'] == patient_id]\n",
    "                    \n",
    "                    if not patient_rows.empty:\n",
    "                        for _, patient_row in patient_rows.iterrows():\n",
    "                            source_value = patient_row[column_name]\n",
    "                            match_percentage = (\n",
    "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
    "                                if pd.notna(source_value) else 0\n",
    "                            )\n",
    "                            \n",
    "                            results.append({\n",
    "                                'Patient_ID': patient_id,\n",
    "                                'Trial_Name': trial_name,\n",
    "                                'Trial_ID': trial_id,\n",
    "                                'Inclusion_Criteria': inclusion_criteria,\n",
    "                                'Category': category,\n",
    "                                'Source_Column': source_column,\n",
    "                                'Source_Value': source_value,\n",
    "                                'Match_Percentage': match_percentage\n",
    "                            })\n",
    "                    else:\n",
    "                        # If no matching rows, include a null result\n",
    "                        results.append({\n",
    "                            'Patient_ID': patient_id,\n",
    "                            'Trial_Name': trial_name,\n",
    "                            'Trial_ID': trial_id,\n",
    "                            'Inclusion_Criteria': inclusion_criteria,\n",
    "                            'Category': category,\n",
    "                            'Source_Column': source_column,\n",
    "                            'Source_Value': None,\n",
    "                            'Match_Percentage': 0\n",
    "                        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Usage\n",
    "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
    "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
    "\n",
    "# Step 1: Filter the eligible DataFrame to only the necessary columns\n",
    "eligible_subset = eligible[['patientid', 'targetdetaileddiagnosisgroup', 'Expert_Decision_Disease']].drop_duplicates()\n",
    "\n",
    "# Step 2: Perform a left join on matched_disease with eligible_subset\n",
    "matched_disease = matched_disease.merge(\n",
    "    eligible_subset,\n",
    "    how='left',\n",
    "    left_on=['Patient_ID', 'Source_Value'],\n",
    "    right_on=['patientid', 'targetdetaileddiagnosisgroup'],\n",
    ")\n",
    "\n",
    "# Step 3: Fill missing values in Expert_Decision_Disease with 0\n",
    "matched_disease['Expert_Decision_Disease'] = matched_disease['Expert_Decision_Disease'].fillna(0).astype(int)\n",
    "\n",
    "# Step 4: (Optional) Debug the resulting DataFrame\n",
    "print(matched_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828d4d05-34be-4ef7-9e9e-03093c17f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_disease.to_csv('matched_disease_bone.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0adf96dc-e460-4791-93a5-764183bf0346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Category: DISEASE\n",
      "\n",
      "Patients Eligible: 6\n",
      "Patients Ineligible: 993\n",
      "\n",
      "Overall Results:\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4374    0]\n",
      " [   0    8]]\n",
      "\n",
      "Cohen's Kappa Score: 1.0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################## Evaluate by Inclusion Criteria ########################################\n",
    "\n",
    "eval_result_df_disease = matched_disease.copy()\n",
    "eval_result_df_disease['Model_Decision'] = eval_result_df_disease['Match_Percentage'].apply(lambda x: 1 if x > 60 else 0)\n",
    "\n",
    "# Calculate overall confusion matrix and kappa score\n",
    "y_true_disease = eval_result_df_disease['Expert_Decision_Disease']\n",
    "y_pred_disease = eval_result_df_disease['Model_Decision']\n",
    "\n",
    "conf_matrix_disease = confusion_matrix(y_true_disease, y_pred_disease)\n",
    "kappa_score_disease = cohen_kappa_score(y_true_disease, y_pred_disease)\n",
    "\n",
    "# Print overall results\n",
    "# Print summary of eligible and ineligible patients\n",
    "print(f\"Results for Category: DISEASE\")\n",
    "print(f\"\\nPatients Eligible: {len(eligible_patient_ids)}\")\n",
    "print(f\"Patients Ineligible: {len(ineligible_patient_ids)}\")\n",
    "print(\"\\nOverall Results:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_disease)\n",
    "print(\"\\nCohen's Kappa Score:\", kappa_score_disease)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cca6e2a-2685-4bed-9899-ac28f0ef57d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Load Data ########################################\n",
      "\n",
      "# Get sample patient ids\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
      "    ORDER BY RANDOM()\n",
      "\"\"\")\n",
      "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
      "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
      "\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT table_name\n",
      "    FROM information_schema.tables\n",
      "    WHERE table_schema = 'DBO'\n",
      "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
      "    AND table_type = 'BASE TABLE';\n",
      "\"\"\")\n",
      "\n",
      "# Fetch all the table names\n",
      "tables = [row[0] for row in cursor.fetchall()]\n",
      "#print(tables)\n",
      "\n",
      "# Create a dictionary to hold each table as a DataFrame\n",
      "table_dataframes = {}\n",
      "table_dataframes_spat = {}\n",
      "\n",
      "for table in tables:\n",
      "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
      "    cursor.execute(f\"\"\"\n",
      "        SELECT column_name\n",
      "        FROM information_schema.columns\n",
      "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
      "    \"\"\")\n",
      "    \n",
      "    columns = [row[0] for row in cursor.fetchall()]\n",
      "    \n",
      "    # If 'patientid' is a column, proceed to query the table\n",
      "    if 'patientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results = cursor.fetchall()\n",
      "        columns = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
      "\n",
      "    # If 'spatientid' is a column, proceed to query the table\n",
      "    if 'spatientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results_spat = cursor.fetchall()\n",
      "        columns_spat = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
      "\n",
      "# Merge table_dataframes_spat into table_dataframes_pat\n",
      "table_dataframes.update(table_dataframes_spat)\n",
      "\n",
      "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
      "print(\"Data Loaded Successfully!\")\n",
      "print(\" \")\n",
      "print(\"Tables Loaded:\")\n",
      "for table, df in table_dataframes.items():\n",
      "    print(f\"{table}\")\n",
      "    #print(df.head())\n",
      "\n",
      "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
      "for table, df in table_dataframes.items():\n",
      "    globals()[table] = df\n",
      "\n",
      "# Now you can access the DataFrames as individual variables:\n",
      "# print(ADMINISTRATIONS.head())\n",
      "\n",
      "# Bring in clinical trial data\n",
      "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
      "clinical_trials_incl = pd.read_csv('breastcancer_incl.csv')\n",
      "print(\"clinical_trials_data_simple_exclusion\")\n",
      "print(\"clinical_trials_data_simple_inclusion\")\n",
      "print(\" \")\n",
      "\n",
      "def print_columns_of_dict_of_dfs(df_dict):\n",
      "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
      "\n",
      "    for df_name, df in df_dict.items():\n",
      "        print(f\"Columns of {df_name}:\")\n",
      "        print(df.columns)\n",
      "        print(\"-\" * 20)\n",
      "\n",
      "# Call the function to print the columns\n",
      "print_columns_of_dict_of_dfs(table_dataframes)\n",
      "######################################## Check Environment ########################################\n",
      "import sys\n",
      "print(\"Python executable:\", sys.executable)\n",
      "print(\"Python version:\", sys.version)\n",
      "######################################## Install packages ########################################\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "# Create chunks\n",
      "import re\n",
      "\n",
      "# Model for NER\n",
      "import spacy \n",
      "from sklearn.cluster import KMeans\n",
      "import medspacy\n",
      "from medspacy.ner import TargetRule\n",
      "from thefuzz import fuzz, process\n",
      "\n",
      "#UMLSClient for NER\n",
      "import umls_api\n",
      "from umls_api_client import UMLS\n",
      "from quickumls import QuickUMLS\n",
      "\n",
      "# Use natural language processing (NLP) to extract keywords from the criteria\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "nltk.download('stopwords')\n",
      "nltk.download('punkt_tab')\n",
      "nltk.download('wordnet')\n",
      "from sentence_transformers import SentenceTransformer, util\n",
      "\n",
      "# Performance\n",
      "import sklearn\n",
      "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "\n",
      "import snowflake.connector\n",
      "######################################## Connect to Snowflake ########################################\n",
      "\n",
      "# Establish a connection\n",
      "conn = snowflake.connector.connect(\n",
      "    user='dana_george@hakkoda.io',\n",
      "    authenticator='externalbrowser',\n",
      "    account='ska04930.east-us-2.azure',\n",
      "    warehouse='DATASCIENCE_WH',\n",
      "    database='ONCOEMR_RAW_DEV',\n",
      "    schema='DBO',\n",
      "    role='ACCOUNTADMIN'\n",
      ")\n",
      "\n",
      "# Run a test query\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
      "row = cursor.fetchone()\n",
      "print(\"Snowflake version:\", row[0])\n",
      "######################################## Load Data ########################################\n",
      "\n",
      "# Get sample patient ids\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
      "    ORDER BY RANDOM()\n",
      "\"\"\")\n",
      "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
      "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
      "\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT table_name\n",
      "    FROM information_schema.tables\n",
      "    WHERE table_schema = 'DBO'\n",
      "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
      "    AND table_type = 'BASE TABLE';\n",
      "\"\"\")\n",
      "\n",
      "# Fetch all the table names\n",
      "tables = [row[0] for row in cursor.fetchall()]\n",
      "#print(tables)\n",
      "\n",
      "# Create a dictionary to hold each table as a DataFrame\n",
      "table_dataframes = {}\n",
      "table_dataframes_spat = {}\n",
      "\n",
      "for table in tables:\n",
      "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
      "    cursor.execute(f\"\"\"\n",
      "        SELECT column_name\n",
      "        FROM information_schema.columns\n",
      "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
      "    \"\"\")\n",
      "    \n",
      "    columns = [row[0] for row in cursor.fetchall()]\n",
      "    \n",
      "    # If 'patientid' is a column, proceed to query the table\n",
      "    if 'patientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results = cursor.fetchall()\n",
      "        columns = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
      "\n",
      "    # If 'spatientid' is a column, proceed to query the table\n",
      "    if 'spatientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results_spat = cursor.fetchall()\n",
      "        columns_spat = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
      "\n",
      "# Merge table_dataframes_spat into table_dataframes_pat\n",
      "table_dataframes.update(table_dataframes_spat)\n",
      "\n",
      "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
      "print(\"Data Loaded Successfully!\")\n",
      "print(\" \")\n",
      "print(\"Tables Loaded:\")\n",
      "for table, df in table_dataframes.items():\n",
      "    print(f\"{table}\")\n",
      "    #print(df.head())\n",
      "\n",
      "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
      "for table, df in table_dataframes.items():\n",
      "    globals()[table] = df\n",
      "\n",
      "# Now you can access the DataFrames as individual variables:\n",
      "# print(ADMINISTRATIONS.head())\n",
      "\n",
      "# Bring in clinical trial data\n",
      "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
      "clinical_trials_incl = pd.read_csv('breastcancer_incl.csv')\n",
      "print(\"clinical_trials_data_simple_exclusion\")\n",
      "print(\"clinical_trials_data_simple_inclusion\")\n",
      "print(\" \")\n",
      "\n",
      "def print_columns_of_dict_of_dfs(df_dict):\n",
      "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
      "\n",
      "    for df_name, df in df_dict.items():\n",
      "        print(f\"Columns of {df_name}:\")\n",
      "        print(df.columns)\n",
      "        print(\"-\" * 20)\n",
      "\n",
      "# Call the function to print the columns\n",
      "print_columns_of_dict_of_dfs(table_dataframes)\n",
      "######################################## Load Data ########################################\n",
      "\n",
      "# Get sample patient ids\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
      "    ORDER BY RANDOM()\n",
      "\"\"\")\n",
      "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
      "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
      "\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT table_name\n",
      "    FROM information_schema.tables\n",
      "    WHERE table_schema = 'DBO'\n",
      "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
      "    AND table_type = 'BASE TABLE';\n",
      "\"\"\")\n",
      "\n",
      "# Fetch all the table names\n",
      "tables = [row[0] for row in cursor.fetchall()]\n",
      "#print(tables)\n",
      "\n",
      "# Create a dictionary to hold each table as a DataFrame\n",
      "table_dataframes = {}\n",
      "table_dataframes_spat = {}\n",
      "\n",
      "for table in tables:\n",
      "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
      "    cursor.execute(f\"\"\"\n",
      "        SELECT column_name\n",
      "        FROM information_schema.columns\n",
      "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
      "    \"\"\")\n",
      "    \n",
      "    columns = [row[0] for row in cursor.fetchall()]\n",
      "    \n",
      "    # If 'patientid' is a column, proceed to query the table\n",
      "    if 'patientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results = cursor.fetchall()\n",
      "        columns = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
      "\n",
      "    # If 'spatientid' is a column, proceed to query the table\n",
      "    if 'spatientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results_spat = cursor.fetchall()\n",
      "        columns_spat = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
      "\n",
      "# Merge table_dataframes_spat into table_dataframes_pat\n",
      "table_dataframes.update(table_dataframes_spat)\n",
      "\n",
      "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
      "print(\"Data Loaded Successfully!\")\n",
      "print(\" \")\n",
      "print(\"Tables Loaded:\")\n",
      "for table, df in table_dataframes.items():\n",
      "    print(f\"{table}\")\n",
      "    #print(df.head())\n",
      "\n",
      "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
      "for table, df in table_dataframes.items():\n",
      "    globals()[table] = df\n",
      "\n",
      "# Now you can access the DataFrames as individual variables:\n",
      "# print(ADMINISTRATIONS.head())\n",
      "\n",
      "# Bring in clinical trial data\n",
      "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
      "clinical_trials_incl = pd.read_csv('breastcancer_incl.csv')\n",
      "print(\"clinical_trials_data_simple_exclusion\")\n",
      "print(\"clinical_trials_data_simple_inclusion\")\n",
      "print(\" \")\n",
      "\n",
      "def print_columns_of_dict_of_dfs(df_dict):\n",
      "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
      "\n",
      "    for df_name, df in df_dict.items():\n",
      "        print(f\"Columns of {df_name}:\")\n",
      "        print(df.columns)\n",
      "        print(\"-\" * 20)\n",
      "\n",
      "# Call the function to print the columns\n",
      "print_columns_of_dict_of_dfs(table_dataframes)\n",
      "######################################## Check Environment ########################################\n",
      "import sys\n",
      "print(\"Python executable:\", sys.executable)\n",
      "print(\"Python version:\", sys.version)\n",
      "######################################## Install packages ########################################\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "# Create chunks\n",
      "import re\n",
      "\n",
      "# Model for NER\n",
      "import spacy \n",
      "from sklearn.cluster import KMeans\n",
      "import medspacy\n",
      "from medspacy.ner import TargetRule\n",
      "from thefuzz import fuzz, process\n",
      "\n",
      "#UMLSClient for NER\n",
      "import umls_api\n",
      "from umls_api_client import UMLS\n",
      "from quickumls import QuickUMLS\n",
      "\n",
      "# Use natural language processing (NLP) to extract keywords from the criteria\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "nltk.download('stopwords')\n",
      "nltk.download('punkt_tab')\n",
      "nltk.download('wordnet')\n",
      "from sentence_transformers import SentenceTransformer, util\n",
      "\n",
      "# Performance\n",
      "import sklearn\n",
      "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "\n",
      "import snowflake.connector\n",
      "######################################## Connect to Snowflake ########################################\n",
      "\n",
      "# Establish a connection\n",
      "conn = snowflake.connector.connect(\n",
      "    user='dana_george@hakkoda.io',\n",
      "    authenticator='externalbrowser',\n",
      "    account='ska04930.east-us-2.azure',\n",
      "    warehouse='DATASCIENCE_WH',\n",
      "    database='ONCOEMR_RAW_DEV',\n",
      "    schema='DBO',\n",
      "    role='ACCOUNTADMIN'\n",
      ")\n",
      "\n",
      "# Run a test query\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
      "row = cursor.fetchone()\n",
      "print(\"Snowflake version:\", row[0])\n",
      "######################################## Load Data ########################################\n",
      "\n",
      "# Get sample patient ids\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
      "    ORDER BY RANDOM()\n",
      "\"\"\")\n",
      "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
      "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
      "\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT table_name\n",
      "    FROM information_schema.tables\n",
      "    WHERE table_schema = 'DBO'\n",
      "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
      "    AND table_type = 'BASE TABLE';\n",
      "\"\"\")\n",
      "\n",
      "# Fetch all the table names\n",
      "tables = [row[0] for row in cursor.fetchall()]\n",
      "#print(tables)\n",
      "\n",
      "# Create a dictionary to hold each table as a DataFrame\n",
      "table_dataframes = {}\n",
      "table_dataframes_spat = {}\n",
      "\n",
      "for table in tables:\n",
      "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
      "    cursor.execute(f\"\"\"\n",
      "        SELECT column_name\n",
      "        FROM information_schema.columns\n",
      "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
      "    \"\"\")\n",
      "    \n",
      "    columns = [row[0] for row in cursor.fetchall()]\n",
      "    \n",
      "    # If 'patientid' is a column, proceed to query the table\n",
      "    if 'patientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results = cursor.fetchall()\n",
      "        columns = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
      "\n",
      "    # If 'spatientid' is a column, proceed to query the table\n",
      "    if 'spatientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results_spat = cursor.fetchall()\n",
      "        columns_spat = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
      "\n",
      "# Merge table_dataframes_spat into table_dataframes_pat\n",
      "table_dataframes.update(table_dataframes_spat)\n",
      "\n",
      "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
      "print(\"Data Loaded Successfully!\")\n",
      "print(\" \")\n",
      "print(\"Tables Loaded:\")\n",
      "for table, df in table_dataframes.items():\n",
      "    print(f\"{table}\")\n",
      "    #print(df.head())\n",
      "\n",
      "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
      "for table, df in table_dataframes.items():\n",
      "    globals()[table] = df\n",
      "\n",
      "# Now you can access the DataFrames as individual variables:\n",
      "# print(ADMINISTRATIONS.head())\n",
      "\n",
      "# Bring in clinical trial data\n",
      "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
      "clinical_trials_incl = pd.read_csv('breastcancer_incl.csv')\n",
      "print(\"clinical_trials_data_simple_exclusion\")\n",
      "print(\"clinical_trials_data_simple_inclusion\")\n",
      "print(\" \")\n",
      "\n",
      "def print_columns_of_dict_of_dfs(df_dict):\n",
      "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
      "\n",
      "    for df_name, df in df_dict.items():\n",
      "        print(f\"Columns of {df_name}:\")\n",
      "        print(df.columns)\n",
      "        print(\"-\" * 20)\n",
      "\n",
      "# Call the function to print the columns\n",
      "print_columns_of_dict_of_dfs(table_dataframes)\n",
      "######################################## Feature Engineering ########################################\n",
      "\n",
      "# Convert non-numeric values to NaN\n",
      "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
      "\n",
      "# Now, convert the column to integers (NaNs will remain as NaN)\n",
      "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
      "print(\"Feature Engineering Complete!\")\n",
      "######################################## Quality Check ########################################\n",
      "print(clinical_trials_incl.columns)\n",
      "print(DEMOGRAPHICS)\n",
      "######################################## Build Mock Expert Decision ########################################\n",
      "# Perform the LEFT JOIN\n",
      "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
      "\n",
      "# Filter using \"LIKE\" equivalent\n",
      "eligible = merged_df[\n",
      "    # (merged_df['age'] >= 18) &\n",
      "    # (merged_df['gender'] == 'Female') &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('lung', case=False, na=False)) &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
      "]\n",
      "\n",
      "# # For evaluation metrics later\n",
      "# eligible['Expert_Decision_Age'] = 1\n",
      "# eligible['Expert_Decision_Gender'] = 1\n",
      "eligible['Expert_Decision_Disease'] = 1\n",
      "\n",
      "#distinct_count = eligible['patientid'].nunique()\n",
      "\n",
      "# Extract patient IDs that match the expert's eligibility criteria\n",
      "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
      "\n",
      "# Get patient IDs that are not in the eligible list\n",
      "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
      "\n",
      "print(len(eligible_patient_ids))\n",
      "print(len(ineligible_patient_ids))\n",
      "\n",
      "print(eligible)\n",
      "######################################## Build Mock Expert Decision ########################################\n",
      "# Perform the LEFT JOIN\n",
      "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
      "\n",
      "# Filter using \"LIKE\" equivalent\n",
      "eligible = merged_df[\n",
      "    # (merged_df['age'] >= 18) &\n",
      "    # (merged_df['gender'] == 'Female') &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('breast', case=False, na=False)) &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
      "]\n",
      "\n",
      "# # For evaluation metrics later\n",
      "# eligible['Expert_Decision_Age'] = 1\n",
      "# eligible['Expert_Decision_Gender'] = 1\n",
      "eligible['Expert_Decision_Disease'] = 1\n",
      "\n",
      "#distinct_count = eligible['patientid'].nunique()\n",
      "\n",
      "# Extract patient IDs that match the expert's eligibility criteria\n",
      "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
      "\n",
      "# Get patient IDs that are not in the eligible list\n",
      "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
      "\n",
      "print(len(eligible_patient_ids))\n",
      "print(len(ineligible_patient_ids))\n",
      "\n",
      "print(eligible)\n",
      "######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - Clinical Trial Dataframe ########################################\n",
      "\n",
      "### Apply to a dataframe of trial data\n",
      "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
      "\n",
      "# Load the MedSpaCy model\n",
      "nlp = spacy.load('en_ner_bc5cdr_md')\n",
      "\n",
      "# Function to extract entities and labels\n",
      "def extract_entities(text):\n",
      "    # Process the text through the NLP model\n",
      "    doc = nlp(text)\n",
      "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
      "\n",
      "    # Custom check for age-related information (e.g., \"18 years old\")\n",
      "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
      "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
      "    \n",
      "    # If age-related information is found, add it to the entities with the correct label\n",
      "    for age in age_matches:\n",
      "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
      "    \n",
      "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
      "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
      "    \n",
      "    # Check for the first gender-related term match (female first, then male)\n",
      "    gender_found = False\n",
      "    for gender in gender_keywords:\n",
      "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
      "        if match:\n",
      "            entities.append((match.group(), 'GENDER'))\n",
      "            break  # Once a match is found, stop further checking\n",
      "\n",
      "    # Extract the unique labels to avoid duplicates and return them\n",
      "    unique_labels = set([label for _, label in entities])\n",
      "    return list(unique_labels)\n",
      "\n",
      "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
      "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
      "\n",
      "# Display the updated DataFrame\n",
      "print(clinical_trials_incl)\n",
      "######################################## Use Fuzzy: Find columns in Patient Data that match Trial Inclusion Criteria ########################################\n",
      "\n",
      "# Function to find exact matches and fuzzy matches\n",
      "def find_matching_columns(category, dict_of_dfs, fuzzy_threshold=80):\n",
      "    if category.lower() == 'disease':\n",
      "        return ['DIAGNOSIS.targetdetaileddiagnosisgroup']\n",
      "    \n",
      "    # Step 1: Find exact matches (case-insensitive)\n",
      "    exact_matches = []\n",
      "    for df_name, df in dict_of_dfs.items():\n",
      "        if category.lower() in [col.lower() for col in df.columns]:\n",
      "            exact_column = next(col for col in df.columns if col.lower() == category.lower())\n",
      "            exact_matches.append(f'{df_name}.{exact_column}')\n",
      "            return exact_matches  # Return immediately after finding an exact match\n",
      "    \n",
      "    # Step 2: If no exact match, find fuzzy matches\n",
      "    fuzzy_matches = []\n",
      "    for df_name, df in dict_of_dfs.items():\n",
      "        columns = df.columns\n",
      "        for column in columns:\n",
      "            score = process.extractOne(category, [column])  # Compare category with each column\n",
      "            if score and score[1] >= fuzzy_threshold:  # If score is above threshold\n",
      "                fuzzy_matches.append(f'{df_name}.{column}')\n",
      "    \n",
      "    return fuzzy_matches\n",
      "\n",
      "# Loop through the clinical_trials_incl DataFrame and apply matching function\n",
      "def add_source_columns(clinical_trials_incl, table_dataframes):\n",
      "    source_columns_list = []\n",
      "    \n",
      "    for index, row in clinical_trials_incl.iterrows():\n",
      "        category = row['Category']\n",
      "        matching_columns = find_matching_columns(category, table_dataframes)\n",
      "        \n",
      "        # If there are multiple matches, list them, else return 'No match'\n",
      "        if matching_columns:\n",
      "            source_columns_list.append(', '.join(matching_columns))\n",
      "        else:\n",
      "            source_columns_list.append('No match')\n",
      "    \n",
      "    clinical_trials_incl['Source_Columns'] = source_columns_list\n",
      "    return clinical_trials_incl\n",
      "\n",
      "# Apply the function to the clinical_trials_incl DataFrame\n",
      "clinical_trials_incl_ner = add_source_columns(clinical_trials_incl, table_dataframes)\n",
      "\n",
      "# Display the updated DataFrame\n",
      "print(clinical_trials_incl_ner)\n",
      "\n",
      "######################### Now the clinical trial data is ready. #########################\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = []\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_rows = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_rows.empty:\n",
      "                        for _, patient_row in patient_rows.iterrows():\n",
      "                            source_value = patient_row[column_name]\n",
      "                            match_percentage = (\n",
      "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
      "                                if pd.notna(source_value) else 0\n",
      "                            )\n",
      "                            \n",
      "                            results.append({\n",
      "                                'Patient_ID': patient_id,\n",
      "                                'Trial_Name': trial_name,\n",
      "                                'Trial_ID': trial_id,\n",
      "                                'Inclusion_Criteria': inclusion_criteria,\n",
      "                                'Category': category,\n",
      "                                'Source_Column': source_column,\n",
      "                                'Source_Value': source_value,\n",
      "                                'Match_Percentage': match_percentage\n",
      "                            })\n",
      "                    else:\n",
      "                        # If no matching rows, include a null result\n",
      "                        results.append({\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': None,\n",
      "                            'Match_Percentage': 0\n",
      "                        })\n",
      "\n",
      "    # Convert results to a DataFrame\n",
      "    return pd.DataFrame(results)\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# Ensure column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "print(matched_disease)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
      "\n",
      "# Load the SentenceTransformer model and biomedical NER pipeline\n",
      "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
      "\n",
      "# Load the biomedical-ner-all model\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
      "\n",
      "# Function to extract biomedical entities using the NER pipeline\n",
      "def extract_entities(text):\n",
      "    if not text:\n",
      "        return []\n",
      "    ner_results = biomedical_ner_pipeline(text)\n",
      "    return [entity['word'] for entity in ner_results]\n",
      "\n",
      "# Function to calculate match percentage using NER and cosine similarity\n",
      "def calculate_match_percentage(criteria, value):\n",
      "    if not criteria or not value:\n",
      "        return 0\n",
      "\n",
      "    # Extract entities from criteria and value\n",
      "    criteria_entities = extract_entities(criteria)\n",
      "    value_entities = extract_entities(value)\n",
      "\n",
      "    # Use extracted entities if available, otherwise fallback to raw text\n",
      "    if criteria_entities and value_entities:\n",
      "        criteria_text = \" \".join(criteria_entities)\n",
      "        value_text = \" \".join(value_entities)\n",
      "    else:\n",
      "        criteria_text = str(criteria)\n",
      "        value_text = str(value)\n",
      "    \n",
      "    # Generate embeddings\n",
      "    criteria_embedding = transformer_model.encode([criteria_text])\n",
      "    value_embedding = transformer_model.encode([value_text])\n",
      "    \n",
      "    # Calculate cosine similarity\n",
      "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
      "    return similarity_score[0][0] * 100\n",
      "\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = []\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_rows = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_rows.empty:\n",
      "                        for _, patient_row in patient_rows.iterrows():\n",
      "                            source_value = patient_row[column_name]\n",
      "                            match_percentage = (\n",
      "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
      "                                if pd.notna(source_value) else 0\n",
      "                            )\n",
      "                            \n",
      "                            results.append({\n",
      "                                'Patient_ID': patient_id,\n",
      "                                'Trial_Name': trial_name,\n",
      "                                'Trial_ID': trial_id,\n",
      "                                'Inclusion_Criteria': inclusion_criteria,\n",
      "                                'Category': category,\n",
      "                                'Source_Column': source_column,\n",
      "                                'Source_Value': source_value,\n",
      "                                'Match_Percentage': match_percentage\n",
      "                            })\n",
      "                    else:\n",
      "                        # If no matching rows, include a null result\n",
      "                        results.append({\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': None,\n",
      "                            'Match_Percentage': 0\n",
      "                        })\n",
      "\n",
      "    # Convert results to a DataFrame\n",
      "    return pd.DataFrame(results)\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# Ensure column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "print(matched_disease)\n",
      "######################################## Evaluate by Inclusion Criteria ########################################\n",
      "\n",
      "eval_result_df_disease = matched_disease.copy()\n",
      "eval_result_df_disease['Model_Decision'] = eval_result_df_disease['Match_Percentage'].apply(lambda x: 1 if x > 95 else 0)\n",
      "\n",
      "# Calculate overall confusion matrix and kappa score\n",
      "y_true_disease = eval_result_df_disease['Expert_Decision_Disease']\n",
      "y_pred_disease = eval_result_df_disease['Model_Decision']\n",
      "\n",
      "conf_matrix_disease = confusion_matrix(y_true_disease, y_pred_disease)\n",
      "kappa_score_disease = cohen_kappa_score(y_true_disease, y_pred_disease)\n",
      "\n",
      "# Print overall results\n",
      "# Print summary of eligible and ineligible patients\n",
      "print(f\"Results for Category: DISEASE\")\n",
      "print(f\"\\nPatients Eligible: {len(eligible_patient_ids)}\")\n",
      "print(f\"Patients Ineligible: {len(ineligible_patient_ids)}\")\n",
      "print(\"\\nOverall Results:\")\n",
      "print(\"\\nConfusion Matrix:\")\n",
      "print(conf_matrix_disease)\n",
      "print(\"\\nCohen's Kappa Score:\", kappa_score_disease)\n",
      "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_mitsui_condapy310)",
   "language": "python",
   "name": "venv_mitsui_condapy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
