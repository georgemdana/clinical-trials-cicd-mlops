{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef112a06-1ff5-41a3-ab40-7ec260c1e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/bin/python\n",
      "Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:20) [Clang 17.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "######################################## Check Environment ########################################\n",
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420d431f-e164-4c22-9e4f-ad7b9e9ed80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################################## Install packages ########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create chunks\n",
    "import re\n",
    "\n",
    "# Model for NER\n",
    "import spacy \n",
    "from sklearn.cluster import KMeans\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "#UMLSClient for NER\n",
    "import umls_api\n",
    "from umls_api_client import UMLS\n",
    "from quickumls import QuickUMLS\n",
    "\n",
    "# Use natural language processing (NLP) to extract keywords from the criteria\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Performance\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fdc997-2323-400b-b5b5-e8b779cc070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://login.microsoftonline.com/bbaf0319-e615-416f-8870-f7eacf074b66/saml2?SAMLRequest=nZJBc5swEIX%2FCqOeAQkoxBrbGdeetNRO4tq4nfQmw%2BJoDBKRREj66yuwPZMekkNvGuntfk%2F7dnz9UlfOMyjNpZgg4mHkgMhlwcVhgnbZjXuFHG2YKFglBUzQK2h0PR1rVlcNnbXmUWzgqQVtHNtIaNo%2FTFCrBJVMc00Fq0FTk9Pt7HZFAw9TpjUoY3HoXFJoblmPxjTU97uu87rQk%2BrgBxhjH498q%2Boln9AbRPMxo1HSyFxWl5IX%2B6d3EMTHUY%2BwCktYnwu%2FcHEawUeU%2FUmk6bcsW7vr%2B22GnNnld3MpdFuD2oJ65jnsNquTAW0d6CPD0SjEHjBt3Fa7gcf%2BtAo8LWRXVuwIuayb1tjmnj35JRR%2BJQ%2FcjixdTFBz5IUisFvOH5L0YXW4N1%2FjYLWLqtvNkmTfTfsUhCpdxUmyXP7qfuTI%2BXkJOOgDTrVuIRV9rMZe4SByCXEDkpGQRiHFIy8eRb%2BRs7CxcsHMUHnxPvjwap4rqWVppKi4gMHlfs9KHJKRCzH57EYkLt2rqwS7ZQIsL3ES7ePY78ML0GmB6GBETf9zLGP%2FbZPzSt7ZlNLFWlY8f3VupKqZeT9E4pHhhhduOUgp1IxXs6JQoLUNs6pkN1fAjN18o1pA%2FvRE%2FXf3p38B&RelayState=58617 to authenticate...\n",
      "Snowflake version: 8.43.0\n"
     ]
    }
   ],
   "source": [
    "######################################## Connect to Snowflake ########################################\n",
    "\n",
    "# Establish a connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user='dana_george@hakkoda.io',\n",
    "    authenticator='externalbrowser',\n",
    "    account='ska04930.east-us-2.azure',\n",
    "    warehouse='DATASCIENCE_WH',\n",
    "    database='ONCOEMR_RAW_DEV',\n",
    "    schema='DBO',\n",
    "    role='ACCOUNTADMIN'\n",
    ")\n",
    "\n",
    "# Run a test query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
    "row = cursor.fetchone()\n",
    "print(\"Snowflake version:\", row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c0af24-5888-4593-a386-e6e6259a5e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      " \n",
      "Tables Loaded:\n",
      "ADMINISTRATIONS\n",
      "ADVANCEDIRECTIVES\n",
      "ALLERGY\n",
      "CHARGE\n",
      "DEMOGRAHPICS\n",
      "DEMOGRAPHICS\n",
      "DIAGNOSIS\n",
      "DISEASESTATUS\n",
      "ERX\n",
      "FAMILYHISTORY\n",
      "HOSPITALIZATION\n",
      "INSURANCE\n",
      "LABS\n",
      "ORDERS\n",
      "RADIOLOGY\n",
      "REFERRINGPROVIDER\n",
      "SOCIALHISTORY\n",
      "TRANSFUSION\n",
      "GRADESCALES\n",
      "SURGICALHISTORY\n",
      "PERFORMANCE\n",
      "VISIT\n",
      "BIOMARKERS\n",
      "TOXICITIES\n",
      "MEDICATIONLIST\n",
      "STAGING\n",
      "DATA_HISTORY\n",
      "PATIENT_LOCATION_HISTORY\n",
      "ORDER_CHARGE_HISTORY\n",
      "TREATMENT_CURRENT_HISTORY\n",
      "VITAL_SIGN_HISTORY\n",
      "TREATMENT_PREVIOUS_HISTORY\n",
      "clinical_trials_data_simple_exclusion\n",
      "clinical_trials_data_simple_inclusion\n",
      " \n",
      "Columns of ADMINISTRATIONS:\n",
      "Index(['clientid', 'administrationid', 'diagnosisid', 'doseadministered',\n",
      "       'doseapproved', 'drugname', 'duration', 'intent', 'endreason', 'form',\n",
      "       'targetdrugname', 'targetdrugshortname', 'targetdrugcategory', 'ndc',\n",
      "       'nodosestaken', 'orderedamount', 'ordereddate', 'administeredunits',\n",
      "       'targetadministeredunits', 'orderid', 'patientid', 'plannedcycles',\n",
      "       'providerid', 'orderhassignoff', 'orderstatus', 'regimen', 'route',\n",
      "       'targetroute', 'locationid', 'startdate', 'stopdate',\n",
      "       'transactiontimestamp', 'lineoftx', 'visitid', 'administrationdate',\n",
      "       'clinicalstudydrugind', 'clinicalstudyregimenind',\n",
      "       'compassionatecaredrugind', 'targetdiagnosiscode',\n",
      "       'targetdiagnosiscodesys', 'antineoplasticind',\n",
      "       'targetclinicalstudyregimenind'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ADVANCEDIRECTIVES:\n",
      "Index(['clientid', 'patientid', 'advancedirectiveid', 'dnr', 'lw', 'dpa',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ALLERGY:\n",
      "Index(['allergy', 'allergyid', 'allergyseverity', 'allergytype', 'clientid',\n",
      "       'onsetdate', 'patientid', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of CHARGE:\n",
      "Index(['clientid', 'patientid', 'chargeid', 'visitid', 'servicecode',\n",
      "       'servicecodedescription', 'billcdtype', 'providerid',\n",
      "       'orderingproviderid', 'locationid', 'units', 'servicedate',\n",
      "       'chargestatus', 'quantity', 'transactiontimestamp', 'icdhold',\n",
      "       'icdcode1', 'icdcode2', 'icdcode3', 'icdcode4', 'icdcode5', 'icdcode6',\n",
      "       'icdcode7', 'icdcode8', 'icdcode9', 'icdcode10', 'icdcode11'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DEMOGRAHPICS:\n",
      "Index(['RowID', 'clientid', 'patientid', 'patientmrn', 'patientssn',\n",
      "       'primaryphysicianid', 'dob', 'birthyear', 'age', 'dod', 'vitalstatus',\n",
      "       'gender', 'targetgender', 'race', 'targetrace', 'zip', 'zip3',\n",
      "       'preferredlang', 'address1', 'address2', 'city', 'state', 'targetstate',\n",
      "       'ethnicity', 'targetethnicity', 'locationid', 'registrationdate',\n",
      "       'transactiontimestamp', 'lastname', 'firstname', 'emailaddress',\n",
      "       'phonenumber', 'middlename', 'status', 'statusdate',\n",
      "       'TrialPatientIndicator', 'LogDate', 'DeathYear'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DEMOGRAPHICS:\n",
      "Index(['RowID', 'clientid', 'patientid', 'patientmrn', 'patientssn',\n",
      "       'primaryphysicianid', 'dob', 'birthyear', 'age', 'dod', 'vitalstatus',\n",
      "       'gender', 'targetgender', 'race', 'targetrace', 'zip', 'zip3',\n",
      "       'preferredlang', 'address1', 'address2', 'city', 'state', 'targetstate',\n",
      "       'ethnicity', 'targetethnicity', 'locationid', 'registrationdate',\n",
      "       'transactiontimestamp', 'lastname', 'firstname', 'emailaddress',\n",
      "       'phonenumber', 'middlename', 'status', 'statusdate',\n",
      "       'TrialPatientIndicator', 'LogDate', 'DeathYear'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DIAGNOSIS:\n",
      "Index(['clientid', 'patientid', 'diagnosisid', 'primaryflag', 'diagnosistype',\n",
      "       'diagnosisdescription', 'diagnosisdate', 'resolutiondate',\n",
      "       'patientstatus', 'metastaticindicator', 'transactiontimestamp',\n",
      "       'apprind', 'resolutiontyp', 'targeticd9description', 'targeticd9code',\n",
      "       'diagnosiscode', 'diagnosiscodesys', 'targetdiagnosiscode',\n",
      "       'targetdiagnosiscodesys', 'targetdiagnosisdescription',\n",
      "       'targetdetaileddiagnosisgroup', 'targetdiagnosisgroup',\n",
      "       'cancerdiagnosisind', 'diseaseid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DISEASESTATUS:\n",
      "Index(['clientid', 'diagnosisid', 'diseasestatusid', 'diseasestatus',\n",
      "       'patientid', 'locationid', 'statusdate', 'transactiontimestamp',\n",
      "       'visitid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ERX:\n",
      "Index(['clientid', 'erxid', 'erxtype', 'orderid', 'patientid', 'providerid',\n",
      "       'transactiontimestamp', 'pharmacyid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of FAMILYHISTORY:\n",
      "Index(['clientid', 'familyhistoryid', 'familyitem', 'familyvalue', 'patientid',\n",
      "       'recorddate', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of HOSPITALIZATION:\n",
      "Index(['clientid', 'patientid', 'hospitalizationid', 'startdate', 'enddate',\n",
      "       'reason', 'outcome', 'comment', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of INSURANCE:\n",
      "Index(['clientid', 'patientid', 'payer', 'payertype', 'targetpayertype',\n",
      "       'targetpayername', 'targetmedicareadvind', 'effectivedate',\n",
      "       'inactivedate', 'transactiontimestamp', 'primaryindicator',\n",
      "       'currentindicator', 'ismedicareadv', 'ismedicaresupp', 'ispartaonly',\n",
      "       'ispartbonly', 'ispartaandpartb', 'ispartdonly', 'ismanagedmedicaid',\n",
      "       'isacaplan', 'ismedicaremedicaid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of LABS:\n",
      "Index(['category', 'clientid', 'compflag', 'labid', 'maxnorm', 'minnorm',\n",
      "       'normal', 'orderid', 'diagnosisid', 'disease', 'panel', 'patientid',\n",
      "       'resultdate', 'test', 'testdate', 'testresult', 'testunits',\n",
      "       'transactiontimestamp', 'visitid', 'loinc', 'targettest',\n",
      "       'targettestunits', 'targetloinc'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ORDERS:\n",
      "Index(['clientid', 'diagnosisid', 'expectedstartdate', 'expectedstopdate',\n",
      "       'form', 'frequency', 'diagnosiscode', 'itemno', 'ndc', 'orderedamount',\n",
      "       'ordereddate', 'orderedunits', 'orderid', 'ordername', 'ordertype',\n",
      "       'orderstatus', 'patientid', 'plannedcycles', 'providerid', 'qtyperday',\n",
      "       'locationid', 'quantity', 'quantityunits', 'dayssupply', 'refill',\n",
      "       'regimen', 'relativedose', 'relativedoseuom', 'lineoftx', 'intent',\n",
      "       'route', 'strength', 'transactiontimestamp', 'visitid', 'orderstopdate',\n",
      "       'targetorderedunits', 'targetrelativeorderedunits', 'targetdrugname',\n",
      "       'targetdrugshortname', 'targetdrugcategory', 'targetroute',\n",
      "       'targetquantityunits', 'clinicalstudydrugind',\n",
      "       'clinicalstudyregimenind', 'compassionatecaredrugind',\n",
      "       'targetdiagnosiscode', 'targetdiagnosiscodesys', 'antineoplasticind',\n",
      "       'targetclinicalstudyregimenind'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of RADIOLOGY:\n",
      "Index(['clientid', 'patientid', 'radiologyid', 'visitid', 'visitdate',\n",
      "       'category', 'type', 'radiologyresult', 'mdinterpretation',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of REFERRINGPROVIDER:\n",
      "Index(['clientid', 'patientid', 'referringproviderid', 'providername',\n",
      "       'transactiontimestamp', 'providertype', 'specialty',\n",
      "       'referringprovidernpi', 'referringproviderupin'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of SOCIALHISTORY:\n",
      "Index(['clientid', 'patientid', 'recorddate', 'socialhistoryid', 'socialitem',\n",
      "       'socialvalue', 'transactiontimestamp', 'targetsocialitem',\n",
      "       'targetsocialvalue'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TRANSFUSION:\n",
      "Index(['clientid', 'patientid', 'transfusionid', 'transfusiondate',\n",
      "       'transfusiontype', 'units', 'comment', 'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of GRADESCALES:\n",
      "Index(['clientid', 'patientid', 'gradescaleid', 'gradescaledate',\n",
      "       'gradescalename', 'result', 'transactiontimestamp', 'documentid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of SURGICALHISTORY:\n",
      "Index(['clientid', 'patientid', 'surgerydate', 'surgeryid', 'surgicalsite',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of PERFORMANCE:\n",
      "Index(['clientid', 'patientid', 'performancedate', 'performanceid',\n",
      "       'performancescale', 'visitid', 'performancevalue',\n",
      "       'targetperformancescale', 'targetperformancevalue',\n",
      "       'transactiontimestamp'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of VISIT:\n",
      "Index(['clientid', 'patientid', 'visitid', 'visittype', 'visitdate',\n",
      "       'transactiontimestamp', 'providerid', 'diagnosisid', 'locationid',\n",
      "       'visitdesc'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of BIOMARKERS:\n",
      "Index(['category', 'clientid', 'labid', 'diagnosisid', 'patientid',\n",
      "       'resultdate', 'test', 'testdate', 'testresult', 'testunits',\n",
      "       'transactiontimestamp', 'targettest', 'targettestunits', 'targetloinc',\n",
      "       'targettestresult'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TOXICITIES:\n",
      "Index(['clientid', 'patientid', 'locationid', 'toxicity', 'toxicitydate',\n",
      "       'toxicitygrade', 'toxicityid', 'transactiontimestamp', 'visitid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of MEDICATIONLIST:\n",
      "Index(['clientid', 'patientid', 'medicationid', 'ordereddate',\n",
      "       'medicationtype', 'medicationname', 'targetdrugname',\n",
      "       'targetdrugshortname', 'targetdrugcategory', 'sourcedrugkey',\n",
      "       'sourcedrugvalue', 'ndc', 'gcn', 'units', 'targetunits', 'frequency',\n",
      "       'targetroute', 'transactiontimestamp', 'qtyperday', 'quantity',\n",
      "       'refill', 'medicationstopdate', 'verifydate', 'externalind'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of STAGING:\n",
      "Index(['clientid', 'patientid', 'diagnosisid', 'stagingsystem', 'stageid',\n",
      "       'stagingdate', 'stage', 'stagebasis', 't', 'n', 'm', 'g', 'histology',\n",
      "       'transactiontimestamp', 'critdesc', 'morphology', 'locationid', 'grade',\n",
      "       'targetstage', 'targett', 'targetn', 'targetm', 'targethistology',\n",
      "       'targetgleasonscore', 'histopathology'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of DATA_HISTORY:\n",
      "Index(['srowid', 'snoteid', 'sgroupid', 'spatientid', 'dservicedate', 'sfrom',\n",
      "       'sctltype', 'sdataname', 'sdatavalue'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of PATIENT_LOCATION_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'slocation', 'dservicedate',\n",
      "       'dstatuschangeddate', 'sstatuschangedbyuid', 'sstatusreprowid',\n",
      "       'dstatusdeleteddate', 'sstatusdeletedbyuid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of ORDER_CHARGE_HISTORY:\n",
      "Index(['srowid', 'saccountno', 'sgroupid', 'spatientid', 'sorderid', 'soidext',\n",
      "       'slocationid', 'sdescription', 'fsequence', 'sorderdose', 'sroute',\n",
      "       'sduration', 'ddatetime', 'sicdcode', 'schargetype', 'schargecode',\n",
      "       'fbillingunits', 'fquantity', 'sthisdose', 'scomment', 'ssignoffuid',\n",
      "       'dsignoffdate', 'ssupersedeuid', 'dsupersededate', 'sorderstatus',\n",
      "       'schargestatus', 'dstoptime', 'dstarttime', 'shideuid', 'dhidedt',\n",
      "       'istatus', 'dstatuschangeddate', 'sstatuschangedbyuid',\n",
      "       'sstatusreprowid', 'sdoseunits', 'sbuunits', 'ssupervisingmduid',\n",
      "       'sorderingmduid', 'sbagnum', 'smodifiers', 'dstatusdeleteddate',\n",
      "       'sstatusdeletedbyuid', 'sreferringmdid', 'sreferralauth', 'spriorauth',\n",
      "       'sicd10code', 'saddtcodes', 'sndc', 'sndcuom', 'fndcqty'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TREATMENT_CURRENT_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'stype', 'ddate', 'ddateend',\n",
      "       'sintent', 'svalue', 'svalue2', 'soutcome', 'dstatuschangeddate',\n",
      "       'sstatuschangedbyuid', 'sstatusreprowid', 'dstatusdeleteddate',\n",
      "       'sstatusdeletedbyuid', 'stxdocuid', 'shospmdid', 'sunknownptinfo',\n",
      "       'streatmenthistoryid', 'lsnomedcode'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of VITAL_SIGN_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'ddatetime', 'scode', 'svalue',\n",
      "       'sunits', 'flowerlimit', 'fupperlimit', 'dstatuschangeddate',\n",
      "       'sstatuschangedbyuid', 'slimits', 'sstatusreprowid',\n",
      "       'dstatusdeleteddate', 'sstatusdeletedbyuid'],\n",
      "      dtype='object')\n",
      "--------------------\n",
      "Columns of TREATMENT_PREVIOUS_HISTORY:\n",
      "Index(['srowid', 'sgroupid', 'spatientid', 'stype', 'ddate', 'ddateend',\n",
      "       'sintent', 'svalue', 'svalue2', 'soutcome', 'dstatuschangeddate',\n",
      "       'sstatuschangedbyuid', 'sstatusreprowid', 'dstatusdeleteddate',\n",
      "       'sstatusdeletedbyuid', 'lsnomedcode'],\n",
      "      dtype='object')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "######################################## Load Data ########################################\n",
    "\n",
    "# Get sample patient ids\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
    "    ORDER BY RANDOM()\n",
    "\"\"\")\n",
    "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
    "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'DBO'\n",
    "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
    "    AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all the table names\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "#print(tables)\n",
    "\n",
    "# Create a dictionary to hold each table as a DataFrame\n",
    "table_dataframes = {}\n",
    "table_dataframes_spat = {}\n",
    "\n",
    "for table in tables:\n",
    "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
    "    \"\"\")\n",
    "    \n",
    "    columns = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    # If 'patientid' is a column, proceed to query the table\n",
    "    if 'patientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "    # If 'spatientid' is a column, proceed to query the table\n",
    "    if 'spatientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results_spat = cursor.fetchall()\n",
    "        columns_spat = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
    "\n",
    "# Merge table_dataframes_spat into table_dataframes_pat\n",
    "table_dataframes.update(table_dataframes_spat)\n",
    "\n",
    "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
    "print(\"Data Loaded Successfully!\")\n",
    "print(\" \")\n",
    "print(\"Tables Loaded:\")\n",
    "for table, df in table_dataframes.items():\n",
    "    print(f\"{table}\")\n",
    "    #print(df.head())\n",
    "\n",
    "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
    "for table, df in table_dataframes.items():\n",
    "    globals()[table] = df\n",
    "\n",
    "# Now you can access the DataFrames as individual variables:\n",
    "# print(ADMINISTRATIONS.head())\n",
    "\n",
    "# Bring in clinical trial data\n",
    "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
    "clinical_trials_incl = pd.read_csv('agegender_incl1.csv')\n",
    "print(\"clinical_trials_data_simple_exclusion\")\n",
    "print(\"clinical_trials_data_simple_inclusion\")\n",
    "print(\" \")\n",
    "\n",
    "def print_columns_of_dict_of_dfs(df_dict):\n",
    "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
    "\n",
    "    for df_name, df in df_dict.items():\n",
    "        print(f\"Columns of {df_name}:\")\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "# Call the function to print the columns\n",
    "print_columns_of_dict_of_dfs(table_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112b909a-3fe7-4a3a-bb29-0ff963fdacf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete!\n"
     ]
    }
   ],
   "source": [
    "######################################## Feature Engineering ########################################\n",
    "\n",
    "# Convert non-numeric values to NaN\n",
    "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
    "\n",
    "# Now, convert the column to integers (NaNs will remain as NaN)\n",
    "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
    "print(\"Feature Engineering Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6c4807-c0a9-4eac-827a-0c2a1960f310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Trial_Name', 'Trial_ID', 'Inclusion_Criteria'], dtype='object')\n",
      "      RowID clientid                             patientid patientmrn  \\\n",
      "0    112304   CA0026  D6288764-EBAB-429D-9D6E-BA5152340FDD       None   \n",
      "1    158902   CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "2       924   CA0026  A552A6C5-63DB-4152-B0E3-4C1A94C9CF27       None   \n",
      "3    109938   CA0026  ECCE7682-F192-4E4B-8915-D3808F81E60E       None   \n",
      "4    131886   CA0026  B995B177-DA99-4BEF-9818-8E40DCD9841D       None   \n",
      "..      ...      ...                                   ...        ...   \n",
      "995     148   CA0026  9D1DAE72-E47F-453C-AF06-12AA2B97855C       None   \n",
      "996     228   CA0026  E393B5A7-862D-43DD-97A2-4B2075FBD297       None   \n",
      "997     398   CA0026  F90AA3C5-D2D7-4A6E-AFC5-024A1F912112       None   \n",
      "998     878   CA0026  BE19FCC3-3107-400D-9C0B-1A6C3ADB8D5E       None   \n",
      "999     275   CA0026  F124E3E2-C129-4FA2-8144-BF11CEC44CFB       None   \n",
      "\n",
      "    patientssn         primaryphysicianid   dob  birthyear  age   dod  ...  \\\n",
      "0         None  PH_2E0C6FDB8CA0035D2FABD0  None     1944.0   79  None  ...   \n",
      "1         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "2         None         UID_MA206161585_30  None     1973.0   50  None  ...   \n",
      "3         None  PH_82AFB13F99200B0A05DAD7  None     1981.0   42  None  ...   \n",
      "4         None  PH_B124FEEF1BE70F214EB8C8  None     1960.0   63  None  ...   \n",
      "..         ...                        ...   ...        ...  ...   ...  ...   \n",
      "995       None                       None  None        NaN   99  None  ...   \n",
      "996       None                       None  None        NaN   97  None  ...   \n",
      "997       None                       None  None        NaN   92  None  ...   \n",
      "998       None                       None  None        NaN  117  None  ...   \n",
      "999       None                       None  None        NaN   97  None  ...   \n",
      "\n",
      "     lastname firstname emailaddress phonenumber middlename    status  \\\n",
      "0        None      None         None        None       None  Deceased   \n",
      "1        None      None         None        None       None  Deceased   \n",
      "2        None      None         None        None       None  Deceased   \n",
      "3        None      None         None        None       None  Deceased   \n",
      "4        None      None         None        None       None  Deceased   \n",
      "..        ...       ...          ...         ...        ...       ...   \n",
      "995      None      None         None        None       None    Active   \n",
      "996      None      None         None        None       None    Active   \n",
      "997      None      None         None        None       None    Active   \n",
      "998      None      None         None        None       None    Active   \n",
      "999      None      None         None        None       None    Active   \n",
      "\n",
      "             statusdate TrialPatientIndicator    LogDate DeathYear  \n",
      "0   2022-08-31 12:04:27                   Yes 2024-02-12    2022.0  \n",
      "1   2022-12-23 18:18:43                   Yes 2024-02-12    2022.0  \n",
      "2   2022-01-17 13:37:13                    No 2024-02-12    2022.0  \n",
      "3   2023-11-08 13:57:03                   Yes 2024-02-12    2022.0  \n",
      "4   2022-09-19 12:45:19                   Yes 2024-02-12    2022.0  \n",
      "..                  ...                   ...        ...       ...  \n",
      "995                 NaT                    No 2024-02-12       NaN  \n",
      "996                 NaT                    No 2024-02-12       NaN  \n",
      "997                 NaT                    No 2024-02-12       NaN  \n",
      "998                 NaT                    No 2024-02-12       NaN  \n",
      "999                 NaT                    No 2024-02-12       NaN  \n",
      "\n",
      "[1000 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################## Quality Check ########################################\n",
    "print(clinical_trials_incl.columns)\n",
    "print(DEMOGRAPHICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7865d0fd-f717-453e-a2fc-88c5dd035db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579\n",
      "420\n",
      "       RowID clientid_x                             patientid patientmrn  \\\n",
      "10    158902     CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "11    158902     CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "12    158902     CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "13    158902     CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "14    158902     CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "...      ...        ...                                   ...        ...   \n",
      "4370     439     CA0026  9B4AB207-5DE3-43ED-8267-16C8FE7409A8       None   \n",
      "4373     123     CA0026  D0BF1727-EB9C-4D6C-86AF-2BA142AC3ABA       None   \n",
      "4375     593     CA0026  87F5D3B1-7EBB-48C9-ACD4-7AB4D211701D       None   \n",
      "4379     148     CA0026  9D1DAE72-E47F-453C-AF06-12AA2B97855C       None   \n",
      "4382     878     CA0026  BE19FCC3-3107-400D-9C0B-1A6C3ADB8D5E       None   \n",
      "\n",
      "     patientssn         primaryphysicianid   dob  birthyear  age   dod  ...  \\\n",
      "10         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "11         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "12         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "13         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "14         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "...         ...                        ...   ...        ...  ...   ...  ...   \n",
      "4370       None                       None  None        NaN   92  None  ...   \n",
      "4373       None                       None  None        NaN   98  None  ...   \n",
      "4375       None                       None  None        NaN  104  None  ...   \n",
      "4379       None                       None  None        NaN   99  None  ...   \n",
      "4382       None                       None  None        NaN  117  None  ...   \n",
      "\n",
      "      diagnosiscode diagnosiscodesys targetdiagnosiscode  \\\n",
      "10            D70.1        ICD-10-CM               D70.1   \n",
      "11            D63.0        ICD-10-CM               D63.0   \n",
      "12            C18.8        ICD-10-CM               C18.8   \n",
      "13           C79.51        ICD-10-CM              C79.51   \n",
      "14           C78.00        ICD-10-CM              C78.00   \n",
      "...             ...              ...                 ...   \n",
      "4370            NaN              NaN                 NaN   \n",
      "4373            NaN              NaN                 NaN   \n",
      "4375            NaN              NaN                 NaN   \n",
      "4379            NaN              NaN                 NaN   \n",
      "4382            NaN              NaN                 NaN   \n",
      "\n",
      "     targetdiagnosiscodesys                        targetdiagnosisdescription  \\\n",
      "10                ICD-10-CM  Agranulocytosis secondary to cancer chemotherapy   \n",
      "11                ICD-10-CM                      Anemia in neoplastic disease   \n",
      "12                ICD-10-CM  Malignant neoplasm of overlapping sites of colon   \n",
      "13                ICD-10-CM              Secondary malignant neoplasm of bone   \n",
      "14                ICD-10-CM  Secondary malignant neoplasm of unspecified lung   \n",
      "...                     ...                                               ...   \n",
      "4370                    NaN                                               NaN   \n",
      "4373                    NaN                                               NaN   \n",
      "4375                    NaN                                               NaN   \n",
      "4379                    NaN                                               NaN   \n",
      "4382                    NaN                                               NaN   \n",
      "\n",
      "               targetdetaileddiagnosisgroup          targetdiagnosisgroup  \\\n",
      "10    Other benign hematological conditions  Benign hematologic condition   \n",
      "11    Other benign hematological conditions  Benign hematologic condition   \n",
      "12      Cancer of colon (excluding in situ)                         Colon   \n",
      "13             Secondary malignant neoplasm  Secondary malignant neoplasm   \n",
      "14             Secondary malignant neoplasm  Secondary malignant neoplasm   \n",
      "...                                     ...                           ...   \n",
      "4370                                    NaN                           NaN   \n",
      "4373                                    NaN                           NaN   \n",
      "4375                                    NaN                           NaN   \n",
      "4379                                    NaN                           NaN   \n",
      "4382                                    NaN                           NaN   \n",
      "\n",
      "     cancerdiagnosisind            diseaseid Expert_Decision  \n",
      "10                    N    DD_20140310_44_10               1  \n",
      "11                    N    DD_20140310_36_10               1  \n",
      "12                    Y  3744070510199468701               1  \n",
      "13                    Y           20051111_1               1  \n",
      "14                    Y           20051111_1               1  \n",
      "...                 ...                  ...             ...  \n",
      "4370                NaN                  NaN               1  \n",
      "4373                NaN                  NaN               1  \n",
      "4375                NaN                  NaN               1  \n",
      "4379                NaN                  NaN               1  \n",
      "4382                NaN                  NaN               1  \n",
      "\n",
      "[2755 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################## Build Mock Expert Decision ########################################\n",
    "# Perform the LEFT JOIN\n",
    "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
    "\n",
    "# Filter using \"LIKE\" equivalent\n",
    "eligible = merged_df[\n",
    "    (merged_df['age'] >= 18) &\n",
    "    (merged_df['gender'] == 'Female')\n",
    "    # (merged_df['targetdetaileddiagnosisgroup'].str.contains('breast', case=False, na=False)) &\n",
    "    # (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
    "]\n",
    "\n",
    "# # For evaluation metrics later\n",
    "# eligible['Expert_Decision_Age'] = 1\n",
    "# eligible['Expert_Decision_Gender'] = 1\n",
    "eligible['Expert_Decision'] = 1\n",
    "\n",
    "#distinct_count = eligible['patientid'].nunique()\n",
    "\n",
    "# Extract patient IDs that match the expert's eligibility criteria\n",
    "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
    "\n",
    "# Get patient IDs that are not in the eligible list\n",
    "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
    "\n",
    "print(len(eligible_patient_ids))\n",
    "print(len(ineligible_patient_ids))\n",
    "\n",
    "print(eligible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413bca5f-ef11-4c9d-8688-6e3fef8d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible.to_csv('test_eligible.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea0ed51-9c15-41a8-830a-154b5a8f11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: breast cancer, Label: DISEASE\n",
      "Entity: Tamoxifen, Label: CHEMICAL\n",
      "Entity: 18 years old, Label: AGE\n",
      "Entity: female, Label: GENDER\n"
     ]
    }
   ],
   "source": [
    "# ######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - 1 line of text, model testing ########################################\n",
    "\n",
    "# ### Test to apply to 1 line of text\n",
    "# ### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# # Load the MedSpaCy model\n",
    "# nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# # Process your text\n",
    "# text = \"The patient is a female 18 years old and was diagnosed with breast cancer and prescribed Tamoxifen.\"\n",
    "\n",
    "# # Function to extract entities and labels\n",
    "# def extract_entities(text):\n",
    "#     doc = nlp(text)\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "#     # Custom check for age-related information (e.g., \"18 years old\")\n",
    "#     age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "#     age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "#     # If age-related information is found, add it to the entities with the correct label\n",
    "#     for age in age_matches:\n",
    "#         entities.append((f\"{age} years old\", 'AGE'))\n",
    "    \n",
    "#     # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "#     gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "#     # Check for the first gender-related term match (female first, then male)\n",
    "#     gender_found = False\n",
    "#     for gender in gender_keywords:\n",
    "#         match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "#         if match:\n",
    "#             entities.append((match.group(), 'GENDER'))\n",
    "#             break  # Once a match is found, stop further checking\n",
    "\n",
    "#     return entities\n",
    "\n",
    "# # Display named entities and custom additions\n",
    "# entities = extract_entities(text)\n",
    "# for ent in entities:\n",
    "#     print(f\"Entity: {ent[0]}, Label: {ent[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e491783-7d24-49d8-a9ee-2a0963cd335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial_Name  Trial_ID          Inclusion_Criteria Category\n",
      "0  Test_Trial       123            Aged 18 or over.      AGE\n",
      "1  Test_Trial       123                      Female   GENDER\n",
      "2  Test_Trial       123  Diagnosed with Lung Cancer  DISEASE\n"
     ]
    }
   ],
   "source": [
    "######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - Clinical Trial Dataframe ########################################\n",
    "\n",
    "### Apply to a dataframe of trial data\n",
    "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# Load the MedSpaCy model\n",
    "nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# Function to extract entities and labels\n",
    "def extract_entities(text):\n",
    "    # Process the text through the NLP model\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # Custom check for age-related information (e.g., \"18 years old\")\n",
    "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If age-related information is found, add it to the entities with the correct label\n",
    "    for age in age_matches:\n",
    "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
    "    \n",
    "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "    # Check for the first gender-related term match (female first, then male)\n",
    "    gender_found = False\n",
    "    for gender in gender_keywords:\n",
    "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            entities.append((match.group(), 'GENDER'))\n",
    "            break  # Once a match is found, stop further checking\n",
    "\n",
    "    # Extract the unique labels to avoid duplicates and return them\n",
    "    unique_labels = set([label for _, label in entities])\n",
    "    return list(unique_labels)\n",
    "\n",
    "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
    "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1a0444-d109-4fed-866d-cd0445090f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial_Name  Trial_ID          Inclusion_Criteria Category  \\\n",
      "0  Test_Trial       123            Aged 18 or over.      AGE   \n",
      "1  Test_Trial       123                      Female   GENDER   \n",
      "2  Test_Trial       123  Diagnosed with Lung Cancer  DISEASE   \n",
      "\n",
      "                           Source_Columns  \n",
      "0                        DEMOGRAHPICS.age  \n",
      "1                     DEMOGRAHPICS.gender  \n",
      "2  DIAGNOSIS.targetdetaileddiagnosisgroup  \n"
     ]
    }
   ],
   "source": [
    "######################################## Use Fuzzy: Find columns in Patient Data that match Trial Inclusion Criteria ########################################\n",
    "\n",
    "# Function to find exact matches and fuzzy matches\n",
    "def find_matching_columns(category, dict_of_dfs, fuzzy_threshold=80):\n",
    "    if category.lower() == 'disease':\n",
    "        return ['DIAGNOSIS.targetdetaileddiagnosisgroup']\n",
    "    \n",
    "    # Step 1: Find exact matches (case-insensitive)\n",
    "    exact_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        if category.lower() in [col.lower() for col in df.columns]:\n",
    "            exact_column = next(col for col in df.columns if col.lower() == category.lower())\n",
    "            exact_matches.append(f'{df_name}.{exact_column}')\n",
    "            return exact_matches  # Return immediately after finding an exact match\n",
    "    \n",
    "    # Step 2: If no exact match, find fuzzy matches\n",
    "    fuzzy_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        columns = df.columns\n",
    "        for column in columns:\n",
    "            score = process.extractOne(category, [column])  # Compare category with each column\n",
    "            if score and score[1] >= fuzzy_threshold:  # If score is above threshold\n",
    "                fuzzy_matches.append(f'{df_name}.{column}')\n",
    "    \n",
    "    return fuzzy_matches\n",
    "\n",
    "# Loop through the clinical_trials_incl DataFrame and apply matching function\n",
    "def add_source_columns(clinical_trials_incl, table_dataframes):\n",
    "    source_columns_list = []\n",
    "    \n",
    "    for index, row in clinical_trials_incl.iterrows():\n",
    "        category = row['Category']\n",
    "        matching_columns = find_matching_columns(category, table_dataframes)\n",
    "        \n",
    "        # If there are multiple matches, list them, else return 'No match'\n",
    "        if matching_columns:\n",
    "            source_columns_list.append(', '.join(matching_columns))\n",
    "        else:\n",
    "            source_columns_list.append('No match')\n",
    "    \n",
    "    clinical_trials_incl['Source_Columns'] = source_columns_list\n",
    "    return clinical_trials_incl\n",
    "\n",
    "# Apply the function to the clinical_trials_incl DataFrame\n",
    "clinical_trials_incl_ner = add_source_columns(clinical_trials_incl, table_dataframes)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl_ner)\n",
    "\n",
    "######################### Now the clinical trial data is ready. #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efd096a8-9bb1-4834-9f94-127e5840495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Patient_ID  Trial_Name  Trial_ID  \\\n",
      "0     D6288764-EBAB-429D-9D6E-BA5152340FDD  Test_Trial       123   \n",
      "1     548CD51B-9AC0-4A25-9D48-B6D08675DD00  Test_Trial       123   \n",
      "2     A552A6C5-63DB-4152-B0E3-4C1A94C9CF27  Test_Trial       123   \n",
      "3     ECCE7682-F192-4E4B-8915-D3808F81E60E  Test_Trial       123   \n",
      "4     B995B177-DA99-4BEF-9818-8E40DCD9841D  Test_Trial       123   \n",
      "...                                    ...         ...       ...   \n",
      "6027  C95B62FB-36CC-405C-A4BD-F419053188BB  Test_Trial       123   \n",
      "6028  7F7E43E7-4438-4A9A-A11B-299DDAB8DB58  Test_Trial       123   \n",
      "6029  6876BBD9-29FE-4B06-947B-D7EC22355212  Test_Trial       123   \n",
      "6030  67EEC590-6EDC-4A20-8D00-490754E25110  Test_Trial       123   \n",
      "6031  DC49B6B7-027A-4416-BA1B-922031859121  Test_Trial       123   \n",
      "\n",
      "              Inclusion_Criteria Category  \\\n",
      "0               Aged 18 or over.      AGE   \n",
      "1               Aged 18 or over.      AGE   \n",
      "2               Aged 18 or over.      AGE   \n",
      "3               Aged 18 or over.      AGE   \n",
      "4               Aged 18 or over.      AGE   \n",
      "...                          ...      ...   \n",
      "6027  Diagnosed with Lung Cancer  DISEASE   \n",
      "6028  Diagnosed with Lung Cancer  DISEASE   \n",
      "6029  Diagnosed with Lung Cancer  DISEASE   \n",
      "6030  Diagnosed with Lung Cancer  DISEASE   \n",
      "6031  Diagnosed with Lung Cancer  DISEASE   \n",
      "\n",
      "                               Source_Column Source_Value  Match_Percentage  \n",
      "0                           DEMOGRAHPICS.age           79             92.15  \n",
      "1                           DEMOGRAHPICS.age           61             92.38  \n",
      "2                           DEMOGRAHPICS.age           50             92.92  \n",
      "3                           DEMOGRAHPICS.age           42             92.53  \n",
      "4                           DEMOGRAHPICS.age           63             92.57  \n",
      "...                                      ...          ...               ...  \n",
      "6027  DIAGNOSIS.targetdetaileddiagnosisgroup         None              0.00  \n",
      "6028  DIAGNOSIS.targetdetaileddiagnosisgroup         None              0.00  \n",
      "6029  DIAGNOSIS.targetdetaileddiagnosisgroup         None              0.00  \n",
      "6030  DIAGNOSIS.targetdetaileddiagnosisgroup         None              0.00  \n",
      "6031  DIAGNOSIS.targetdetaileddiagnosisgroup         None              0.00  \n",
      "\n",
      "[6032 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load RoBERTa model and tokenizer\n",
    "model_name = \"roberta-base\"  # You can also use \"bert-base-uncased\" or \"xlnet-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def calculate_similarity_transformer(inclusion_criteria, source_value):\n",
    "    \"\"\"\n",
    "    Calculate similarity between two text strings using RoBERTa model embeddings.\n",
    "    \"\"\"\n",
    "    if pd.isna(inclusion_criteria) or pd.isna(source_value) or not inclusion_criteria.strip() or not source_value.strip():\n",
    "        #print(f\"Skipping empty input: inclusion_criteria = {inclusion_criteria}, source_value = {source_value}\")\n",
    "        return 0  # If either string is empty, return 0 as match percentage\n",
    "    \n",
    "    #print(f\"Comparing: {inclusion_criteria} vs {source_value}\")\n",
    "    \n",
    "    # Tokenize both inclusion_criteria and source_value separately\n",
    "    inputs_inclusion = tokenizer(inclusion_criteria, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs_source = tokenizer(source_value, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get embeddings for both input texts\n",
    "        embeddings_inclusion = model(**inputs_inclusion).last_hidden_state.mean(dim=1)  # Pool the embeddings\n",
    "        embeddings_source = model(**inputs_source).last_hidden_state.mean(dim=1)  # Pool the embeddings\n",
    "    \n",
    "    # Print embeddings shape for debugging\n",
    "    #print(f\"Inclusion Embeddings shape: {embeddings_inclusion.shape}\")\n",
    "    #print(f\"Source Embeddings shape: {embeddings_source.shape}\")\n",
    "    \n",
    "    # If embeddings are empty, return 0\n",
    "    if embeddings_inclusion.numel() == 0 or embeddings_source.numel() == 0:\n",
    "        print(\"Empty embeddings detected!\")\n",
    "        return 0\n",
    "\n",
    "    # Cosine similarity between the two embeddings\n",
    "    similarity = torch.nn.functional.cosine_similarity(embeddings_inclusion, embeddings_source)\n",
    "    return round(similarity.item() * 100, 2)\n",
    "\n",
    "def match_patients_to_trials(clinical_trials_incl_ner, table_dataframes):\n",
    "    \"\"\"\n",
    "    Match patients to clinical trials using RoBERTa for similarity calculation.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, row in clinical_trials_incl_ner.iterrows():\n",
    "        trial_name = row['Trial_Name']\n",
    "        trial_id = row['Trial_ID']\n",
    "        inclusion_criteria = row['Inclusion_Criteria']\n",
    "        category = row['Category']\n",
    "        source_column = row['Source_Columns']\n",
    "        \n",
    "        table_name, column_name = source_column.split('.')\n",
    "        \n",
    "        # Check if the table exists in the provided dataframes\n",
    "        if table_name in table_dataframes:\n",
    "            df = table_dataframes[table_name]\n",
    "            if column_name in df.columns:\n",
    "                for _, patient_row in df.iterrows():\n",
    "                    patient_id = patient_row['patientid']\n",
    "                    source_value = patient_row[column_name]\n",
    "\n",
    "                    # Use RoBERTa for all categories (no need to parse age/gender)\n",
    "                    match_percentage = calculate_similarity_transformer(inclusion_criteria, source_value)\n",
    "\n",
    "                    # Append results\n",
    "                    results.append({\n",
    "                        'Patient_ID': patient_id,\n",
    "                        'Trial_Name': trial_name,\n",
    "                        'Trial_ID': trial_id,\n",
    "                        'Inclusion_Criteria': inclusion_criteria,\n",
    "                        'Category': category,\n",
    "                        'Source_Column': source_column,\n",
    "                        'Source_Value': source_value,\n",
    "                        'Match_Percentage': match_percentage\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run Matching\n",
    "matched_results = match_patients_to_trials(clinical_trials_incl_ner, table_dataframes)\n",
    "\n",
    "# Display the result\n",
    "print(matched_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "989e639e-d03d-4e63-b282-a2da099ba2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Patient_ID  Trial_Name  Trial_ID  \\\n",
      "0     548CD51B-9AC0-4A25-9D48-B6D08675DD00  Test_Trial       123   \n",
      "14    A552A6C5-63DB-4152-B0E3-4C1A94C9CF27  Test_Trial       123   \n",
      "34    D7498EED-DFEB-4B1D-AF0F-AAABD6F97760  Test_Trial       123   \n",
      "43    6C4D35A4-465F-49C5-B4FE-744CBF5D2AB7  Test_Trial       123   \n",
      "66    0274040C-DCE0-4217-9821-2B7318E5F8D1  Test_Trial       123   \n",
      "...                                    ...         ...       ...   \n",
      "2750  9B4AB207-5DE3-43ED-8267-16C8FE7409A8  Test_Trial       123   \n",
      "2751  D0BF1727-EB9C-4D6C-86AF-2BA142AC3ABA  Test_Trial       123   \n",
      "2752  87F5D3B1-7EBB-48C9-ACD4-7AB4D211701D  Test_Trial       123   \n",
      "2753  9D1DAE72-E47F-453C-AF06-12AA2B97855C  Test_Trial       123   \n",
      "2754  BE19FCC3-3107-400D-9C0B-1A6C3ADB8D5E  Test_Trial       123   \n",
      "\n",
      "     Inclusion_Criteria Category     Source_Column  Source_Value  \\\n",
      "0      Aged 18 or over.      AGE  DEMOGRAHPICS.age          61.0   \n",
      "14     Aged 18 or over.      AGE  DEMOGRAHPICS.age          50.0   \n",
      "34     Aged 18 or over.      AGE  DEMOGRAHPICS.age          70.0   \n",
      "43     Aged 18 or over.      AGE  DEMOGRAHPICS.age          74.0   \n",
      "66     Aged 18 or over.      AGE  DEMOGRAHPICS.age          68.0   \n",
      "...                 ...      ...               ...           ...   \n",
      "2750   Aged 18 or over.      AGE  DEMOGRAHPICS.age          92.0   \n",
      "2751   Aged 18 or over.      AGE  DEMOGRAHPICS.age          98.0   \n",
      "2752   Aged 18 or over.      AGE  DEMOGRAHPICS.age         104.0   \n",
      "2753   Aged 18 or over.      AGE  DEMOGRAHPICS.age          99.0   \n",
      "2754   Aged 18 or over.      AGE  DEMOGRAHPICS.age         117.0   \n",
      "\n",
      "      Match_Percentage  Expert_Decision  \n",
      "0                92.38                1  \n",
      "14               92.92                1  \n",
      "34               92.37                1  \n",
      "43               92.62                1  \n",
      "66               92.50                1  \n",
      "...                ...              ...  \n",
      "2750             92.12                1  \n",
      "2751             92.25                1  \n",
      "2752             92.11                1  \n",
      "2753             92.26                1  \n",
      "2754             91.39                1  \n",
      "\n",
      "[579 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract the age and gender information from Source_Column and Source_Value\n",
    "age_data = matched_results[matched_results['Source_Column'] == 'DEMOGRAHPICS.age'].drop_duplicates()\n",
    "\n",
    "# Convert 'Source_Value' to numeric for age data, coerce errors to NaN if there are non-numeric entries\n",
    "age_data['Source_Value'] = pd.to_numeric(age_data['Source_Value'], errors='coerce')\n",
    "\n",
    "# First, merge age data\n",
    "age_merged = pd.merge(age_data, eligible[['patientid', 'age', 'Expert_Decision']], \n",
    "                       left_on=['Patient_ID', 'Source_Value'], right_on=['patientid', 'age'], \n",
    "                       how='inner').drop_duplicates()\n",
    "\n",
    "# Display the merged dataframe with relevant columns\n",
    "age_merged = age_merged[['Patient_ID', 'Trial_Name', 'Trial_ID', 'Inclusion_Criteria', 'Category', 'Source_Column', 'Source_Value', 'Match_Percentage', 'Expert_Decision']]\n",
    "print(age_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "224a75c2-b7f8-4d91-9d3a-10d192f07d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Patient_ID  Trial_Name  Trial_ID  \\\n",
      "0     548CD51B-9AC0-4A25-9D48-B6D08675DD00  Test_Trial       123   \n",
      "14    A552A6C5-63DB-4152-B0E3-4C1A94C9CF27  Test_Trial       123   \n",
      "34    D7498EED-DFEB-4B1D-AF0F-AAABD6F97760  Test_Trial       123   \n",
      "43    6C4D35A4-465F-49C5-B4FE-744CBF5D2AB7  Test_Trial       123   \n",
      "66    0274040C-DCE0-4217-9821-2B7318E5F8D1  Test_Trial       123   \n",
      "...                                    ...         ...       ...   \n",
      "2750  9B4AB207-5DE3-43ED-8267-16C8FE7409A8  Test_Trial       123   \n",
      "2751  D0BF1727-EB9C-4D6C-86AF-2BA142AC3ABA  Test_Trial       123   \n",
      "2752  87F5D3B1-7EBB-48C9-ACD4-7AB4D211701D  Test_Trial       123   \n",
      "2753  9D1DAE72-E47F-453C-AF06-12AA2B97855C  Test_Trial       123   \n",
      "2754  BE19FCC3-3107-400D-9C0B-1A6C3ADB8D5E  Test_Trial       123   \n",
      "\n",
      "     Inclusion_Criteria Category        Source_Column Source_Value  \\\n",
      "0                Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "14               Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "34               Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "43               Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "66               Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "...                 ...      ...                  ...          ...   \n",
      "2750             Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "2751             Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "2752             Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "2753             Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "2754             Female   GENDER  DEMOGRAHPICS.gender       Female   \n",
      "\n",
      "      Match_Percentage  Expert_Decision  \n",
      "0                100.0                1  \n",
      "14               100.0                1  \n",
      "34               100.0                1  \n",
      "43               100.0                1  \n",
      "66               100.0                1  \n",
      "...                ...              ...  \n",
      "2750             100.0                1  \n",
      "2751             100.0                1  \n",
      "2752             100.0                1  \n",
      "2753             100.0                1  \n",
      "2754             100.0                1  \n",
      "\n",
      "[579 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract the age and gender information from Source_Column and Source_Value\n",
    "gender_data = matched_results[matched_results['Source_Column'] == 'DEMOGRAHPICS.gender'].drop_duplicates()\n",
    "\n",
    "# Convert 'Source_Value' to string to align with 'gender' column in 'eligible'\n",
    "gender_data['Source_Value'] = gender_data['Source_Value'].astype(str)\n",
    "\n",
    "# Ensure 'gender' column in 'eligible' is also string (if necessary)\n",
    "eligible['gender'] = eligible['gender'].astype(str)\n",
    "\n",
    "# First, merge age data\n",
    "gender_merged = pd.merge(gender_data, eligible[['patientid', 'gender', 'Expert_Decision']], \n",
    "                       left_on=['Patient_ID', 'Source_Value'], right_on=['patientid', 'gender'], \n",
    "                       how='inner').drop_duplicates()\n",
    "\n",
    "# Display the merged dataframe with relevant columns\n",
    "gender_merged = gender_merged[['Patient_ID', 'Trial_Name', 'Trial_ID', 'Inclusion_Criteria', 'Category', 'Source_Column', 'Source_Value', 'Match_Percentage', 'Expert_Decision']]\n",
    "print(gender_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b04279f-44fb-4257-a3c1-f5956d2f2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_merged.to_csv('gender_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f12ff32-5161-4a43-bb5c-66ada696750b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Expert_Decision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Expert_Decision'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m eval_result_df_category[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_Decision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_result_df_category[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatch_Percentage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m70\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get the true values for evaluation (assuming 'Expert_Decision_Disease' exists in the data)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m y_true_category \u001b[38;5;241m=\u001b[39m \u001b[43meval_result_df_category\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpert_Decision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m y_pred_category \u001b[38;5;241m=\u001b[39m eval_result_df_category[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel_Decision\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate confusion matrix and Cohen's Kappa score\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Expert_Decision'"
     ]
    }
   ],
   "source": [
    "######################################## Evaluate by Inclusion Criteria ########################################\n",
    "\n",
    "matched_results_agegender = matched_results[matched_results['Category'].isin(['AGE', 'GENDER'])]\n",
    "\n",
    "# Loop through all unique categories in the 'Category' column\n",
    "for category in matched_results_agegender['Category'].unique():\n",
    "    # Filter matched results for the current category\n",
    "    matched_results_category = matched_results_agegender[matched_results_agegender['Category'] == category]\n",
    "    \n",
    "    # Copy the filtered data for further evaluation\n",
    "    eval_result_df_category = matched_results_category.copy()\n",
    "    \n",
    "    # Apply model decision (based on match percentage)\n",
    "    eval_result_df_category['Model_Decision'] = eval_result_df_category['Match_Percentage'].apply(lambda x: 1 if x > 70 else 0)\n",
    "    \n",
    "    # Get the true values for evaluation (assuming 'Expert_Decision_Disease' exists in the data)\n",
    "    y_true_category = eval_result_df_category['Expert_Decision']\n",
    "    y_pred_category = eval_result_df_category['Model_Decision']\n",
    "    \n",
    "    # Calculate confusion matrix and Cohen's Kappa score\n",
    "    conf_matrix_category = confusion_matrix(y_true_category, y_pred_category)\n",
    "    kappa_score_category = cohen_kappa_score(y_true_category, y_pred_category)\n",
    "    \n",
    "    # Print results for the current category\n",
    "    print(f\"Results for Category: {category}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix_category)\n",
    "    print(\"\\nCohen's Kappa Score:\", kappa_score_category)\n",
    "    \n",
    "    # Print summary of eligible and ineligible patients\n",
    "    eligible_patient_ids = eval_result_df_category[eval_result_df_category['Model_Decision'] == 1]\n",
    "    ineligible_patient_ids = eval_result_df_category[eval_result_df_category['Model_Decision'] == 0]\n",
    "    \n",
    "    print(f\"\\nPatients Eligible: {len(eligible_patient_ids)}\")\n",
    "    print(f\"Patients Ineligible: {len(ineligible_patient_ids)}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d0fea-2f03-4ea7-b689-d62831c8b4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_mitsui_condapy310)",
   "language": "python",
   "name": "venv_mitsui_condapy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
