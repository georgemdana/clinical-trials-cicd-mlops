{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef112a06-1ff5-41a3-ab40-7ec260c1e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/bin/python\n",
      "Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:20) [Clang 17.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "######################################## Check Environment ########################################\n",
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "420d431f-e164-4c22-9e4f-ad7b9e9ed80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/danageorge/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################################## Install packages ########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create chunks\n",
    "import re\n",
    "\n",
    "# Model for NER\n",
    "import spacy \n",
    "from sklearn.cluster import KMeans\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "#UMLSClient for NER\n",
    "import umls_api\n",
    "from umls_api_client import UMLS\n",
    "from quickumls import QuickUMLS\n",
    "\n",
    "# Use natural language processing (NLP) to extract keywords from the criteria\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Performance\n",
    "import sklearn\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5fdc997-2323-400b-b5b5-e8b779cc070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://login.microsoftonline.com/bbaf0319-e615-416f-8870-f7eacf074b66/saml2?SAMLRequest=nZJNc9owEIb%2Fikc925YM5UMDZCg0hSlpGCBtpzfZXoMGWQKtjBN%2BfYUJM%2BkhOfSmkZ5dPdK7g7vnUgUnsCiNHhIWURKAzkwu9XZInjb3YY8E6ITOhTIahuQFkNyNBihKdeDjyu30Co4VoAt8I428ORiSympuBErkWpSA3GV8PX5Y8CSi%2FGCNM5lR5E3JxxUCEazzhreSHKXX2zl34HFc13VUtyJjt3FCKY1pP%2FbUBfl045%2F9m97hWUzbF94THl%2B%2Bun2R%2BvoFH2mlVwj5bLNZhsvH9YYE45vqxGisSrBrsCeZwdNqcRVAb4B7Qdv9Fo1AoAsrDJNInCsLEWpTF0rsITPloXK%2BeeRXcQF5rMxW%2BvfPp0Ny2Mu8%2Bo678jx7PCy6s1%2BT0%2B%2F9alUc07M%2Bj78e1fRbOtsatm7tU9fvZST4eQs4uQQ8R6xgri%2BxOr9Fk3bIWJiwDWM8SThtRUnS%2FUOCqY9VauGaypt74xGVMrMGTeGMVlJDY5mmoqAt1g%2Bhwz6HbdYpwl6vS8OiCyIraLeddjrxJeyEXAeINyJ29J%2FfMojfNnkdyR8%2Bpfl0aZTMXoJ7Y0vh3g%2BRRazZkXlYNCiHUkg1znMLiD5MpUw9sSCcn3xnKyDx6Hrrv7M%2F%2Bgs%3D&RelayState=51110 to authenticate...\n",
      "Snowflake version: 8.43.0\n"
     ]
    }
   ],
   "source": [
    "######################################## Connect to Snowflake ########################################\n",
    "\n",
    "# Establish a connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user='dana_george@hakkoda.io',\n",
    "    authenticator='externalbrowser',\n",
    "    account='ska04930.east-us-2.azure',\n",
    "    warehouse='DATASCIENCE_WH',\n",
    "    database='ONCOEMR_RAW_DEV',\n",
    "    schema='DBO',\n",
    "    role='ACCOUNTADMIN'\n",
    ")\n",
    "\n",
    "# Run a test query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
    "row = cursor.fetchone()\n",
    "print(\"Snowflake version:\", row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c0af24-5888-4593-a386-e6e6259a5e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      " \n",
      "Tables Loaded:\n",
      "ADMINISTRATIONS\n",
      "ADVANCEDIRECTIVES\n",
      "ALLERGY\n",
      "CHARGE\n",
      "DEMOGRAHPICS\n",
      "DEMOGRAPHICS\n",
      "DIAGNOSIS\n",
      "DISEASESTATUS\n",
      "ERX\n",
      "FAMILYHISTORY\n",
      "HOSPITALIZATION\n",
      "INSURANCE\n",
      "LABS\n",
      "ORDERS\n",
      "RADIOLOGY\n",
      "REFERRINGPROVIDER\n",
      "SOCIALHISTORY\n",
      "TRANSFUSION\n",
      "GRADESCALES\n",
      "SURGICALHISTORY\n",
      "PERFORMANCE\n",
      "VISIT\n",
      "BIOMARKERS\n",
      "TOXICITIES\n",
      "MEDICATIONLIST\n",
      "STAGING\n",
      "DATA_HISTORY\n",
      "PATIENT_LOCATION_HISTORY\n",
      "ORDER_CHARGE_HISTORY\n",
      "TREATMENT_CURRENT_HISTORY\n",
      "VITAL_SIGN_HISTORY\n",
      "TREATMENT_PREVIOUS_HISTORY\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'breastcancer_incl.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 87\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Now you can access the DataFrames as individual variables:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print(ADMINISTRATIONS.head())\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Bring in clinical trial data\u001b[39;00m\n\u001b[1;32m     86\u001b[0m clinical_trials_excl \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclinical_trials_data_simple_exclusion.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m clinical_trials_incl \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbreastcancer_incl.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclinical_trials_data_simple_exclusion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclinical_trials_data_simple_inclusion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/venv_mitsui_condapy310/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'breastcancer_incl.csv'"
     ]
    }
   ],
   "source": [
    "######################################## Load Data ########################################\n",
    "\n",
    "# Get sample patient ids\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
    "    ORDER BY RANDOM()\n",
    "\"\"\")\n",
    "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
    "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'DBO'\n",
    "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
    "    AND table_type = 'BASE TABLE';\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all the table names\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "#print(tables)\n",
    "\n",
    "# Create a dictionary to hold each table as a DataFrame\n",
    "table_dataframes = {}\n",
    "table_dataframes_spat = {}\n",
    "\n",
    "for table in tables:\n",
    "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
    "    \"\"\")\n",
    "    \n",
    "    columns = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    # If 'patientid' is a column, proceed to query the table\n",
    "    if 'patientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "    # If 'spatientid' is a column, proceed to query the table\n",
    "    if 'spatientid' in columns:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
    "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch the result and convert it to a DataFrame\n",
    "        results_spat = cursor.fetchall()\n",
    "        columns_spat = [desc[0] for desc in cursor.description]\n",
    "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
    "\n",
    "# Merge table_dataframes_spat into table_dataframes_pat\n",
    "table_dataframes.update(table_dataframes_spat)\n",
    "\n",
    "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
    "print(\"Data Loaded Successfully!\")\n",
    "print(\" \")\n",
    "print(\"Tables Loaded:\")\n",
    "for table, df in table_dataframes.items():\n",
    "    print(f\"{table}\")\n",
    "    #print(df.head())\n",
    "\n",
    "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
    "for table, df in table_dataframes.items():\n",
    "    globals()[table] = df\n",
    "\n",
    "# Now you can access the DataFrames as individual variables:\n",
    "# print(ADMINISTRATIONS.head())\n",
    "\n",
    "# Bring in clinical trial data\n",
    "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
    "clinical_trials_incl = pd.read_csv('lungcancer_incl.csv')\n",
    "print(\"clinical_trials_data_simple_exclusion\")\n",
    "print(\"clinical_trials_data_simple_inclusion\")\n",
    "print(\" \")\n",
    "\n",
    "def print_columns_of_dict_of_dfs(df_dict):\n",
    "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
    "\n",
    "    for df_name, df in df_dict.items():\n",
    "        print(f\"Columns of {df_name}:\")\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "# Call the function to print the columns\n",
    "print_columns_of_dict_of_dfs(table_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "112b909a-3fe7-4a3a-bb29-0ff963fdacf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete!\n"
     ]
    }
   ],
   "source": [
    "######################################## Feature Engineering ########################################\n",
    "\n",
    "# Convert non-numeric values to NaN\n",
    "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
    "\n",
    "# Now, convert the column to integers (NaNs will remain as NaN)\n",
    "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
    "print(\"Feature Engineering Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba6c4807-c0a9-4eac-827a-0c2a1960f310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Trial_Name', 'Trial_ID', 'Inclusion_Criteria', 'Category',\n",
      "       'Source_Columns'],\n",
      "      dtype='object')\n",
      "      RowID clientid                             patientid patientmrn  \\\n",
      "0    112304   CA0026  D6288764-EBAB-429D-9D6E-BA5152340FDD       None   \n",
      "1    158902   CA0026  548CD51B-9AC0-4A25-9D48-B6D08675DD00       None   \n",
      "2       924   CA0026  A552A6C5-63DB-4152-B0E3-4C1A94C9CF27       None   \n",
      "3    109938   CA0026  ECCE7682-F192-4E4B-8915-D3808F81E60E       None   \n",
      "4    131886   CA0026  B995B177-DA99-4BEF-9818-8E40DCD9841D       None   \n",
      "..      ...      ...                                   ...        ...   \n",
      "995     148   CA0026  9D1DAE72-E47F-453C-AF06-12AA2B97855C       None   \n",
      "996     228   CA0026  E393B5A7-862D-43DD-97A2-4B2075FBD297       None   \n",
      "997     398   CA0026  F90AA3C5-D2D7-4A6E-AFC5-024A1F912112       None   \n",
      "998     878   CA0026  BE19FCC3-3107-400D-9C0B-1A6C3ADB8D5E       None   \n",
      "999     275   CA0026  F124E3E2-C129-4FA2-8144-BF11CEC44CFB       None   \n",
      "\n",
      "    patientssn         primaryphysicianid   dob  birthyear  age   dod  ...  \\\n",
      "0         None  PH_2E0C6FDB8CA0035D2FABD0  None     1944.0   79  None  ...   \n",
      "1         None  PH_B124FEEF1BE70F214EB8C8  None     1962.0   61  None  ...   \n",
      "2         None         UID_MA206161585_30  None     1973.0   50  None  ...   \n",
      "3         None  PH_82AFB13F99200B0A05DAD7  None     1981.0   42  None  ...   \n",
      "4         None  PH_B124FEEF1BE70F214EB8C8  None     1960.0   63  None  ...   \n",
      "..         ...                        ...   ...        ...  ...   ...  ...   \n",
      "995       None                       None  None        NaN   99  None  ...   \n",
      "996       None                       None  None        NaN   97  None  ...   \n",
      "997       None                       None  None        NaN   92  None  ...   \n",
      "998       None                       None  None        NaN  117  None  ...   \n",
      "999       None                       None  None        NaN   97  None  ...   \n",
      "\n",
      "     lastname firstname emailaddress phonenumber middlename    status  \\\n",
      "0        None      None         None        None       None  Deceased   \n",
      "1        None      None         None        None       None  Deceased   \n",
      "2        None      None         None        None       None  Deceased   \n",
      "3        None      None         None        None       None  Deceased   \n",
      "4        None      None         None        None       None  Deceased   \n",
      "..        ...       ...          ...         ...        ...       ...   \n",
      "995      None      None         None        None       None    Active   \n",
      "996      None      None         None        None       None    Active   \n",
      "997      None      None         None        None       None    Active   \n",
      "998      None      None         None        None       None    Active   \n",
      "999      None      None         None        None       None    Active   \n",
      "\n",
      "             statusdate TrialPatientIndicator    LogDate DeathYear  \n",
      "0   2022-08-31 12:04:27                   Yes 2024-02-12    2022.0  \n",
      "1   2022-12-23 18:18:43                   Yes 2024-02-12    2022.0  \n",
      "2   2022-01-17 13:37:13                    No 2024-02-12    2022.0  \n",
      "3   2023-11-08 13:57:03                   Yes 2024-02-12    2022.0  \n",
      "4   2022-09-19 12:45:19                   Yes 2024-02-12    2022.0  \n",
      "..                  ...                   ...        ...       ...  \n",
      "995                 NaT                    No 2024-02-12       NaN  \n",
      "996                 NaT                    No 2024-02-12       NaN  \n",
      "997                 NaT                    No 2024-02-12       NaN  \n",
      "998                 NaT                    No 2024-02-12       NaN  \n",
      "999                 NaT                    No 2024-02-12       NaN  \n",
      "\n",
      "[1000 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################## Quality Check ########################################\n",
    "print(clinical_trials_incl.columns)\n",
    "print(DEMOGRAPHICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7865d0fd-f717-453e-a2fc-88c5dd035db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "921\n",
      "      RowID clientid_x                             patientid patientmrn  \\\n",
      "144   87883     CA0026  6A1C01D3-7500-43C3-911F-0CC2396A064E       None   \n",
      "145   87883     CA0026  6A1C01D3-7500-43C3-911F-0CC2396A064E       None   \n",
      "238     867     CA0026  FC9D1DFA-C3FE-49EB-9345-CD1B03B3248E       None   \n",
      "239     867     CA0026  FC9D1DFA-C3FE-49EB-9345-CD1B03B3248E       None   \n",
      "603       6     CA0026  308DA9C9-C288-48CC-B445-DB497DCCCE92       None   \n",
      "...     ...        ...                                   ...        ...   \n",
      "4253    508     CA0026  7C060B0B-4A5E-4242-9BBC-87CA877D10BB       None   \n",
      "4271    773     CA0026  27B8359C-56B3-4716-A252-7E0EF090412A       None   \n",
      "4294    874     CA0026  FCB57CE8-02CE-46EF-810B-60592A418623       None   \n",
      "4326    206     CA0026  4AEAE5F0-9EC7-4B55-AC30-5D8C5A16250D       None   \n",
      "4327    206     CA0026  4AEAE5F0-9EC7-4B55-AC30-5D8C5A16250D       None   \n",
      "\n",
      "     patientssn         primaryphysicianid   dob  birthyear  age   dod  ...  \\\n",
      "144        None  PH_4F92721C0EAD0F3B9B746C  None     1949.0   74  None  ...   \n",
      "145        None  PH_4F92721C0EAD0F3B9B746C  None     1949.0   74  None  ...   \n",
      "238        None  PH_0B3995AA42A401B9E6F1CD  None     1950.0   73  None  ...   \n",
      "239        None  PH_0B3995AA42A401B9E6F1CD  None     1950.0   73  None  ...   \n",
      "603        None         UID_MA206161585_30  None     1936.0   87  None  ...   \n",
      "...         ...                        ...   ...        ...  ...   ...  ...   \n",
      "4253       None          UID_MA206161585_7  None     1963.0   60  None  ...   \n",
      "4271       None         UID_MA206161585_30  None     1943.0   80  None  ...   \n",
      "4294       None                       None  None     1940.0   83  None  ...   \n",
      "4326       None          UID_MA206161585_7  None        NaN  102  None  ...   \n",
      "4327       None          UID_MA206161585_7  None        NaN  102  None  ...   \n",
      "\n",
      "      diagnosiscode diagnosiscodesys targetdiagnosiscode  \\\n",
      "144         C50.912        ICD-10-CM             C50.912   \n",
      "145         C50.019        ICD-10-CM             C50.019   \n",
      "238         C50.411        ICD-10-CM             C50.411   \n",
      "239           174.8         ICD-9-CM               174.8   \n",
      "603           174.8         ICD-9-CM               174.8   \n",
      "...             ...              ...                 ...   \n",
      "4253          233.0         ICD-9-CM               233.0   \n",
      "4271          174.9         ICD-9-CM               174.9   \n",
      "4294          174.4         ICD-9-CM               174.4   \n",
      "4326          174.4         ICD-9-CM               174.4   \n",
      "4327        C50.419        ICD-10-CM             C50.419   \n",
      "\n",
      "     targetdiagnosiscodesys  \\\n",
      "144               ICD-10-CM   \n",
      "145               ICD-10-CM   \n",
      "238               ICD-10-CM   \n",
      "239                ICD-9-CM   \n",
      "603                ICD-9-CM   \n",
      "...                     ...   \n",
      "4253               ICD-9-CM   \n",
      "4271               ICD-9-CM   \n",
      "4294               ICD-9-CM   \n",
      "4326               ICD-9-CM   \n",
      "4327              ICD-10-CM   \n",
      "\n",
      "                             targetdiagnosisdescription  \\\n",
      "144   Malignant neoplasm of unspecified site of left...   \n",
      "145   Malignant neoplasm of nipple and areola, unspe...   \n",
      "238   Malignant neoplasm of upper-outer quadrant of ...   \n",
      "239   Malignant neoplasm of other specified sites of...   \n",
      "603   Malignant neoplasm of other specified sites of...   \n",
      "...                                                 ...   \n",
      "4253                        Carcinoma in situ of breast   \n",
      "4271  Malignant neoplasm of breast (female), unspeci...   \n",
      "4294  Malignant neoplasm of upper-outer quadrant of ...   \n",
      "4326  Malignant neoplasm of upper-outer quadrant of ...   \n",
      "4327  Malignant neoplasm of upper-outer quadrant of ...   \n",
      "\n",
      "       targetdetaileddiagnosisgroup targetdiagnosisgroup cancerdiagnosisind  \\\n",
      "144         Cancer of female breast               Breast                  Y   \n",
      "145         Cancer of female breast               Breast                  Y   \n",
      "238         Cancer of female breast               Breast                  Y   \n",
      "239         Cancer of female breast               Breast                  Y   \n",
      "603         Cancer of female breast               Breast                  Y   \n",
      "...                             ...                  ...                ...   \n",
      "4253  In situ cancer of  breast NOS               Breast                  Y   \n",
      "4271        Cancer of female breast               Breast                  Y   \n",
      "4294        Cancer of female breast               Breast                  Y   \n",
      "4326        Cancer of female breast               Breast                  Y   \n",
      "4327        Cancer of female breast               Breast                  Y   \n",
      "\n",
      "                diseaseid Expert_Decision_Disease  \n",
      "144   3744070510199456322                       1  \n",
      "145   3744070510199456322                       1  \n",
      "238   3744070510199456322                       1  \n",
      "239   3744070510199456322                       1  \n",
      "603   3744070510199456322                       1  \n",
      "...                   ...                     ...  \n",
      "4253                 None                       1  \n",
      "4271  3744070510199456322                       1  \n",
      "4294  3744070510199456322                       1  \n",
      "4326  3744070510199456322                       1  \n",
      "4327  3744070510199456322                       1  \n",
      "\n",
      "[101 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################## Build Mock Expert Decision ########################################\n",
    "# Perform the LEFT JOIN\n",
    "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
    "\n",
    "# Filter using \"LIKE\" equivalent\n",
    "eligible = merged_df[\n",
    "    # (merged_df['age'] >= 18) &\n",
    "    # (merged_df['gender'] == 'Female') &\n",
    "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('breast', case=False, na=False)) &\n",
    "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
    "]\n",
    "\n",
    "# # For evaluation metrics later\n",
    "# eligible['Expert_Decision_Age'] = 1\n",
    "# eligible['Expert_Decision_Gender'] = 1\n",
    "eligible['Expert_Decision_Disease'] = 1\n",
    "\n",
    "#distinct_count = eligible['patientid'].nunique()\n",
    "\n",
    "# Extract patient IDs that match the expert's eligibility criteria\n",
    "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
    "\n",
    "# Get patient IDs that are not in the eligible list\n",
    "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
    "\n",
    "print(len(eligible_patient_ids))\n",
    "print(len(ineligible_patient_ids))\n",
    "\n",
    "print(eligible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413bca5f-ef11-4c9d-8688-6e3fef8d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible.to_csv('test_eligible.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea0ed51-9c15-41a8-830a-154b5a8f11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: breast cancer, Label: DISEASE\n",
      "Entity: Tamoxifen, Label: CHEMICAL\n",
      "Entity: 18 years old, Label: AGE\n",
      "Entity: female, Label: GENDER\n"
     ]
    }
   ],
   "source": [
    "# ######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - 1 line of text, model testing ########################################\n",
    "\n",
    "# ### Test to apply to 1 line of text\n",
    "# ### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# # Load the MedSpaCy model\n",
    "# nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# # Process your text\n",
    "# text = \"The patient is a female 18 years old and was diagnosed with breast cancer and prescribed Tamoxifen.\"\n",
    "\n",
    "# # Function to extract entities and labels\n",
    "# def extract_entities(text):\n",
    "#     doc = nlp(text)\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "#     # Custom check for age-related information (e.g., \"18 years old\")\n",
    "#     age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "#     age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "#     # If age-related information is found, add it to the entities with the correct label\n",
    "#     for age in age_matches:\n",
    "#         entities.append((f\"{age} years old\", 'AGE'))\n",
    "    \n",
    "#     # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "#     gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "#     # Check for the first gender-related term match (female first, then male)\n",
    "#     gender_found = False\n",
    "#     for gender in gender_keywords:\n",
    "#         match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "#         if match:\n",
    "#             entities.append((match.group(), 'GENDER'))\n",
    "#             break  # Once a match is found, stop further checking\n",
    "\n",
    "#     return entities\n",
    "\n",
    "# # Display named entities and custom additions\n",
    "# entities = extract_entities(text)\n",
    "# for ent in entities:\n",
    "#     print(f\"Entity: {ent[0]}, Label: {ent[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e491783-7d24-49d8-a9ee-2a0963cd335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial_Name  Trial_ID          Inclusion_Criteria Category  \\\n",
      "0  Test_Trial       123            Aged 18 or over.      AGE   \n",
      "1  Test_Trial       123                      Female   GENDER   \n",
      "2  Test_Trial       123  Diagnosed with Lung Cancer  DISEASE   \n",
      "\n",
      "                           Source_Columns  \n",
      "0                        DEMOGRAHPICS.age  \n",
      "1                     DEMOGRAHPICS.gender  \n",
      "2  DIAGNOSIS.targetdetaileddiagnosisgroup  \n"
     ]
    }
   ],
   "source": [
    "######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - Clinical Trial Dataframe ########################################\n",
    "\n",
    "### Apply to a dataframe of trial data\n",
    "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
    "\n",
    "# Load the MedSpaCy model\n",
    "nlp = spacy.load('en_ner_bc5cdr_md')\n",
    "\n",
    "# Function to extract entities and labels\n",
    "def extract_entities(text):\n",
    "    # Process the text through the NLP model\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    # Custom check for age-related information (e.g., \"18 years old\")\n",
    "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
    "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If age-related information is found, add it to the entities with the correct label\n",
    "    for age in age_matches:\n",
    "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
    "    \n",
    "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
    "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
    "    \n",
    "    # Check for the first gender-related term match (female first, then male)\n",
    "    gender_found = False\n",
    "    for gender in gender_keywords:\n",
    "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
    "        if match:\n",
    "            entities.append((match.group(), 'GENDER'))\n",
    "            break  # Once a match is found, stop further checking\n",
    "\n",
    "    # Extract the unique labels to avoid duplicates and return them\n",
    "    unique_labels = set([label for _, label in entities])\n",
    "    return list(unique_labels)\n",
    "\n",
    "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
    "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1a0444-d109-4fed-866d-cd0445090f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial_Name  Trial_ID          Inclusion_Criteria Category  \\\n",
      "0  Test_Trial       123            Aged 18 or over.      AGE   \n",
      "1  Test_Trial       123                      Female   GENDER   \n",
      "2  Test_Trial       123  Diagnosed with Lung Cancer  DISEASE   \n",
      "\n",
      "                           Source_Columns  \n",
      "0                        DEMOGRAHPICS.age  \n",
      "1                     DEMOGRAHPICS.gender  \n",
      "2  DIAGNOSIS.targetdetaileddiagnosisgroup  \n"
     ]
    }
   ],
   "source": [
    "######################################## Use Fuzzy: Find columns in Patient Data that match Trial Inclusion Criteria ########################################\n",
    "\n",
    "# Function to find exact matches and fuzzy matches\n",
    "def find_matching_columns(category, dict_of_dfs, fuzzy_threshold=80):\n",
    "    if category.lower() == 'disease':\n",
    "        return ['DIAGNOSIS.targetdetaileddiagnosisgroup']\n",
    "    \n",
    "    # Step 1: Find exact matches (case-insensitive)\n",
    "    exact_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        if category.lower() in [col.lower() for col in df.columns]:\n",
    "            exact_column = next(col for col in df.columns if col.lower() == category.lower())\n",
    "            exact_matches.append(f'{df_name}.{exact_column}')\n",
    "            return exact_matches  # Return immediately after finding an exact match\n",
    "    \n",
    "    # Step 2: If no exact match, find fuzzy matches\n",
    "    fuzzy_matches = []\n",
    "    for df_name, df in dict_of_dfs.items():\n",
    "        columns = df.columns\n",
    "        for column in columns:\n",
    "            score = process.extractOne(category, [column])  # Compare category with each column\n",
    "            if score and score[1] >= fuzzy_threshold:  # If score is above threshold\n",
    "                fuzzy_matches.append(f'{df_name}.{column}')\n",
    "    \n",
    "    return fuzzy_matches\n",
    "\n",
    "# Loop through the clinical_trials_incl DataFrame and apply matching function\n",
    "def add_source_columns(clinical_trials_incl, table_dataframes):\n",
    "    source_columns_list = []\n",
    "    \n",
    "    for index, row in clinical_trials_incl.iterrows():\n",
    "        category = row['Category']\n",
    "        matching_columns = find_matching_columns(category, table_dataframes)\n",
    "        \n",
    "        # If there are multiple matches, list them, else return 'No match'\n",
    "        if matching_columns:\n",
    "            source_columns_list.append(', '.join(matching_columns))\n",
    "        else:\n",
    "            source_columns_list.append('No match')\n",
    "    \n",
    "    clinical_trials_incl['Source_Columns'] = source_columns_list\n",
    "    return clinical_trials_incl\n",
    "\n",
    "# Apply the function to the clinical_trials_incl DataFrame\n",
    "clinical_trials_incl_ner = add_source_columns(clinical_trials_incl, table_dataframes)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(clinical_trials_incl_ner)\n",
    "\n",
    "######################### Now the clinical trial data is ready. #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f6deb0-9a73-49fe-9075-a8f3bd33ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Patient_ID  Trial_Name  Trial_ID  \\\n",
      "0     3B9D9B16-023D-469F-8987-B4450C785B4B  Test_Trial       123   \n",
      "1     3B9D9B16-023D-469F-8987-B4450C785B4B  Test_Trial       123   \n",
      "2     3B9D9B16-023D-469F-8987-B4450C785B4B  Test_Trial       123   \n",
      "3     3B9D9B16-023D-469F-8987-B4450C785B4B  Test_Trial       123   \n",
      "4     3B9D9B16-023D-469F-8987-B4450C785B4B  Test_Trial       123   \n",
      "...                                    ...         ...       ...   \n",
      "4377  E26D1D02-CD6A-40F6-A992-4893CB54D47C  Test_Trial       123   \n",
      "4378  E26D1D02-CD6A-40F6-A992-4893CB54D47C  Test_Trial       123   \n",
      "4379  E26D1D02-CD6A-40F6-A992-4893CB54D47C  Test_Trial       123   \n",
      "4380  98FDD64B-2E15-4F54-AC6C-1BDC23277408  Test_Trial       123   \n",
      "4381  E7E47811-0A63-45E1-9F3B-1C1C55E45062  Test_Trial       123   \n",
      "\n",
      "              Inclusion_Criteria Category  \\\n",
      "0     Diagnosed with Lung Cancer  DISEASE   \n",
      "1     Diagnosed with Lung Cancer  DISEASE   \n",
      "2     Diagnosed with Lung Cancer  DISEASE   \n",
      "3     Diagnosed with Lung Cancer  DISEASE   \n",
      "4     Diagnosed with Lung Cancer  DISEASE   \n",
      "...                          ...      ...   \n",
      "4377  Diagnosed with Lung Cancer  DISEASE   \n",
      "4378  Diagnosed with Lung Cancer  DISEASE   \n",
      "4379  Diagnosed with Lung Cancer  DISEASE   \n",
      "4380  Diagnosed with Lung Cancer  DISEASE   \n",
      "4381  Diagnosed with Lung Cancer  DISEASE   \n",
      "\n",
      "                               Source_Column  \\\n",
      "0     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "1     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "2     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "3     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4     DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "...                                      ...   \n",
      "4377  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4378  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4379  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4380  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "4381  DIAGNOSIS.targetdetaileddiagnosisgroup   \n",
      "\n",
      "                               Source_Value  Match_Percentage  \\\n",
      "0     Other benign hematological conditions         28.264013   \n",
      "1     Other benign hematological conditions         28.264013   \n",
      "2     Other benign hematological conditions         28.264013   \n",
      "3               Cancer of exocrine pancreas         99.999988   \n",
      "4               Cancer of exocrine pancreas         99.999988   \n",
      "...                                     ...               ...   \n",
      "4377                                   None          0.000000   \n",
      "4378                                   None          0.000000   \n",
      "4379                                   None          0.000000   \n",
      "4380                                   None          0.000000   \n",
      "4381                                   None          0.000000   \n",
      "\n",
      "      Expert_Decision_Disease  \n",
      "0                           0  \n",
      "1                           0  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           0  \n",
      "...                       ...  \n",
      "4377                        0  \n",
      "4378                        0  \n",
      "4379                        0  \n",
      "4380                        0  \n",
      "4381                        0  \n",
      "\n",
      "[4382 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to match patients to trial criteria\n",
    "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
    "    results = []\n",
    "    all_patient_ids = set()\n",
    "\n",
    "    # Collect all unique patient IDs\n",
    "    for df in table_dataframes.values():\n",
    "        if 'patientid' in df.columns:\n",
    "            all_patient_ids.update(df['patientid'].unique())\n",
    "\n",
    "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
    "        trial_name = row['Trial_Name']\n",
    "        trial_id = row['Trial_ID']\n",
    "        inclusion_criteria = row['Inclusion_Criteria']\n",
    "        category = row['Category']\n",
    "        source_column = row['Source_Columns']\n",
    "        \n",
    "        table_name, column_name = source_column.split('.')\n",
    "        \n",
    "        if table_name in table_dataframes:\n",
    "            df = table_dataframes[table_name]\n",
    "            \n",
    "            if column_name in df.columns:\n",
    "                for patient_id in all_patient_ids:\n",
    "                    patient_rows = df[df['patientid'] == patient_id]\n",
    "                    \n",
    "                    if not patient_rows.empty:\n",
    "                        for _, patient_row in patient_rows.iterrows():\n",
    "                            source_value = patient_row[column_name]\n",
    "                            match_percentage = (\n",
    "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
    "                                if pd.notna(source_value) else 0\n",
    "                            )\n",
    "                            \n",
    "                            results.append({\n",
    "                                'Patient_ID': patient_id,\n",
    "                                'Trial_Name': trial_name,\n",
    "                                'Trial_ID': trial_id,\n",
    "                                'Inclusion_Criteria': inclusion_criteria,\n",
    "                                'Category': category,\n",
    "                                'Source_Column': source_column,\n",
    "                                'Source_Value': source_value,\n",
    "                                'Match_Percentage': match_percentage\n",
    "                            })\n",
    "                    else:\n",
    "                        # If no matching rows, include a null result\n",
    "                        results.append({\n",
    "                            'Patient_ID': patient_id,\n",
    "                            'Trial_Name': trial_name,\n",
    "                            'Trial_ID': trial_id,\n",
    "                            'Inclusion_Criteria': inclusion_criteria,\n",
    "                            'Category': category,\n",
    "                            'Source_Column': source_column,\n",
    "                            'Source_Value': None,\n",
    "                            'Match_Percentage': 0\n",
    "                        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Usage\n",
    "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
    "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
    "\n",
    "# Ensure column names match exactly\n",
    "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
    "\n",
    "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
    "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
    "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
    "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
    "                else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(matched_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0adf96dc-e460-4791-93a5-764183bf0346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Category: DISEASE\n",
      "\n",
      "Patients Eligible: 78\n",
      "Patients Ineligible: 921\n",
      "\n",
      "Overall Results:\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3730  555]\n",
      " [  94    3]]\n",
      "\n",
      "Cohen's Kappa Score: -0.029674600410288576\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################## Evaluate by Inclusion Criteria ########################################\n",
    "\n",
    "eval_result_df_disease = matched_disease.copy()\n",
    "eval_result_df_disease['Model_Decision'] = eval_result_df_disease['Match_Percentage'].apply(lambda x: 1 if x > 95 else 0)\n",
    "\n",
    "# Calculate overall confusion matrix and kappa score\n",
    "y_true_disease = eval_result_df_disease['Expert_Decision_Disease']\n",
    "y_pred_disease = eval_result_df_disease['Model_Decision']\n",
    "\n",
    "conf_matrix_disease = confusion_matrix(y_true_disease, y_pred_disease)\n",
    "kappa_score_disease = cohen_kappa_score(y_true_disease, y_pred_disease)\n",
    "\n",
    "# Print overall results\n",
    "# Print summary of eligible and ineligible patients\n",
    "print(f\"Results for Category: DISEASE\")\n",
    "print(f\"\\nPatients Eligible: {len(eligible_patient_ids)}\")\n",
    "print(f\"Patients Ineligible: {len(ineligible_patient_ids)}\")\n",
    "print(\"\\nOverall Results:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_disease)\n",
    "print(\"\\nCohen's Kappa Score:\", kappa_score_disease)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cca6e2a-2685-4bed-9899-ac28f0ef57d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Install packages ########################################\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "# Create chunks\n",
      "import re\n",
      "\n",
      "# Model for NER\n",
      "import spacy \n",
      "from sklearn.cluster import KMeans\n",
      "import medspacy\n",
      "from medspacy.ner import TargetRule\n",
      "from thefuzz import fuzz, process\n",
      "\n",
      "#UMLSClient for NER\n",
      "import umls_api\n",
      "from umls_api_client import UMLS\n",
      "from quickumls import QuickUMLS\n",
      "\n",
      "# Use natural language processing (NLP) to extract keywords from the criteria\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "nltk.download('stopwords')\n",
      "nltk.download('punkt_tab')\n",
      "nltk.download('wordnet')\n",
      "from sentence_transformers import SentenceTransformer, util\n",
      "\n",
      "# Performance\n",
      "import sklearn\n",
      "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "\n",
      "import snowflake.connector\n",
      "######################################## Connect to Snowflake ########################################\n",
      "\n",
      "# Establish a connection\n",
      "conn = snowflake.connector.connect(\n",
      "    user='dana_george@hakkoda.io',\n",
      "    authenticator='externalbrowser',\n",
      "    account='ska04930.east-us-2.azure',\n",
      "    warehouse='DATASCIENCE_WH',\n",
      "    database='ONCOEMR_RAW_DEV',\n",
      "    schema='DBO',\n",
      "    role='ACCOUNTADMIN'\n",
      ")\n",
      "\n",
      "# Run a test query\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
      "row = cursor.fetchone()\n",
      "print(\"Snowflake version:\", row[0])\n",
      "######################################## Connect to Snowflake ########################################\n",
      "\n",
      "# Establish a connection\n",
      "conn = snowflake.connector.connect(\n",
      "    user='dana_george@hakkoda.io',\n",
      "    authenticator='externalbrowser',\n",
      "    account='ska04930.east-us-2.azure',\n",
      "    warehouse='DATASCIENCE_WH',\n",
      "    database='ONCOEMR_RAW_DEV',\n",
      "    schema='DBO',\n",
      "    role='ACCOUNTADMIN'\n",
      ")\n",
      "\n",
      "# Run a test query\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
      "row = cursor.fetchone()\n",
      "print(\"Snowflake version:\", row[0])\n",
      "######################################## Load Data ########################################\n",
      "\n",
      "# Get sample patient ids\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
      "    ORDER BY RANDOM()\n",
      "\"\"\")\n",
      "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
      "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
      "\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT table_name\n",
      "    FROM information_schema.tables\n",
      "    WHERE table_schema = 'DBO'\n",
      "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
      "    AND table_type = 'BASE TABLE';\n",
      "\"\"\")\n",
      "\n",
      "# Fetch all the table names\n",
      "tables = [row[0] for row in cursor.fetchall()]\n",
      "#print(tables)\n",
      "\n",
      "# Create a dictionary to hold each table as a DataFrame\n",
      "table_dataframes = {}\n",
      "table_dataframes_spat = {}\n",
      "\n",
      "for table in tables:\n",
      "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
      "    cursor.execute(f\"\"\"\n",
      "        SELECT column_name\n",
      "        FROM information_schema.columns\n",
      "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
      "    \"\"\")\n",
      "    \n",
      "    columns = [row[0] for row in cursor.fetchall()]\n",
      "    \n",
      "    # If 'patientid' is a column, proceed to query the table\n",
      "    if 'patientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results = cursor.fetchall()\n",
      "        columns = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
      "\n",
      "    # If 'spatientid' is a column, proceed to query the table\n",
      "    if 'spatientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results_spat = cursor.fetchall()\n",
      "        columns_spat = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
      "\n",
      "# Merge table_dataframes_spat into table_dataframes_pat\n",
      "table_dataframes.update(table_dataframes_spat)\n",
      "\n",
      "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
      "print(\"Data Loaded Successfully!\")\n",
      "print(\" \")\n",
      "print(\"Tables Loaded:\")\n",
      "for table, df in table_dataframes.items():\n",
      "    print(f\"{table}\")\n",
      "    #print(df.head())\n",
      "\n",
      "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
      "for table, df in table_dataframes.items():\n",
      "    globals()[table] = df\n",
      "\n",
      "# Now you can access the DataFrames as individual variables:\n",
      "# print(ADMINISTRATIONS.head())\n",
      "\n",
      "# Bring in clinical trial data\n",
      "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
      "clinical_trials_incl = pd.read_csv('clinical_trials_data_simple_inclusion.csv')\n",
      "print(\"clinical_trials_data_simple_exclusion\")\n",
      "print(\"clinical_trials_data_simple_inclusion\")\n",
      "print(\" \")\n",
      "\n",
      "def print_columns_of_dict_of_dfs(df_dict):\n",
      "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
      "\n",
      "    for df_name, df in df_dict.items():\n",
      "        print(f\"Columns of {df_name}:\")\n",
      "        print(df.columns)\n",
      "        print(\"-\" * 20)\n",
      "\n",
      "# Call the function to print the columns\n",
      "print_columns_of_dict_of_dfs(table_dataframes)\n",
      "######################################## Feature Engineering ########################################\n",
      "\n",
      "# Convert non-numeric values to NaN\n",
      "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
      "\n",
      "# Now, convert the column to integers (NaNs will remain as NaN)\n",
      "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
      "print(\"Feature Engineering Complete!\")\n",
      "######################################## Quality Check ########################################\n",
      "print(clinical_trials_incl.columns)\n",
      "print(DEMOGRAPHICS)\n",
      "eligible.to_csv('test_eligible.csv', index=False)\n",
      "######################################## Build Mock Expert Decision ########################################\n",
      "# Perform the LEFT JOIN\n",
      "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
      "\n",
      "# Filter using \"LIKE\" equivalent\n",
      "eligible = merged_df[\n",
      "    # (merged_df['age'] >= 18) &\n",
      "    # (merged_df['gender'] == 'Female') &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('lung', case=False, na=False)) &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
      "]\n",
      "\n",
      "# # For evaluation metrics later\n",
      "# eligible['Expert_Decision_Age'] = 1\n",
      "# eligible['Expert_Decision_Gender'] = 1\n",
      "eligible['Expert_Decision_Disease'] = 1\n",
      "\n",
      "#distinct_count = eligible['patientid'].nunique()\n",
      "\n",
      "# Extract patient IDs that match the expert's eligibility criteria\n",
      "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
      "\n",
      "# Get patient IDs that are not in the eligible list\n",
      "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
      "\n",
      "print(len(eligible_patient_ids))\n",
      "print(len(ineligible_patient_ids))\n",
      "\n",
      "print(eligible)\n",
      "eligible.to_csv('test_eligible.csv', index=False)\n",
      "######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - Clinical Trial Dataframe ########################################\n",
      "\n",
      "### Apply to a dataframe of trial data\n",
      "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
      "\n",
      "# Load the MedSpaCy model\n",
      "nlp = spacy.load('en_ner_bc5cdr_md')\n",
      "\n",
      "# Function to extract entities and labels\n",
      "def extract_entities(text):\n",
      "    # Process the text through the NLP model\n",
      "    doc = nlp(text)\n",
      "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
      "\n",
      "    # Custom check for age-related information (e.g., \"18 years old\")\n",
      "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
      "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
      "    \n",
      "    # If age-related information is found, add it to the entities with the correct label\n",
      "    for age in age_matches:\n",
      "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
      "    \n",
      "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
      "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
      "    \n",
      "    # Check for the first gender-related term match (female first, then male)\n",
      "    gender_found = False\n",
      "    for gender in gender_keywords:\n",
      "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
      "        if match:\n",
      "            entities.append((match.group(), 'GENDER'))\n",
      "            break  # Once a match is found, stop further checking\n",
      "\n",
      "    # Extract the unique labels to avoid duplicates and return them\n",
      "    unique_labels = set([label for _, label in entities])\n",
      "    return list(unique_labels)\n",
      "\n",
      "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
      "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
      "\n",
      "# Display the updated DataFrame\n",
      "print(clinical_trials_incl)\n",
      "######################################## Use Fuzzy: Find columns in Patient Data that match Trial Inclusion Criteria ########################################\n",
      "\n",
      "# Function to find exact matches and fuzzy matches\n",
      "def find_matching_columns(category, dict_of_dfs, fuzzy_threshold=80):\n",
      "    if category.lower() == 'disease':\n",
      "        return ['DIAGNOSIS.targetdetaileddiagnosisgroup']\n",
      "    \n",
      "    # Step 1: Find exact matches (case-insensitive)\n",
      "    exact_matches = []\n",
      "    for df_name, df in dict_of_dfs.items():\n",
      "        if category.lower() in [col.lower() for col in df.columns]:\n",
      "            exact_column = next(col for col in df.columns if col.lower() == category.lower())\n",
      "            exact_matches.append(f'{df_name}.{exact_column}')\n",
      "            return exact_matches  # Return immediately after finding an exact match\n",
      "    \n",
      "    # Step 2: If no exact match, find fuzzy matches\n",
      "    fuzzy_matches = []\n",
      "    for df_name, df in dict_of_dfs.items():\n",
      "        columns = df.columns\n",
      "        for column in columns:\n",
      "            score = process.extractOne(category, [column])  # Compare category with each column\n",
      "            if score and score[1] >= fuzzy_threshold:  # If score is above threshold\n",
      "                fuzzy_matches.append(f'{df_name}.{column}')\n",
      "    \n",
      "    return fuzzy_matches\n",
      "\n",
      "# Loop through the clinical_trials_incl DataFrame and apply matching function\n",
      "def add_source_columns(clinical_trials_incl, table_dataframes):\n",
      "    source_columns_list = []\n",
      "    \n",
      "    for index, row in clinical_trials_incl.iterrows():\n",
      "        category = row['Category']\n",
      "        matching_columns = find_matching_columns(category, table_dataframes)\n",
      "        \n",
      "        # If there are multiple matches, list them, else return 'No match'\n",
      "        if matching_columns:\n",
      "            source_columns_list.append(', '.join(matching_columns))\n",
      "        else:\n",
      "            source_columns_list.append('No match')\n",
      "    \n",
      "    clinical_trials_incl['Source_Columns'] = source_columns_list\n",
      "    return clinical_trials_incl\n",
      "\n",
      "# Apply the function to the clinical_trials_incl DataFrame\n",
      "clinical_trials_incl_ner = add_source_columns(clinical_trials_incl, table_dataframes)\n",
      "\n",
      "# Display the updated DataFrame\n",
      "print(clinical_trials_incl_ner)\n",
      "\n",
      "######################### Now the clinical trial data is ready. #########################\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
      "\n",
      "# Load the SentenceTransformer model and biomedical NER pipeline\n",
      "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
      "\n",
      "# Load the biomedical-ner-all model\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
      "\n",
      "# Function to extract biomedical entities using the NER pipeline\n",
      "def extract_entities(text):\n",
      "    if not text:\n",
      "        return []\n",
      "    ner_results = biomedical_ner_pipeline(text)\n",
      "    return [entity['word'] for entity in ner_results]\n",
      "\n",
      "# Function to calculate match percentage using NER and cosine similarity\n",
      "def calculate_match_percentage(criteria, value):\n",
      "    if not criteria or not value:\n",
      "        return 0\n",
      "\n",
      "    # Extract entities from criteria and value\n",
      "    criteria_entities = extract_entities(criteria)\n",
      "    value_entities = extract_entities(value)\n",
      "    print(value)\n",
      "\n",
      "    # Use extracted entities if available, otherwise fallback to raw text\n",
      "    if criteria_entities and value_entities:\n",
      "        criteria_text = \" \".join(criteria_entities)\n",
      "        value_text = \" \".join(value_entities)\n",
      "    else:\n",
      "        criteria_text = str(criteria)\n",
      "        value_text = str(value)\n",
      "    \n",
      "    # Generate embeddings\n",
      "    criteria_embedding = transformer_model.encode([criteria_text])\n",
      "    value_embedding = transformer_model.encode([value_text])\n",
      "    \n",
      "    # Calculate cosine similarity\n",
      "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
      "    return similarity_score[0][0] * 100\n",
      "\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = {}\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                print(column_name)\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_row = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_row.empty and column_name in patient_row.columns:\n",
      "                        source_value = patient_row[column_name].iloc[0]\n",
      "                        match_percentage = calculate_match_percentage(inclusion_criteria, source_value)\n",
      "                    else:\n",
      "                        source_value = None\n",
      "                        match_percentage = 0\n",
      "                    \n",
      "                    key = (patient_id, trial_id, inclusion_criteria)\n",
      "                    \n",
      "                    if key not in results:\n",
      "                        results[key] = {\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': source_value,\n",
      "                            'Match_Percentage': match_percentage\n",
      "                        }\n",
      "                    else:\n",
      "                        if match_percentage > results[key]['Match_Percentage']:\n",
      "                            results[key]['Match_Percentage'] = match_percentage\n",
      "                            results[key]['Source_Value'] = source_value\n",
      "\n",
      "    return pd.DataFrame(list(results.values()))\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# # First, ensure that the column names match exactly\n",
      "# eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# # Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "# matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "#     lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "#                       (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "#                 else 0, \n",
      "#     axis=1\n",
      "# )\n",
      "\n",
      "# Display the first few rows of the merged DataFrame\n",
      "#print(matched_disease)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
      "\n",
      "# Load the SentenceTransformer model and biomedical NER pipeline\n",
      "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
      "\n",
      "# Load the biomedical-ner-all model\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
      "\n",
      "# Function to extract biomedical entities using the NER pipeline\n",
      "def extract_entities(text):\n",
      "    if not text:\n",
      "        return []\n",
      "    ner_results = biomedical_ner_pipeline(text)\n",
      "    return [entity['word'] for entity in ner_results]\n",
      "\n",
      "# Function to calculate match percentage using NER and cosine similarity\n",
      "def calculate_match_percentage(criteria, value):\n",
      "    if not criteria or not value:\n",
      "        return 0\n",
      "\n",
      "    # Extract entities from criteria and value\n",
      "    criteria_entities = extract_entities(criteria)\n",
      "    value_entities = extract_entities(value)\n",
      "\n",
      "    # Use extracted entities if available, otherwise fallback to raw text\n",
      "    if criteria_entities and value_entities:\n",
      "        criteria_text = \" \".join(criteria_entities)\n",
      "        value_text = \" \".join(value_entities)\n",
      "    else:\n",
      "        criteria_text = str(criteria)\n",
      "        value_text = str(value)\n",
      "    \n",
      "    # Generate embeddings\n",
      "    criteria_embedding = transformer_model.encode([criteria_text])\n",
      "    value_embedding = transformer_model.encode([value_text])\n",
      "    \n",
      "    # Calculate cosine similarity\n",
      "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
      "    return similarity_score[0][0] * 100\n",
      "\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = {}\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                print(column_name)\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_row = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_row.empty and column_name in patient_row.columns:\n",
      "                        source_value = patient_row[column_name].iloc[0]\n",
      "                        match_percentage = calculate_match_percentage(inclusion_criteria, source_value)\n",
      "                    else:\n",
      "                        source_value = None\n",
      "                        match_percentage = 0\n",
      "                    \n",
      "                    key = (patient_id, trial_id, inclusion_criteria)\n",
      "                    \n",
      "                    if key not in results:\n",
      "                        results[key] = {\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': source_value,\n",
      "                            'Match_Percentage': match_percentage\n",
      "                        }\n",
      "                    else:\n",
      "                        if match_percentage > results[key]['Match_Percentage']:\n",
      "                            results[key]['Match_Percentage'] = match_percentage\n",
      "                            results[key]['Source_Value'] = source_value\n",
      "\n",
      "    return pd.DataFrame(list(results.values()))\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# # First, ensure that the column names match exactly\n",
      "# eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# # Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "# matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "#     lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "#                       (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "#                 else 0, \n",
      "#     axis=1\n",
      "# )\n",
      "\n",
      "# Display the first few rows of the merged DataFrame\n",
      "#print(matched_disease)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
      "\n",
      "# Load the SentenceTransformer model and biomedical NER pipeline\n",
      "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
      "\n",
      "# Load the biomedical-ner-all model\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
      "\n",
      "# Function to extract biomedical entities using the NER pipeline\n",
      "def extract_entities(text):\n",
      "    if not text:\n",
      "        return []\n",
      "    ner_results = biomedical_ner_pipeline(text)\n",
      "    return [entity['word'] for entity in ner_results]\n",
      "\n",
      "# Function to calculate match percentage using NER and cosine similarity\n",
      "def calculate_match_percentage(criteria, value):\n",
      "    if not criteria or not value:\n",
      "        return 0\n",
      "\n",
      "    # Extract entities from criteria and value\n",
      "    criteria_entities = extract_entities(criteria)\n",
      "    value_entities = extract_entities(value)\n",
      "\n",
      "    # Use extracted entities if available, otherwise fallback to raw text\n",
      "    if criteria_entities and value_entities:\n",
      "        criteria_text = \" \".join(criteria_entities)\n",
      "        value_text = \" \".join(value_entities)\n",
      "    else:\n",
      "        criteria_text = str(criteria)\n",
      "        value_text = str(value)\n",
      "    \n",
      "    # Generate embeddings\n",
      "    criteria_embedding = transformer_model.encode([criteria_text])\n",
      "    value_embedding = transformer_model.encode([value_text])\n",
      "    \n",
      "    # Calculate cosine similarity\n",
      "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
      "    return similarity_score[0][0] * 100\n",
      "\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = {}\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_row = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_row.empty and column_name in patient_row.columns:\n",
      "                        source_value = patient_row[column_name].iloc[0]\n",
      "                        print(source_value)\n",
      "                        match_percentage = calculate_match_percentage(inclusion_criteria, source_value)\n",
      "                    else:\n",
      "                        source_value = None\n",
      "                        match_percentage = 0\n",
      "                    \n",
      "                    key = (patient_id, trial_id, inclusion_criteria)\n",
      "                    \n",
      "                    if key not in results:\n",
      "                        results[key] = {\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': source_value,\n",
      "                            'Match_Percentage': match_percentage\n",
      "                        }\n",
      "                    else:\n",
      "                        if match_percentage > results[key]['Match_Percentage']:\n",
      "                            results[key]['Match_Percentage'] = match_percentage\n",
      "                            results[key]['Source_Value'] = source_value\n",
      "\n",
      "    return pd.DataFrame(list(results.values()))\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# # First, ensure that the column names match exactly\n",
      "# eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# # Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "# matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "#     lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "#                       (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "#                 else 0, \n",
      "#     axis=1\n",
      "# )\n",
      "\n",
      "# Display the first few rows of the merged DataFrame\n",
      "#print(matched_disease)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
      "\n",
      "# Load the SentenceTransformer model and biomedical NER pipeline\n",
      "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
      "\n",
      "# Load the biomedical-ner-all model\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
      "\n",
      "# Function to extract biomedical entities using the NER pipeline\n",
      "def extract_entities(text):\n",
      "    if not text:\n",
      "        return []\n",
      "    ner_results = biomedical_ner_pipeline(text)\n",
      "    return [entity['word'] for entity in ner_results]\n",
      "\n",
      "# Function to calculate match percentage using NER and cosine similarity\n",
      "def calculate_match_percentage(criteria, value):\n",
      "    if not criteria or not value:\n",
      "        return 0\n",
      "\n",
      "    # Extract entities from criteria and value\n",
      "    criteria_entities = extract_entities(criteria)\n",
      "    value_entities = extract_entities(value)\n",
      "\n",
      "    # Use extracted entities if available, otherwise fallback to raw text\n",
      "    if criteria_entities and value_entities:\n",
      "        criteria_text = \" \".join(criteria_entities)\n",
      "        value_text = \" \".join(value_entities)\n",
      "    else:\n",
      "        criteria_text = str(criteria)\n",
      "        value_text = str(value)\n",
      "    \n",
      "    # Generate embeddings\n",
      "    criteria_embedding = transformer_model.encode([criteria_text])\n",
      "    value_embedding = transformer_model.encode([value_text])\n",
      "    \n",
      "    # Calculate cosine similarity\n",
      "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
      "    return similarity_score[0][0] * 100\n",
      "\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = {}\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_row = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_row.empty and column_name in patient_row.columns:\n",
      "                        source_value = patient_row[column_name].iloc[0]\n",
      "                        match_percentage = calculate_match_percentage(inclusion_criteria, source_value)\n",
      "                    else:\n",
      "                        source_value = None\n",
      "                        match_percentage = 0\n",
      "                    \n",
      "                    key = (patient_id, trial_id, inclusion_criteria)\n",
      "                    \n",
      "                    if key not in results:\n",
      "                        results[key] = {\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': source_value,\n",
      "                            'Match_Percentage': match_percentage\n",
      "                        }\n",
      "                    else:\n",
      "                        if match_percentage > results[key]['Match_Percentage']:\n",
      "                            results[key]['Match_Percentage'] = match_percentage\n",
      "                            results[key]['Source_Value'] = source_value\n",
      "\n",
      "    return pd.DataFrame(list(results.values()))\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# First, ensure that the column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "Display the first few rows of the merged DataFrame\n",
      "print(matched_disease)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
      "\n",
      "# Load the SentenceTransformer model and biomedical NER pipeline\n",
      "transformer_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
      "\n",
      "# Load the biomedical-ner-all model\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
      "biomedical_ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
      "\n",
      "# Function to extract biomedical entities using the NER pipeline\n",
      "def extract_entities(text):\n",
      "    if not text:\n",
      "        return []\n",
      "    ner_results = biomedical_ner_pipeline(text)\n",
      "    return [entity['word'] for entity in ner_results]\n",
      "\n",
      "# Function to calculate match percentage using NER and cosine similarity\n",
      "def calculate_match_percentage(criteria, value):\n",
      "    if not criteria or not value:\n",
      "        return 0\n",
      "\n",
      "    # Extract entities from criteria and value\n",
      "    criteria_entities = extract_entities(criteria)\n",
      "    value_entities = extract_entities(value)\n",
      "\n",
      "    # Use extracted entities if available, otherwise fallback to raw text\n",
      "    if criteria_entities and value_entities:\n",
      "        criteria_text = \" \".join(criteria_entities)\n",
      "        value_text = \" \".join(value_entities)\n",
      "    else:\n",
      "        criteria_text = str(criteria)\n",
      "        value_text = str(value)\n",
      "    \n",
      "    # Generate embeddings\n",
      "    criteria_embedding = transformer_model.encode([criteria_text])\n",
      "    value_embedding = transformer_model.encode([value_text])\n",
      "    \n",
      "    # Calculate cosine similarity\n",
      "    similarity_score = cosine_similarity(criteria_embedding, value_embedding)\n",
      "    return similarity_score[0][0] * 100\n",
      "\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = {}\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_row = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_row.empty and column_name in patient_row.columns:\n",
      "                        source_value = patient_row[column_name].iloc[0]\n",
      "                        match_percentage = calculate_match_percentage(inclusion_criteria, source_value)\n",
      "                    else:\n",
      "                        source_value = None\n",
      "                        match_percentage = 0\n",
      "                    \n",
      "                    key = (patient_id, trial_id, inclusion_criteria)\n",
      "                    \n",
      "                    if key not in results:\n",
      "                        results[key] = {\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': source_value,\n",
      "                            'Match_Percentage': match_percentage\n",
      "                        }\n",
      "                    else:\n",
      "                        if match_percentage > results[key]['Match_Percentage']:\n",
      "                            results[key]['Match_Percentage'] = match_percentage\n",
      "                            results[key]['Source_Value'] = source_value\n",
      "\n",
      "    return pd.DataFrame(list(results.values()))\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# First, ensure that the column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "#Display the first few rows of the merged DataFrame\n",
      "print(matched_disease)\n",
      "matched_disease.to_csv('test_matched_disease.csv', index=False)\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = []\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_rows = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_rows.empty:\n",
      "                        for _, patient_row in patient_rows.iterrows():\n",
      "                            source_value = patient_row[column_name]\n",
      "                            if pd.notna(source_value):\n",
      "                                match_percentage = calculate_match_percentage(inclusion_criteria, source_value)\n",
      "\n",
      "                                results.append({\n",
      "                                    'Patient_ID': patient_id,\n",
      "                                    'Trial_Name': trial_name,\n",
      "                                    'Trial_ID': trial_id,\n",
      "                                    'Inclusion_Criteria': inclusion_criteria,\n",
      "                                    'Category': category,\n",
      "                                    'Source_Column': source_column,\n",
      "                                    'Source_Value': source_value,\n",
      "                                    'Match_Percentage': match_percentage\n",
      "                                })\n",
      "\n",
      "    # Convert results to a DataFrame and keep only the highest match per patient/trial/criteria combination\n",
      "    results_df = pd.DataFrame(results)\n",
      "    if not results_df.empty:\n",
      "        results_df = results_df.sort_values(by=['Patient_ID', 'Trial_ID', 'Inclusion_Criteria', 'Match_Percentage'], ascending=[True, True, True, False])\n",
      "        results_df = results_df.drop_duplicates(subset=['Patient_ID', 'Trial_ID', 'Inclusion_Criteria'], keep='first')\n",
      "    \n",
      "    return results_df\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# First, ensure that the column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "print(matched_disease)\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = []\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_rows = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_rows.empty:\n",
      "                        for _, patient_row in patient_rows.iterrows():\n",
      "                            source_value = patient_row[column_name]\n",
      "                            match_percentage = (\n",
      "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
      "                                if pd.notna(source_value) else 0\n",
      "                            )\n",
      "                            \n",
      "                            results.append({\n",
      "                                'Patient_ID': patient_id,\n",
      "                                'Trial_Name': trial_name,\n",
      "                                'Trial_ID': trial_id,\n",
      "                                'Inclusion_Criteria': inclusion_criteria,\n",
      "                                'Category': category,\n",
      "                                'Source_Column': source_column,\n",
      "                                'Source_Value': source_value,\n",
      "                                'Match_Percentage': match_percentage\n",
      "                            })\n",
      "                    else:\n",
      "                        # If no matching rows, include a null result\n",
      "                        results.append({\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': None,\n",
      "                            'Match_Percentage': 0\n",
      "                        })\n",
      "\n",
      "    # Convert results to a DataFrame\n",
      "    return pd.DataFrame(results)\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# Ensure column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "print(matched_disease)\n",
      "matched_disease.to_csv('manymatches_matched_disease.csv', index=False)\n",
      "######################################## Evaluate by Inclusion Criteria ########################################\n",
      "\n",
      "eval_result_df_disease = matched_disease.copy()\n",
      "eval_result_df_disease['Model_Decision'] = eval_result_df_disease['Match_Percentage'].apply(lambda x: 1 if x > 95 else 0)\n",
      "\n",
      "# Calculate overall confusion matrix and kappa score\n",
      "y_true_disease = eval_result_df_disease['Expert_Decision_Disease']\n",
      "y_pred_disease = eval_result_df_disease['Model_Decision']\n",
      "\n",
      "conf_matrix_disease = confusion_matrix(y_true_disease, y_pred_disease)\n",
      "kappa_score_disease = cohen_kappa_score(y_true_disease, y_pred_disease)\n",
      "\n",
      "# Print overall results\n",
      "# Print summary of eligible and ineligible patients\n",
      "print(f\"Results for Category: DISEASE\")\n",
      "print(f\"\\nPatients Eligible: {len(eligible_patient_ids)}\")\n",
      "print(f\"Patients Ineligible: {len(ineligible_patient_ids)}\")\n",
      "print(\"\\nOverall Results:\")\n",
      "print(\"\\nConfusion Matrix:\")\n",
      "print(conf_matrix_disease)\n",
      "print(\"\\nCohen's Kappa Score:\", kappa_score_disease)\n",
      "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = []\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_rows = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_rows.empty:\n",
      "                        for _, patient_row in patient_rows.iterrows():\n",
      "                            source_value = patient_row[column_name]\n",
      "                            match_percentage = (\n",
      "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
      "                                if pd.notna(source_value) else 0\n",
      "                            )\n",
      "                            \n",
      "                            results.append({\n",
      "                                'Patient_ID': patient_id,\n",
      "                                'Trial_Name': trial_name,\n",
      "                                'Trial_ID': trial_id,\n",
      "                                'Inclusion_Criteria': inclusion_criteria,\n",
      "                                'Category': category,\n",
      "                                'Source_Column': source_column,\n",
      "                                'Source_Value': source_value,\n",
      "                                'Match_Percentage': match_percentage\n",
      "                            })\n",
      "                    else:\n",
      "                        # If no matching rows, include a null result\n",
      "                        results.append({\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': None,\n",
      "                            'Match_Percentage': 0\n",
      "                        })\n",
      "\n",
      "    # Convert results to a DataFrame\n",
      "    return pd.DataFrame(results)\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# Ensure column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "print(matched_disease)\n",
      "######################################## Check Environment ########################################\n",
      "import sys\n",
      "print(\"Python executable:\", sys.executable)\n",
      "print(\"Python version:\", sys.version)\n",
      "######################################## Install packages ########################################\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "# Create chunks\n",
      "import re\n",
      "\n",
      "# Model for NER\n",
      "import spacy \n",
      "from sklearn.cluster import KMeans\n",
      "import medspacy\n",
      "from medspacy.ner import TargetRule\n",
      "from thefuzz import fuzz, process\n",
      "\n",
      "#UMLSClient for NER\n",
      "import umls_api\n",
      "from umls_api_client import UMLS\n",
      "from quickumls import QuickUMLS\n",
      "\n",
      "# Use natural language processing (NLP) to extract keywords from the criteria\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "nltk.download('stopwords')\n",
      "nltk.download('punkt_tab')\n",
      "nltk.download('wordnet')\n",
      "from sentence_transformers import SentenceTransformer, util\n",
      "\n",
      "# Performance\n",
      "import sklearn\n",
      "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sentence_transformers import SentenceTransformer\n",
      "\n",
      "import snowflake.connector\n",
      "######################################## Connect to Snowflake ########################################\n",
      "\n",
      "# Establish a connection\n",
      "conn = snowflake.connector.connect(\n",
      "    user='dana_george@hakkoda.io',\n",
      "    authenticator='externalbrowser',\n",
      "    account='ska04930.east-us-2.azure',\n",
      "    warehouse='DATASCIENCE_WH',\n",
      "    database='ONCOEMR_RAW_DEV',\n",
      "    schema='DBO',\n",
      "    role='ACCOUNTADMIN'\n",
      ")\n",
      "\n",
      "# Run a test query\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
      "row = cursor.fetchone()\n",
      "print(\"Snowflake version:\", row[0])\n",
      "######################################## Load Data ########################################\n",
      "\n",
      "# Get sample patient ids\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT DISTINCT \"patientid\" FROM ONCOEMR_RAW_DEV.DBO.DEMOGRAHPICS\n",
      "    ORDER BY RANDOM()\n",
      "\"\"\")\n",
      "sample_patient_ids = [row[0] for row in cursor.fetchall()]\n",
      "sample_patient_ids = [f\"'{id}'\" if isinstance(id, str) else str(id) for id in sample_patient_ids]\n",
      "\n",
      "cursor = conn.cursor()\n",
      "cursor.execute(\"\"\"\n",
      "    SELECT table_name\n",
      "    FROM information_schema.tables\n",
      "    WHERE table_schema = 'DBO'\n",
      "    AND table_catalog = 'ONCOEMR_RAW_DEV'\n",
      "    AND table_type = 'BASE TABLE';\n",
      "\"\"\")\n",
      "\n",
      "# Fetch all the table names\n",
      "tables = [row[0] for row in cursor.fetchall()]\n",
      "#print(tables)\n",
      "\n",
      "# Create a dictionary to hold each table as a DataFrame\n",
      "table_dataframes = {}\n",
      "table_dataframes_spat = {}\n",
      "\n",
      "for table in tables:\n",
      "    # First, check if the table contains 'patientid' by querying the columns of the table\n",
      "    cursor.execute(f\"\"\"\n",
      "        SELECT column_name\n",
      "        FROM information_schema.columns\n",
      "        WHERE table_schema = 'DBO' AND table_name = '{table}'\n",
      "    \"\"\")\n",
      "    \n",
      "    columns = [row[0] for row in cursor.fetchall()]\n",
      "    \n",
      "    # If 'patientid' is a column, proceed to query the table\n",
      "    if 'patientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"patientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results = cursor.fetchall()\n",
      "        columns = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes[table] = pd.DataFrame(results, columns=columns)\n",
      "\n",
      "    # If 'spatientid' is a column, proceed to query the table\n",
      "    if 'spatientid' in columns:\n",
      "        query = f\"\"\"\n",
      "            SELECT *\n",
      "            FROM ONCOEMR_RAW_DEV.DBO.{table}\n",
      "            WHERE \"spatientid\" IN ({', '.join(map(str, sample_patient_ids))})\n",
      "        \"\"\"\n",
      "        cursor.execute(query)\n",
      "        \n",
      "        # Fetch the result and convert it to a DataFrame\n",
      "        results_spat = cursor.fetchall()\n",
      "        columns_spat = [desc[0] for desc in cursor.description]\n",
      "        table_dataframes_spat[table] = pd.DataFrame(results_spat, columns=columns_spat)\n",
      "\n",
      "# Merge table_dataframes_spat into table_dataframes_pat\n",
      "table_dataframes.update(table_dataframes_spat)\n",
      "\n",
      "# Now table_dataframes_pat contains all the tables from both dictionaries\n",
      "print(\"Data Loaded Successfully!\")\n",
      "print(\" \")\n",
      "print(\"Tables Loaded:\")\n",
      "for table, df in table_dataframes.items():\n",
      "    print(f\"{table}\")\n",
      "    #print(df.head())\n",
      "\n",
      "# Loop through the dictionary to create a separate DataFrame variable for each key\n",
      "for table, df in table_dataframes.items():\n",
      "    globals()[table] = df\n",
      "\n",
      "# Now you can access the DataFrames as individual variables:\n",
      "# print(ADMINISTRATIONS.head())\n",
      "\n",
      "# Bring in clinical trial data\n",
      "clinical_trials_excl = pd.read_csv('clinical_trials_data_simple_exclusion.csv')\n",
      "clinical_trials_incl = pd.read_csv('breastcancer_incl.csv')\n",
      "print(\"clinical_trials_data_simple_exclusion\")\n",
      "print(\"clinical_trials_data_simple_inclusion\")\n",
      "print(\" \")\n",
      "\n",
      "def print_columns_of_dict_of_dfs(df_dict):\n",
      "    \"\"\"Prints the columns of each DataFrame in a dictionary of DataFrames.\"\"\"\n",
      "\n",
      "    for df_name, df in df_dict.items():\n",
      "        print(f\"Columns of {df_name}:\")\n",
      "        print(df.columns)\n",
      "        print(\"-\" * 20)\n",
      "\n",
      "# Call the function to print the columns\n",
      "print_columns_of_dict_of_dfs(table_dataframes)\n",
      "######################################## Feature Engineering ########################################\n",
      "\n",
      "# Convert non-numeric values to NaN\n",
      "DEMOGRAPHICS['age'] = pd.to_numeric(DEMOGRAPHICS['age'], errors='coerce')\n",
      "\n",
      "# Now, convert the column to integers (NaNs will remain as NaN)\n",
      "DEMOGRAPHICS['age'] = DEMOGRAPHICS['age'].fillna(-1).astype(int)  \n",
      "print(\"Feature Engineering Complete!\")\n",
      "######################################## Quality Check ########################################\n",
      "print(clinical_trials_incl.columns)\n",
      "print(DEMOGRAPHICS)\n",
      "######################################## Build Mock Expert Decision ########################################\n",
      "# Perform the LEFT JOIN\n",
      "merged_df = DEMOGRAPHICS.merge(DIAGNOSIS, on='patientid', how='left')\n",
      "\n",
      "# Filter using \"LIKE\" equivalent\n",
      "eligible = merged_df[\n",
      "    # (merged_df['age'] >= 18) &\n",
      "    # (merged_df['gender'] == 'Female') &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('breast', case=False, na=False)) &\n",
      "    (merged_df['targetdetaileddiagnosisgroup'].str.contains('cancer', case=False, na=False))\n",
      "]\n",
      "\n",
      "# # For evaluation metrics later\n",
      "# eligible['Expert_Decision_Age'] = 1\n",
      "# eligible['Expert_Decision_Gender'] = 1\n",
      "eligible['Expert_Decision_Disease'] = 1\n",
      "\n",
      "#distinct_count = eligible['patientid'].nunique()\n",
      "\n",
      "# Extract patient IDs that match the expert's eligibility criteria\n",
      "eligible_patient_ids = eligible['patientid'].unique().tolist()\n",
      "\n",
      "# Get patient IDs that are not in the eligible list\n",
      "ineligible_patient_ids = merged_df[~merged_df['patientid'].isin(eligible_patient_ids)]['patientid'].unique().tolist()\n",
      "\n",
      "print(len(eligible_patient_ids))\n",
      "print(len(ineligible_patient_ids))\n",
      "\n",
      "print(eligible)\n",
      "######################################## Use Medspacy: Create Entity/Label Pairs in Inclusion Criteria - Clinical Trial Dataframe ########################################\n",
      "\n",
      "### Apply to a dataframe of trial data\n",
      "### Create Inclusion Criteria Categories to be used later in column matching/finding\n",
      "\n",
      "# Load the MedSpaCy model\n",
      "nlp = spacy.load('en_ner_bc5cdr_md')\n",
      "\n",
      "# Function to extract entities and labels\n",
      "def extract_entities(text):\n",
      "    # Process the text through the NLP model\n",
      "    doc = nlp(text)\n",
      "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
      "\n",
      "    # Custom check for age-related information (e.g., \"18 years old\")\n",
      "    age_pattern = r'\\b(?:aged|over|under|above|below)?\\s*(\\d+)\\s*(?:years? old|yrs?|yo)?\\b'\n",
      "    age_matches = re.findall(age_pattern, text, re.IGNORECASE)\n",
      "    \n",
      "    # If age-related information is found, add it to the entities with the correct label\n",
      "    for age in age_matches:\n",
      "        entities.append((f\"{age[0]} years old\", 'AGE'))\n",
      "    \n",
      "    # Custom check for gender-related information (e.g., \"Male\", \"Female\")\n",
      "    gender_keywords = ['female', 'male']  # We only need to check for 'female' and 'male'\n",
      "    \n",
      "    # Check for the first gender-related term match (female first, then male)\n",
      "    gender_found = False\n",
      "    for gender in gender_keywords:\n",
      "        match = re.search(r'\\b' + gender + r'\\b', text, re.IGNORECASE)\n",
      "        if match:\n",
      "            entities.append((match.group(), 'GENDER'))\n",
      "            break  # Once a match is found, stop further checking\n",
      "\n",
      "    # Extract the unique labels to avoid duplicates and return them\n",
      "    unique_labels = set([label for _, label in entities])\n",
      "    return list(unique_labels)\n",
      "\n",
      "# Apply the function to the inclusion_criteria column and create a new 'Category' column\n",
      "clinical_trials_incl['Category'] = clinical_trials_incl['Inclusion_Criteria'].apply(lambda x: ', '.join(extract_entities(x)))\n",
      "\n",
      "# Display the updated DataFrame\n",
      "print(clinical_trials_incl)\n",
      "# Function to match patients to trial criteria\n",
      "def match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes):\n",
      "    results = []\n",
      "    all_patient_ids = set()\n",
      "\n",
      "    # Collect all unique patient IDs\n",
      "    for df in table_dataframes.values():\n",
      "        if 'patientid' in df.columns:\n",
      "            all_patient_ids.update(df['patientid'].unique())\n",
      "\n",
      "    for _, row in clinical_trials_incl_ner_disease.iterrows():\n",
      "        trial_name = row['Trial_Name']\n",
      "        trial_id = row['Trial_ID']\n",
      "        inclusion_criteria = row['Inclusion_Criteria']\n",
      "        category = row['Category']\n",
      "        source_column = row['Source_Columns']\n",
      "        \n",
      "        table_name, column_name = source_column.split('.')\n",
      "        \n",
      "        if table_name in table_dataframes:\n",
      "            df = table_dataframes[table_name]\n",
      "            \n",
      "            if column_name in df.columns:\n",
      "                for patient_id in all_patient_ids:\n",
      "                    patient_rows = df[df['patientid'] == patient_id]\n",
      "                    \n",
      "                    if not patient_rows.empty:\n",
      "                        for _, patient_row in patient_rows.iterrows():\n",
      "                            source_value = patient_row[column_name]\n",
      "                            match_percentage = (\n",
      "                                calculate_match_percentage(inclusion_criteria, source_value) \n",
      "                                if pd.notna(source_value) else 0\n",
      "                            )\n",
      "                            \n",
      "                            results.append({\n",
      "                                'Patient_ID': patient_id,\n",
      "                                'Trial_Name': trial_name,\n",
      "                                'Trial_ID': trial_id,\n",
      "                                'Inclusion_Criteria': inclusion_criteria,\n",
      "                                'Category': category,\n",
      "                                'Source_Column': source_column,\n",
      "                                'Source_Value': source_value,\n",
      "                                'Match_Percentage': match_percentage\n",
      "                            })\n",
      "                    else:\n",
      "                        # If no matching rows, include a null result\n",
      "                        results.append({\n",
      "                            'Patient_ID': patient_id,\n",
      "                            'Trial_Name': trial_name,\n",
      "                            'Trial_ID': trial_id,\n",
      "                            'Inclusion_Criteria': inclusion_criteria,\n",
      "                            'Category': category,\n",
      "                            'Source_Column': source_column,\n",
      "                            'Source_Value': None,\n",
      "                            'Match_Percentage': 0\n",
      "                        })\n",
      "\n",
      "    # Convert results to a DataFrame\n",
      "    return pd.DataFrame(results)\n",
      "\n",
      "# Usage\n",
      "clinical_trials_incl_ner_disease = clinical_trials_incl_ner[clinical_trials_incl_ner['Category'] == 'DISEASE']\n",
      "matched_disease = match_patients_to_criteria(clinical_trials_incl_ner_disease, table_dataframes)\n",
      "\n",
      "# Ensure column names match exactly\n",
      "eligible = eligible.rename(columns={'patientid': 'Patient_ID', 'targetdetaileddiagnosisgroup': 'Source_Value'})\n",
      "\n",
      "# Create a new column 'Expert_Decision_Disease' in matched_disease\n",
      "matched_disease['Expert_Decision_Disease'] = matched_disease.apply(\n",
      "    lambda row: 1 if ((row['Patient_ID'] in eligible['Patient_ID'].values) and \n",
      "                      (row['Source_Value'] == eligible.loc[eligible['Patient_ID'] == row['Patient_ID'], 'Source_Value'].values[0])) \n",
      "                else 0, \n",
      "    axis=1\n",
      ")\n",
      "\n",
      "print(matched_disease)\n",
      "######################################## Evaluate by Inclusion Criteria ########################################\n",
      "\n",
      "eval_result_df_disease = matched_disease.copy()\n",
      "eval_result_df_disease['Model_Decision'] = eval_result_df_disease['Match_Percentage'].apply(lambda x: 1 if x > 95 else 0)\n",
      "\n",
      "# Calculate overall confusion matrix and kappa score\n",
      "y_true_disease = eval_result_df_disease['Expert_Decision_Disease']\n",
      "y_pred_disease = eval_result_df_disease['Model_Decision']\n",
      "\n",
      "conf_matrix_disease = confusion_matrix(y_true_disease, y_pred_disease)\n",
      "kappa_score_disease = cohen_kappa_score(y_true_disease, y_pred_disease)\n",
      "\n",
      "# Print overall results\n",
      "# Print summary of eligible and ineligible patients\n",
      "print(f\"Results for Category: DISEASE\")\n",
      "print(f\"\\nPatients Eligible: {len(eligible_patient_ids)}\")\n",
      "print(f\"Patients Ineligible: {len(ineligible_patient_ids)}\")\n",
      "print(\"\\nOverall Results:\")\n",
      "print(\"\\nConfusion Matrix:\")\n",
      "print(conf_matrix_disease)\n",
      "print(\"\\nCohen's Kappa Score:\", kappa_score_disease)\n",
      "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_mitsui_condapy310)",
   "language": "python",
   "name": "venv_mitsui_condapy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
